{
  "spec_version": "https://w3id.org/biocompute/1.4.2/",
  "object_id": "https://biocompute.sbgenomics.com/bco/cb08bf2b-ea70-40e3-9d25-6555e631454e",
  "etag": "a37f2b3cdeafd92a7f59e63dead44b1b0fa9b19dc4805e5685553fa3aebea450",
  "provenance_domain": {
    "name": "Differential Expression - Salmon + DESeq2",
    "version": "1.0.0",
    "review": [],
    "derived_from": "https://cgc-api.sbgenomics.com/v2/apps/phil_webster/bco-cwl-examples/rnaseq-test/0/raw/",
    "obsolete_after": "2023-02-26T00:00:00+0000",
    "embargo": ["2023-02-26T00:00:00+0000", "2023-02-26T00:00:00+0000"],
    "created": "2023-02-26T00:00:00+0000",
    "modified": "2023-02-26T00:00:00+0000",
    "contributors": [],
    "license": "https://spdx.org/licenses/CC-BY-4.0.html"
  },
  "usability_domain": "This is the workflow developed for the Purdue CGC seminar series. It takes fastQ gene reads, genome reference, and transcript files with GTF gene annotation to feed into Salmon for pseudoalignment then DESeq2 for differential expression.\n\nThe Salmon workflow infers maximum likelihood estimates of transcript abundances from RNA-Seq data using a process called Quasi-mapping.\n\nQuasi-mapping is a process of assigning reads to transcripts without doing an exact base-to-base alignment. The Salmon tool implements a procedure geared towards knowing the transcript from which a read originates rather than the actual mapping coordinates, since the former is crucial to estimating transcript abundances [1, 2].\n\nThe result is a software running at speeds orders of magnitude faster than other tools which utilize the full likelihood model while obtaining near-optimal probabilistic RNA-seq quantification results [1, 2, 3].\n\nDESeq2 performs differential gene expression analysis by use of negative binomial generalized linear models. It analyzes estimated read counts from several samples, each belonging to one of two or more conditions under study, searching for systematic changes between conditions, as compared to within-condition variability.\n\nThe Bioconductor/R package DESeq2 provides a set of functions for importing data, performing exploratory analysis and finally testing for differential expression. This CWL tool is a wrapper around the script based on the standard workflow for this type of analysis [1].\n\nDESeq2 offers two kinds of hypothesis tests: the Wald test, where we use the estimated standard error of a log2 fold change to test if it is equal to zero, and the likelihood ratio test (LRT). The LRT examines two models for the counts, a full model with a certain number of terms and a reduced model, in which some of the terms of the full model are removed. The test determines if the increased likelihood of the data using the extra terms in the full model is more than expected if those extra terms are truly zero. The LRT is therefore useful for testing multiple terms at once, for example testing 3 or more levels of a factor at once, or all interactions between two variables [2].",
  "extension_domain": {
    "fhir_extension": {
      "fhir_endpoint": "",
      "fhir_version": "",
      "fhir_resources": {}
    },
    "scm_extension": {
      "scm_repository": "",
      "scm_type": "git",
      "scm_commit": "",
      "scm_path": "",
      "scm_preview": ""
    }
  },
  "description_domain": {
    "keywords": [],
    "xref": [],
    "platform": [
      "Seven Bridges Platform"
    ],
    "pipeline_steps": [
      {
        "step_number": "1",
        "name": "salmon_workflow_1_2_0",
        "description": "The **Salmon Workflow** estimates transcript abundances from RNA-Seq data using an improved mapping algorithm named **Selective Alignment (SA)**. SA is designed to remain fast as quasi-mapping while simultaneously eliminating many of its mapping errors. It relies upon alignment scoring to help differentiate between mapping loci that would otherwise be indistinguishable due to the multiple exact matches along the reference. Also, the improved mapping algorithm addresses the failure of direct alignment against the transcriptome, compared to spliced alignment to the genome by identifying and extracting sequence-similar decoy regions or using the entire genome as a decoy. The Salmon index is then augmented with these decoy sequences, which are handled in a special manner during mapping and alignment scoring, leading to a reduction of false mappings [1,2].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of this page.*\n\n### Common Use Cases\n\n- The workflow consists of three steps: **Salmon Index**, **Salmon Quant**, and **SBG Create Expression Matrix**.\n- **FASTQ read files** is the required input port that accepts raw sequencing reads. \n- **Transcript FASTA or Salmon Index** is also required and accepts a transcriptome reference file or a pre-built salmon index file.\n- **Genome FASTA** accepts the reference genome file used for extracting decoy sequences.\n- **Gene annotation** file to be used for creating transcripts to genes mapping file required for gene-level aggregation of quantification results.\n- The workflow will generate transcript abundance estimates in plaintext format (**Transcript-level quantifications**), and an optional file containing **Gene-level quantifications** if the **Gene annotation** input is provided. \n- In addition to the quantification outputs, additional outputs can be produced if the proper options are set. These files will be accessible in the TAR archive on the **Salmon Quant archive** output port. \n- A **Transcript expression matrix** and a **Gene expression matrix** will be generated if more than one sample is provided.\n- The workflow is optimized to run in scatter mode. To run it successfully, supply multiple samples (paired-end or single-end, with adequately filled out **Sample ID** and **Paired End** metadata). \n- The **Salmon Quant archive** output can be used for downstream differential expression analysis tools, like DESeq2. \n\n### Changes Introduced by Seven Bridges\n\n- All output files produced with **Salmon Quant - Reads** will be prefixed by the input sample ID (inferred from the **Sample ID** metadata if existent, or from filename otherwise), instead of having identical names between runs.\n\n### Common Issues and Important Notes\n\n- For paired-end read files, it is important to correctly set the **Paired End** metadata field on your read files.\n- The input FASTA file (if provided instead of the already generated Salmon index archive) should be a transcriptome FASTA, not a genomic FASTA.\n- For FASTQ reads in multi-file format (i.e., two FASTQ files for paired-end 1 and two FASTQ files for paired-end 2), proper metadata needs to be set (the following hierarchy is valid: **Sample ID/Library ID/Platform Unit ID/File Segment Number)**.\n- The GTF and FASTA files need to have compatible transcript IDs.\n- If the location of the project where the workflow is running is set to Google US West, to run the task successfully, please reduce the default number of CPUs by setting the **Number of CPUs** parameter of **SBG Pair FASTQs** to 32.\n\n### Performance Benchmarking\n\nThe main advantage of the Salmon software is that it is not computationally challenging, as alignment in the traditional sense is not performed. Therefore, it is optimized to be run in scatter mode, so a c4.8xlarge instance (AWS) is used by default. \nBelow is a table describing the runtimes and task costs for a couple of samples with different file sizes:\n\n| Experiment type |  Input size | Paired-end | # of reads | Read length | Duration |  Cost |  Instance (AWS) |\n|:---------------:|:-----------:|:----------:|:----------:|:-----------:|:--------:|:-----:|:----------:|\n|     RNA-Seq     |  4 x 4.5 GB |     Yes    |     20M     |     101     |   18min   | $0.44| c4.8xlarge |\n|     RNA-Seq     | 2 x 17.4 GB, 2 x 19 GB |     Yes    |     76M & 84M    |     101     |   46min  | $1.20 | c4.8xlarge |\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### API Python Implementation\nThe workflow's draft task can also be submitted via the **API**. In order to learn how to get your **Authentication token** and **API endpoint** for the corresponding platform, visit our [documentation](https://github.com/sbg/sevenbridges-python#authentication-and-configuration).\n\n```python\nfrom sevenbridges import Api\n\n# Enter api credentials\nauthentication_token, api_endpoint = \"enter_your_token\", \"enter_api_endpoint\"\napi = Api(token=authentication_token, url=api_endpoint)\n\n# Get project_id/workflow_id from your address bar. Example: https://igor.sbgenomics.com/u/your_username/project/workflow\nproject_id, workflow_id = \"your_username/project\", \"your_username/project/workflow\"\n\n# Get file names from files in your project. The file names below are just as an example.\ninputs = {\n        'in_reads': list(api.files.query(project=project_id, names=['sample_pe1.fq', 'sample_pe2.fq'])),\n        'in_annotation': list(api.files.query(project=project_id, names=['gtf_file.gtf'])),\n        'in_transcriptome_or_index': list(api.files.query(project=project_id, names=['transcriptome_fasta_file.fa']))\n        }\n\n# Run the task\ntask = api.tasks.create(name='Salmon 1.0.0 workflow - API Example', project=project_id, app=workflow_id, inputs=inputs, run=True)\n```\nInstructions for installing and configuring the API Python client, are provided on [github](https://github.com/sbg/sevenbridges-python#installation). For more information about using the API Python client, consult [sevenbridges-python documentation](http://sevenbridges-python.readthedocs.io/en/latest/). **More examples** are available [here](https://github.com/sbg/okAPI).\n\nAdditionally, [API R](https://github.com/sbg/sevenbridges-r) and [API Java](https://github.com/sbg/sevenbridges-java) clients are available. To learn more about using these API clients, please refer to the [API R client documentation](https://sbg.github.io/sevenbridges-r/), and [API Java client documentation](https://docs.sevenbridges.com/docs/java-library-quickstart).\n\n### References\n\n[1] [Salmon paper](https://www.biorxiv.org/content/10.1101/657874v2)   \n[2] [Towards selective-alignment](https://www.biorxiv.org/content/10.1101/138800v2)",
        "version": "NA",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "2",
        "name": "fastqc_0_11_9",
        "description": "**FastQC** reads a set of sequence files and produces a quality control report from each one. These reports consist of a number of different modules, each of which will help identify a different type of potential problem in your data [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the end of the page.*\n\n\n### Common Use Cases\n\n**FastQC** is a tool which takes a FASTQ file and runs a series of tests on it to generate a comprehensive QC report.  This report will tell you if there is anything unusual about your sequence.  Each test is flagged as a pass, warning, or fail depending on how far it departs from what you would expect from a normal large dataset with no significant biases.  It is important to stress that warnings or even failures do not necessarily mean that there is a problem with your data, only that it is unusual.  It is possible that the biological nature of your sample means that you would expect this particular bias in your results.\n\n- In order to search the library for specific adapter sequences, a TXT file with the adapter sequences needs to be provided on the **Adapters** (`--adapters/-a`) input port. The lines in the file must follow the name [tab] sequence format.\n- In order to search the overrepresented sequences for specific contaminants, a TXT file with the contaminant sequences needs to be provided on the **Contaminants** (`--contaminants/-c`) input port. The lines in the file must follow the name [tab] sequence format.\n- In order to determine the warn/error limits for the various modules or remove some modules from the output, a TXT file with sets of criteria needs to be provided on the **Limits** (`--limits/-l`) input port. The lines in the file must follow the parameter [tab] warn/error [tab] value format.\n\n\n### Changes introduced by Seven Bridges\n\nNo modifications to the original tool representation have been made.\n\n\n### Common Issues and Important Notes\n\nUser can manually set CPU/Memory requirements by providing values on the **Number of CPUs** and **Memory per job [MB]** input ports. If neither of these two is provided and number of threads has been specified on the **Threads** (`--threads/-t`) input port, both CPU and memory per job will be determined by the provided number of threads; if neither number of CPUs/memory per job nor number of threads have been provided as inputs, the CPU and memory requirements will be determined according to the number of files provided on the **Input file** input port.\n\n\n### Performance Benchmarking\n\nThe speed and cost of the workflow depend on the size of the input FASTQ files. The following table showcases the metrics for the task running on the c4.2xlarge on-demand AWS instance. The price can be significantly reduced by using spot instances (set by default). Visit [The Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.\n\nFastq file 1 size(.gz) | Fastq file 2 size(.gz) | Duration | Cost | Instance type (AWS) |\n|---------------|-----------------|-----------|--------|-----|\n| 700 MB | 680 MB | 2 min. | $0.01 | c4.2xlarge |\n| 12.6 GB | 12.6 GB | 25 min. | $0.11 | c4.2xlarge |\n| 23.8 GB | 26.8 GB | 1 hour |$0.27 | c4.2xlarge |\n| 47.9 GB | 48.9 GB | 1 hour 40 min. | $0.44 | c4.2xlarge |\n\n### References\n\n[1] [FastQC GitHub](https://github.com/s-andrews/FastQC/blob/master/fastqc)",
        "version": "0.11.9",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      },
      {
        "step_number": "3",
        "name": "deseq2_1_26_0",
        "description": "**DESeq2** performs differential gene expression analysis by use of negative binomial generalized linear models. It analyzes estimated read counts from several samples, each belonging to one of two or more conditions under study, searching for systematic changes between conditions, as compared to within-condition variability. \n\nThe Bioconductor/R package **DESeq2** provides a set of functions for importing data, performing exploratory analysis and finally testing for differential expression. This CWL tool is a wrapper around the script based on the standard workflow for this type of analysis [1].\n\n**DESeq2** offers two kinds of hypothesis tests: the Wald test, where we use the estimated standard error of a log2 fold change to test if it is equal to zero, and the likelihood ratio test (LRT). The LRT examines two models for the counts, a full model with a certain number of terms and a reduced model, in which some of the terms of the full model are removed. The test determines if the increased likelihood of the data using the extra terms in the full model is more than expected if those extra terms are truly zero. The LRT is therefore useful for testing multiple terms at once, for example testing 3 or more levels of a factor at once, or all interactions between two variables [2].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the end of the page.*\n\n### Common Use Cases\n\nAs input files, please use one of the following: \n\n- **HTSeq**, **RSEM** or **StringTie** gene level abundance estimates;\n- **Salmon**, **Sailfish** or **Kallisto** transcript level abundance estimates.\n\nIf the abundance estimates provided are on a transcript-level, **tximport** will be used to summarize them for gene-level analysis. **Gene annotation** (in GTF format) needs to be supplied then.\n\nTo fit a generalized linear model for each gene, besides gene abundance estimates - some phenotype information is needed. In the simplest case, only a single independant variable is used to explain the expression levels. Experiments with more than one variable influencing the counts can be analyzed using design formula that includes the additional covariates. \n\nThere are two options for providing phenotype information:\n\n1. By indicating API keys for metadata fields that need to be included in the design. Phenotype information will then consist of variables you listed as **Covariate of interest** and **Control variables**.\n2. By including a CSV file (**Phenotype data** input) that contains a row for each sample, with Sample ID in the first column. These Sample IDs need to match those in input files metadata. Also, a single line header with variable names should be included.\n\nExample CSV content below:\n\n```\nsample_id,library,sex,condition\ntreated1,paired-end,male,treated\ntreated2,single-end,male,treated\ntreated3,paired-end,female,treated\nuntreated1,single-end,male,untreated\nuntreated2,paired-end,female,untreated\nuntreated3,paired-end,female,untreated\nuntreated4,paired-end,male,untreated\n```\n\nSupplying a CSV like this while entering \"condition\" for the value of the **Covariate of interest** parameter and \"library\" in **Control variables** will test for differential expression between treated and untreated samples, while controlling for effect of library preparation.\n\nThe information about sample belonging to the treated or the untreated group can also be kept in the metadata. To use a metadata field for splitting the samples into groups for testing, enter its metadata key for the **Covariate of interest** parameter. All the input files need to have this metadata field populated. To control for possible confounders, enter their API keys as **Control variables**.\n\n### Changes Introduced by Seven Bridges\n\nAlthough the script covers different use cases and gives the user some flexibility to tailor the analysis to his own needs, not everything is customizable.\n\nThe user does not choose the type of test that will be performed. The appropriate test is chosen automatically:\n\n- if there are more than two values (levels) to a chosen **Covariate of interest** - LRT is used. \n- if the **Covariate of interest** has only two different values - Wald test is used to test for differential expression.\n\nThe analysis report contains the list of input parameters, phenotype data table, a heatmap of input samples with cluster dendrogram, dispersion estimates plot and an MA plot showing the log2 fold changes attributable to a given gene over the mean of normalized counts and a short summary of results.\n\n### Common Issues and Important Notes\n\n- Any metadata key entered as **Covariate of interest** or **Control variables** needs to exist and it's field be populated in all the samples (**Expression data**) if phenotype data is read from the metadata. Otherwise, if a CSV is supplied - these keys need to match the column names in it's header. Keep in mind that metadata keys are usually different to what is seen on the front-end. To match metadata keys to their corresponding values on the front-end please refer to the table on [this link](https://docs.sevenbridges.com/docs/metadata-on-the-seven-bridges-platform). To learn how to add custom metadata field to expression data files refer to the [following document](https://docs.sevenbridges.com/docs/format-of-a-manifest-file) (section: _Modifying metadata via the visual interface_).\n- Be careful when choosing covariates - generalized linear model fitting will fail if model matrix is not full rank!\n- If your task fails with \"none of the transcripts in the quantification files are present in the first column of tx2gene\" message in the error log, and you are certain that you are using the proper GTF file - you can try rerunning the task with **ignoreTxVersion** option selected. This can happen if you, for example, download the transcriptome FASTA from the Ensembl website and use it to build aligner index - transcript version will then be included in transcript ID in the quantification output file, while in the GTF it's kept as a separate attribute so the transcript IDs will not match.\n\n### Performance Benchmarking\n\nThe execution time for performing differential expression analysis on 6 samples (3 in each group), using transcripts from GENCODE Release 27 (GRCh38.p10) takes 5-6 minutes on the default instance; the price is negligible (~ 0.01$). Unless specified otherwise, the default instance used to run the __DESeq2__ tool will be c4.large (AWS) with 256GB storage.\n\n### References\n\n[1] [RNA-seq workflow: gene-level exploratory analysis and differential expression](https://www.bioconductor.org/help/workflows/rnaseqGene/)\n\n[2] [DESeq2 vignette](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)",
        "version": "1.26.0",
        "prerequisite": [],
        "input_list": [],
        "output_list": []
      }
    ]
  },
  "execution_domain": {
    "script": [
      "https://cgc-api.sbgenomics.com/v2/apps/phil_webster/bco-cwl-examples/rnaseq-test/0/raw/"
    ],
    "script_driver": "Seven Bridges Common Workflow Language Executor",
    "software_prerequisites": [],
    "external_data_endpoints": [],
    "environment_variables": []
  },
  "parametric_domain": [],
  "io_domain": {
    "input_subdomain": [
      {
        "uri": [
          {
            "filename": "",
            "uri": "",
            "access_time": ""
          }
        ]
      }
    ],
    "output_subdomain": [
      {
        "mediatype": "",
        "uri": [
          {
            "uri": "",
            "access_time": ""
          }
        ]
      }
    ]
  },
  "error_domain": {
    "empirical_error": [],
    "algorithmic_error": []
  }
}
