{
  "class": "Workflow",
  "cwlVersion": "v1.0",
  "doc": "The __HISAT2-StringTie Workflow__ can be used to perform a gene abundance estimation of RNA-Seq data (i.e. quantification) of a unified set of genes common for all samples in the analysis. The workflow is based on the\u00a0Nature protocol paper [1] with the  last step (differential expression testing) omitted.\n\nThe first part of the workflow indexes and aligns RNA-Seq reads to the reference using tools from the __HISAT2 2.2.1__ toolkit. The second part performs quantification and, if specified, transcriptome assembly using tools from the\u00a0__StringTie 2.1.3__\u00a0toolkit. Depending on the value of the __Estimate novel isoform abundance?__ required parameter, analysis will be continued in one of two possible ways:\n\n1) If set to 'True' then aligned reads are fed to the first run of __StringTie__ which performs 'reference guided' transcriptome assembly for each sample. Assembled transcripts and reference annotation transcripts are then merged into a uniform set of transcripts. The second run of __StringTie__ performs a quantification of merged transcripts and genes in each sample. For each sample, the workflow outputs the abundance estimation in the __Ballgown__ input format (one TAR bundle containing 5 .ctab tables), two files containing transcript and gene expression values in the __DESeq2__ input format, and a TAB file containing FPKM, TPM, and Coverage values for each gene. In addition to files containing the abundance estimation, the workflow also outputs a GTF file with merged transcripts, __GffCompare__ output files with comparison results between reference annotation transcripts and merged transcripts.\n\n2) If set to 'False' then aligned reads are only fed to  __StringTie__ once, this run performs quantification in each sample. For each sample, the workflow outputs the abundance estimation in the __Ballgown__ input format (one TAR bundle containing 5 .ctab tables), two files containing transcript and gene expression values in the __DESeq2__ input format, and a TAB file containing FPKM, TPM, and Coverage values for each gene. \n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of this page.*\n\n***Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.***\n\n\n### Common Use Cases\n\n- The workflow consists of five steps: __HISAT2 Build__, __HISAT2__, __StringTie__, __StringTie Merge__ and __GffCompare__.\n- __Reads__ is the required input port that accepts raw sequencing reads in FASTQ or FASTA format. Could be also gzip\u2019ed or bzip2'ed.\n- __Reference or Index files__ is also required and accepts a reference FASTA file(s) or a pre-built __HISAT2__ index TAR bundle.\n- __Reference annotation file__ is used for guiding the assembly process and for extracting exons and splice sites to create an index that will enable __HISAT2__ to be a more accurate aligner.\n- This workflow can be used to perform the quantification of RNA-Seq data of a unified set of genomic features across all samples in an analysis suitable for a downstream differential expression step. Once quantification values are obtained, downstream differential expression analysis can be performed using **DESeq2** or **Ballgown** tools on the Seven Bridges Platform.\n\n\n### Changes Introduced by Seven Bridges\n\n* In order to facilitate and accelerate further RNA-Seq analysis, an additional toolkit __Sambamba (0.7.1)__ is integrated into the same Seven Bridges tool with __HISAT2__. Besides the standard __HISAT2__ SAM output, __HISAT2__ has been extended to provide sorted BAM files as well. Thus, the sorting step as described in the protocol paper [1] is not visible in the workflow\u2019s main page.\n\n* An additional, Seven Bridges-designed tool, __SBG Pair FASTQs by Metadata__, is added at the beginning of the workflow in order to enable the processing of multiple samples in a single run.\n\n* The workflow\u2019s indexing step is optional. __HISAT2 Build__ is implemented in a way that it can accept a TAR bundle containing an already indexed reference instead of reference FASTA file(s). If a TAR bundle is provided, the indexing step is skipped and the TAR bundle is forwarded to the output, thus reducing execution costs. You can find pre-built index files (grch38\\_tran.tar.gz, grch37\\_tran.tar.gz, hg38_tran.tar.gz) on the Seven Bridges Platform under the Public Reference Files section. Pre-built index files for organisms other than human can be found [here](https://daehwankimlab.github.io/hisat2/download/).\n\n* In order to enable __StringTie__ to produce quantification tables tailored for __DESeq2__ or [edgeR](http://bioconductor.org/packages/release/bioc/html/edgeR.html), the [`prepDE.py`](https://ccb.jhu.edu/software/stringtie/dl/prepDE.py) Python script [2] that extracts raw counts from **Ballgown** input tables is embedded within the __StringTie__ tool.\n\n### Common Issues and Important Notes\n\n* For paired-end reads, the __Paired-end__ metadata field should be set appropriately in all FASTQ (or FASTA) files that are found in the **Reads** input node.\n\n* All input FASTQ files (or FASTA files depending on the format of input reads) must have the __Sample ID__ metadata field appropriately set.\n\n* The GTF and reference FASTA files need to have compatible chromosome namings (i.e. >1, >2, ... or >chr1, >chr2, ...). If pre-built HISAT2 index is used (reference FASTA file(s) unknown), parameter __Remove 'chr' string__ (`--remove-chrname`) or __Add 'chr' string__ (`--add-chrname`) should be set to provide the same naming convention with GTF file.\n\n### Limitations\n\nThis workflow is optimised for eukaryotic genomes. When running with prokaryotic samples, whose genomes contain no introns and there are no splicing events, the index building step will fail. Please build the index separately with __HISAT2 Build__ default settings, without  __Splice sites file__ (`--ss`) and __Exon file__ (`--exon`) options, and run the workflow with index file in TAR format instead of the genome reference.\n\n### Performance Benchmarking\n\nWorkflow is optimised to be run in scatter mode, so default instance is set to r5.8xlarge with 2 GB of EBS (AWS). The most intensive part in the workflow is reference indexing. For example, building hg38 human reference index using reference transcriptome requires 160 GB of RAM (for more details see the [HISAT2 homepage](https://daehwankimlab.github.io/hisat2/manual/)).\n\nIn the following table you can find estimates of the workflow runtime and its cost when the __Estimate novel isoform abundance?__ parameter is set to 'True'. Indexing is not performed, a TAR index archive (size 5.4 GB) is provided. Size of the gene annotation file is 1.2 GB. All tasks were executed on the on-demand default AWS instance.\n\nNote: Input size and number of reads refer to the average value per sample.\n\n| # of samples | Input format | Input size | Paired-end | # of reads | Read length | Duration  | Cost   |\n|--------------|--------------|------------|------------|------------|-------------|-----------|--------|\n| 400          | FASTQ.GZ     | 287.5 MB     | No         | 11M      | 36          | 1h 41min  | $17.67 |\n| 100          | FASTQ.GZ     | 300 MB      | No         | 11M      | 36          | 36min  | $5.64 |\n| 1           | FASTQ        | 3.8 GB     | Yes        | 16M    | 101         | 13min  | $0.53 |\n| 50           | FASTQ.GZ     | 3.9 GB     | Yes        | 60M     | 75          | 3h 37min  | $20.91 |\n| 200          | FASTQ.GZ     | 4 GB     | Yes        | 60M     | 75          | 8h 23min | $66.07 |\n| 16           | FASTQ        | 21 GB     | No        | 79M    | 75         | 2h 48min  | $9.50 |\n| 16          | FASTQ        |  35.9 GB     | Yes        | 160M    | 50          | 4h 37min | $15.91 |\n| 1           | FASTQ        |  37 GB     | Yes        | 163M    | 101          | 1h 29 min | $3.44 |\n| 10*          | FASTQ     | 62.5 GB     | Yes        | 190M     | 101          | 6h 40min | $21.68 |\n*EBS increased to 3 GB due to large input size\n\nRuntime and task cost for one of the samples above when indexing is performed (size of reference file - 2.9 GB, size of GTF file - 1.2 GB):\n\n| # of samples | Input format | Input size | Paired-end | # of reads | Read length | Duration  | Cost   |\n|--------------|--------------|------------|------------|------------|-------------|-----------|--------|\n| 1           | FASTQ        | 3.8 GB     | Yes        | 16M    | 101         | 1h 6min  | $2.56 |\n\n*The cost of running __HISAT2-StringTie Workflow__ can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### API Python Implementation\nThe app's draft task can also be submitted via the **API**. In order to learn how to get your **Authentication token** and **API endpoint** for the corresponding Platform visit our [documentation](https://github.com/sbg/sevenbridges-python#authentication-and-configuration).\n\n```python\nfrom sevenbridges import Api\n\n# Enter api credentials\nauthentication_token, api_endpoint = \"enter_your_token\", \"enter_api_endpoint\"\napi = Api(token=authentication_token, url=api_endpoint)\n\n# Get project_id/workflow_id from your address bar. Example: https://igor.sbgenomics.com/u/your_username/project/workflow\nproject_id, workflow_id = \"your_username/project\", \"your_username/project/workflow\"\n\n# Get file names from files in your project. The file names below are just as an example.\ninputs = {\n        'in_reads': list(api.files.query(project=project_id, names=['sample_pe1.fq', 'sample_pe2.fq'])),\n        'in_gene_annotation': list(api.files.query(project=project_id, names=['gtf_file.gtf'])),\n        'in_references_or_index': list(api.files.query(project=project_id, names=['reference_fasta_file.fa'])),\n         'discover_novel_isoform': True\n        }\n\n# Run the task\ntask = api.tasks.create(name='HISAT2-StringTie Workflow - API Run', project=project_id, app=workflow_id, inputs=inputs, run=True)\n```\nInstructions for installing and configuring the API Python client, are provided on [github](https://github.com/sbg/sevenbridges-python#installation). For more information about using the API Python client, consult [sevenbridges-python documentation](http://sevenbridges-python.readthedocs.io/en/latest/). **More examples** are available [here](https://github.com/sbg/okAPI).\n\nAdditionally, [API R](https://github.com/sbg/sevenbridges-r) and [API Java](https://github.com/sbg/sevenbridges-java) clients are available. To learn more about using these API clients please refer to the [API R client documentation](https://sbg.github.io/sevenbridges-r/), and [API Java client documentation](https://docs.sevenbridges.com/docs/java-library-quickstart).\n\n\n### References\n\n[1] [HISAT, StringTie, Ballgown protocol paper](https://www.nature.com/articles/nprot.2016.095)\n\n[2] [StringTie manual page - using StringTie with DESeq2 and edgeR](https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual#deseq)",
  "label": "HISAT2-StringTie Workflow",
  "$namespaces": {
    "sbg": "https://sevenbridges.com"
  },
  "inputs": [
    {
      "id": "in_gene_annotation",
      "sbg:fileTypes": "GTF",
      "type": "File",
      "label": "Reference annotation file",
      "doc": "Reference annotation file (in GTF format) for guiding the assembly process and for extracting exons and splice sites to create an index that will enable HISAT2 to be more accurate aligner.",
      "sbg:x": -977.1519775390625,
      "sbg:y": -454.7715148925781
    },
    {
      "id": "discover_novel_isoform",
      "type": {
        "type": "enum",
        "symbols": [
          "True",
          "False"
        ],
        "name": "discover_novel_isoform"
      },
      "label": "Estimate novel isoform abundance?",
      "doc": "If true, StringTie will be run twice, first time with known isoforms, and second time with input isoforms and isoforms discovered during first run.",
      "description": "If True first input is propagated.",
      "sbg:x": -984.520751953125,
      "sbg:y": -663.4976806640625
    },
    {
      "id": "in_references_or_index",
      "sbg:fileTypes": "FASTA, FA, FASTA.GZ, FA.GZ, TAR, TAR.GZ",
      "type": "File[]",
      "label": "Reference or Index files",
      "doc": "Reference FASTA files for indexing or TAR bundle containing already indexed reference. If TAR bundle is provided indexing part will be skipped and TAR bundle will be forwarded to the output.",
      "sbg:x": -987.4024047851562,
      "sbg:y": 125
    },
    {
      "id": "in_reads",
      "sbg:fileTypes": "FASTQ, FQ, FASTQ.GZ, FQ.GZ, FASTA, FA, FASTA.GZ, FA.GZ, FASTQ.BZ2, FQ.BZ2, FASTA.BZ2, FA.BZ2",
      "type": "File[]",
      "label": "Reads",
      "doc": "Read files in FASTQ or FASTA format. Could be also gzip\u2019ed (extension .gz) or bzip2'ed (extension .bz2).",
      "sbg:x": -988.6988525390625,
      "sbg:y": -157.64093017578125
    },
    {
      "id": "remove_chrname",
      "type": "boolean?",
      "label": "Remove 'chr' string",
      "doc": "Remove 'chr' from reference names in alignment (e.g., chr18 to 18).",
      "sbg:exposed": true
    },
    {
      "id": "add_chrname",
      "type": "boolean?",
      "label": "Add 'chr' string",
      "doc": "Add 'chr' to reference names in alignment (e.g., 18 to chr18).",
      "sbg:exposed": true
    }
  ],
  "outputs": [
    {
      "id": "out_gffcmp_stats_files",
      "outputSource": [
        "sbg_file_selector/out"
      ],
      "sbg:fileTypes": "TRACKING, LOCI, STATS, GTF, REFMAP, TMAP",
      "type": "File[]?",
      "label": "GffCompare stats files",
      "doc": "GffCompare stats files.",
      "sbg:x": 1209.8048095703125,
      "sbg:y": -745.7012329101562
    },
    {
      "id": "out_merged_transcripts",
      "outputSource": [
        "sbg_file_selector_1/out"
      ],
      "sbg:fileTypes": "GTF",
      "type": "File[]?",
      "label": "Merged transcripts",
      "doc": "Merged transcripts.",
      "sbg:x": 1224.0120849609375,
      "sbg:y": -440.40240478515625
    },
    {
      "id": "out_gene_abundance",
      "outputSource": [
        "stringtie_2_1_4/out_gene_abundance"
      ],
      "sbg:fileTypes": "TAB",
      "type": "File[]?",
      "label": "Gene abundance estimation",
      "doc": "Tab delimited file containing gene abundance level estimation.",
      "sbg:x": 1253.1036376953125,
      "sbg:y": -124.10362243652344
    },
    {
      "id": "out_deseq2_transcript_count_matrix",
      "outputSource": [
        "stringtie_2_1_4/out_deseq2_transcript_count_matrix"
      ],
      "sbg:fileTypes": "CSV",
      "type": "File[]?",
      "label": "DESeq2 transcript count matrix",
      "doc": "CSV file containing raw counts for transcripts that can be directly fed to DESeq2 or EdgeR to perform differential expression ananlysis.",
      "sbg:x": 1258.326904296875,
      "sbg:y": 64.83655548095703
    },
    {
      "id": "out_deseq2_gene_count_matrix",
      "outputSource": [
        "stringtie_2_1_4/out_deseq2_gene_count_matrix"
      ],
      "sbg:fileTypes": "CSV",
      "type": "File[]?",
      "label": "DESeq2 gene count matrix",
      "doc": "CSV file containing raw counts for genes that can be directly fed to DESeq2 or EdgeR to perform differential expression analysis.",
      "sbg:x": 1278.269287109375,
      "sbg:y": 228.02882385253906
    },
    {
      "id": "out_archived_ballgown_input_tables",
      "outputSource": [
        "stringtie_2_1_4/out_archived_ballgown_input_tables"
      ],
      "sbg:fileTypes": "TAR",
      "type": "File[]?",
      "label": "Archived ballgown input tables",
      "doc": "Archived file containing all .ctab tables required for differential expression analysis using Ballgown R package.",
      "sbg:x": 1298.2786865234375,
      "sbg:y": 404.46148681640625
    }
  ],
  "steps": [
    {
      "id": "sbg_file_selector",
      "in": [
        {
          "id": "select",
          "source": "discover_novel_isoform"
        },
        {
          "id": "in_1",
          "source": [
            "gffcompare_0_11_6/out_gffcmp_stats_files"
          ]
        }
      ],
      "out": [
        {
          "id": "out"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "sevenbridges/sbgtools-cwl1-0-demo/sbg-file-selector/2",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:includeInPorts": true,
            "id": "select",
            "type": {
              "type": "enum",
              "symbols": [
                "True",
                "False"
              ],
              "name": "select"
            },
            "label": "Propagate first input",
            "doc": "If True first input is propagated."
          },
          {
            "id": "in_2",
            "type": "File[]?",
            "label": "Second input"
          },
          {
            "id": "in_1",
            "type": "File[]?",
            "label": "First input"
          }
        ],
        "outputs": [
          {
            "id": "out",
            "type": "File[]?",
            "outputBinding": {
              "glob": "${  \n    var arr=[];\n    var output=[];   \n    \n    if (inputs.select == 'True'){ ;\n        if(inputs.in_1){ \n            arr=[].concat(inputs.in_1);\n        }\n    } \n    else{ ;\n        if(inputs.in_2){ \n            arr = [].concat(inputs.in_2);\n        }\n    }        \n    \n    for(var i=0; i<arr.length; i++){\n        output.push(arr[i].basename);\n            }\n       \n    var glob=\"{\"+output.join(\",\")+\"}\";\n    \n    return glob; \n} "
            }
          }
        ],
        "doc": "SBG File selector selects which input file will be propagated to output. If 'Propagate first input' parameter is set to 'True', input 'in_1' will be propagated to output, else 'in_2' is chosen.",
        "label": "SBG File Selector",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${\n    if(inputs.select = 'True'){\n        return 'echo pass in_1 on output'\n    }else{\n        return 'echo pass in_2 on output'\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1000,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "ubuntu:16.04"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.in_2)",
              "$(inputs.in_1)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var setMetadata = function(file, metadata) {     if (!('metadata' in file)) {         file['metadata'] = {}     }     for (var key in metadata) {         file['metadata'][key] = metadata[key];     }     return file }; var inheritMetadata = function(o1, o2) {     var commonMetadata = {};     if (!Array.isArray(o2)) {         o2 = [o2]     }     for (var i = 0; i < o2.length; i++) {         var example = o2[i]['metadata'];         for (var key in example) {             if (i == 0)                 commonMetadata[key] = example[key];             else {                 if (!(commonMetadata[key] == example[key])) {                     delete commonMetadata[key]                 }             }         }     }     if (!Array.isArray(o1)) {         o1 = setMetadata(o1, commonMetadata)     } else {         for (var i = 0; i < o1.length; i++) {             o1[i] = setMetadata(o1[i], commonMetadata)         }     }     return o1; };"
            ]
          }
        ],
        "sbg:cmdPreview": "echo pass First_on_output on output",
        "sbg:image_url": null,
        "sbg:projectName": "SBGTools - CWL1.0 - Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598538974,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598539055,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598614698,
            "sbg:revisionNotes": ""
          }
        ],
        "sbg:toolkit": "SBGTools",
        "sbg:categories": [
          "CWL1.0"
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-b3d8bf70/h-4311029e/h-f60dcb48/0",
        "sbg:revision": 2,
        "sbg:revisionNotes": "",
        "sbg:modifiedOn": 1598614698,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1598538974,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "sevenbridges/sbgtools-cwl1-0-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 2,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "aacd65be250d08e1e2abcaccff8c709bca638c8fde960dd692e05865c20bd99f0"
      },
      "label": "SBG File Selector",
      "sbg:x": 915.2741088867188,
      "sbg:y": -640.0308837890625
    },
    {
      "id": "sbg_file_selector_1",
      "in": [
        {
          "id": "select",
          "source": "discover_novel_isoform"
        },
        {
          "id": "in_1",
          "source": [
            "stringtie_merge_2_1_3/out_merged_transcripts"
          ]
        }
      ],
      "out": [
        {
          "id": "out"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "sevenbridges/sbgtools-cwl1-0-demo/sbg-file-selector/2",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:includeInPorts": true,
            "id": "select",
            "type": {
              "type": "enum",
              "symbols": [
                "True",
                "False"
              ],
              "name": "select"
            },
            "label": "Propagate first input",
            "doc": "If True first input is propagated."
          },
          {
            "id": "in_2",
            "type": "File[]?",
            "label": "Second input"
          },
          {
            "id": "in_1",
            "type": "File[]?",
            "label": "First input"
          }
        ],
        "outputs": [
          {
            "id": "out",
            "type": "File[]?",
            "outputBinding": {
              "glob": "${  \n    var arr=[];\n    var output=[];   \n    \n    if (inputs.select == 'True'){ ;\n        if(inputs.in_1){ \n            arr=[].concat(inputs.in_1);\n        }\n    } \n    else{ ;\n        if(inputs.in_2){ \n            arr = [].concat(inputs.in_2);\n        }\n    }        \n    \n    for(var i=0; i<arr.length; i++){\n        output.push(arr[i].basename);\n            }\n       \n    var glob=\"{\"+output.join(\",\")+\"}\";\n    \n    return glob; \n} "
            }
          }
        ],
        "doc": "SBG File selector selects which input file will be propagated to output. If 'Propagate first input' parameter is set to 'True', input 'in_1' will be propagated to output, else 'in_2' is chosen.",
        "label": "SBG File Selector",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${\n    if(inputs.select = 'True'){\n        return 'echo pass in_1 on output'\n    }else{\n        return 'echo pass in_2 on output'\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1000,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "ubuntu:16.04"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.in_2)",
              "$(inputs.in_1)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var setMetadata = function(file, metadata) {     if (!('metadata' in file)) {         file['metadata'] = {}     }     for (var key in metadata) {         file['metadata'][key] = metadata[key];     }     return file }; var inheritMetadata = function(o1, o2) {     var commonMetadata = {};     if (!Array.isArray(o2)) {         o2 = [o2]     }     for (var i = 0; i < o2.length; i++) {         var example = o2[i]['metadata'];         for (var key in example) {             if (i == 0)                 commonMetadata[key] = example[key];             else {                 if (!(commonMetadata[key] == example[key])) {                     delete commonMetadata[key]                 }             }         }     }     if (!Array.isArray(o1)) {         o1 = setMetadata(o1, commonMetadata)     } else {         for (var i = 0; i < o1.length; i++) {             o1[i] = setMetadata(o1[i], commonMetadata)         }     }     return o1; };"
            ]
          }
        ],
        "sbg:cmdPreview": "echo pass First_on_output on output",
        "sbg:image_url": null,
        "sbg:projectName": "SBGTools - CWL1.0 - Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598538974,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598539055,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598614698,
            "sbg:revisionNotes": ""
          }
        ],
        "sbg:toolkit": "SBGTools",
        "sbg:categories": [
          "CWL1.0"
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-95e04080/h-1f162810/h-866cd719/0",
        "sbg:revision": 2,
        "sbg:revisionNotes": "",
        "sbg:modifiedOn": 1598614698,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1598538974,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "sevenbridges/sbgtools-cwl1-0-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 2,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "aacd65be250d08e1e2abcaccff8c709bca638c8fde960dd692e05865c20bd99f0"
      },
      "label": "SBG File Selector",
      "sbg:x": 920.4630126953125,
      "sbg:y": -319.3086853027344
    },
    {
      "id": "sbg_file_selector_2",
      "in": [
        {
          "id": "select",
          "source": "discover_novel_isoform"
        },
        {
          "id": "in_2",
          "source": [
            "in_gene_annotation"
          ]
        },
        {
          "id": "in_1",
          "source": [
            "stringtie_merge_2_1_3/out_merged_transcripts"
          ]
        }
      ],
      "out": [
        {
          "id": "out"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "sevenbridges/sbgtools-cwl1-0-demo/sbg-file-selector/2",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:includeInPorts": true,
            "id": "select",
            "type": {
              "type": "enum",
              "symbols": [
                "True",
                "False"
              ],
              "name": "select"
            },
            "label": "Propagate first input",
            "doc": "If True first input is propagated."
          },
          {
            "id": "in_2",
            "type": "File[]?",
            "label": "Second input"
          },
          {
            "id": "in_1",
            "type": "File[]?",
            "label": "First input"
          }
        ],
        "outputs": [
          {
            "id": "out",
            "type": "File[]?",
            "outputBinding": {
              "glob": "${  \n    var arr=[];\n    var output=[];   \n    \n    if (inputs.select == 'True'){ ;\n        if(inputs.in_1){ \n            arr=[].concat(inputs.in_1);\n        }\n    } \n    else{ ;\n        if(inputs.in_2){ \n            arr = [].concat(inputs.in_2);\n        }\n    }        \n    \n    for(var i=0; i<arr.length; i++){\n        output.push(arr[i].basename);\n            }\n       \n    var glob=\"{\"+output.join(\",\")+\"}\";\n    \n    return glob; \n} "
            }
          }
        ],
        "doc": "SBG File selector selects which input file will be propagated to output. If 'Propagate first input' parameter is set to 'True', input 'in_1' will be propagated to output, else 'in_2' is chosen.",
        "label": "SBG File Selector",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${\n    if(inputs.select = 'True'){\n        return 'echo pass in_1 on output'\n    }else{\n        return 'echo pass in_2 on output'\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1000,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "ubuntu:16.04"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.in_2)",
              "$(inputs.in_1)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var setMetadata = function(file, metadata) {     if (!('metadata' in file)) {         file['metadata'] = {}     }     for (var key in metadata) {         file['metadata'][key] = metadata[key];     }     return file }; var inheritMetadata = function(o1, o2) {     var commonMetadata = {};     if (!Array.isArray(o2)) {         o2 = [o2]     }     for (var i = 0; i < o2.length; i++) {         var example = o2[i]['metadata'];         for (var key in example) {             if (i == 0)                 commonMetadata[key] = example[key];             else {                 if (!(commonMetadata[key] == example[key])) {                     delete commonMetadata[key]                 }             }         }     }     if (!Array.isArray(o1)) {         o1 = setMetadata(o1, commonMetadata)     } else {         for (var i = 0; i < o1.length; i++) {             o1[i] = setMetadata(o1[i], commonMetadata)         }     }     return o1; };"
            ]
          }
        ],
        "sbg:cmdPreview": "echo pass First_on_output on output",
        "sbg:image_url": null,
        "sbg:projectName": "SBGTools - CWL1.0 - Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598538974,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598539055,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598614698,
            "sbg:revisionNotes": ""
          }
        ],
        "sbg:toolkit": "SBGTools",
        "sbg:categories": [
          "CWL1.0"
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-fe00a146/h-cbfd8897/h-7f33bc59/0",
        "sbg:revision": 2,
        "sbg:revisionNotes": "",
        "sbg:modifiedOn": 1598614698,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1598538974,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "sevenbridges/sbgtools-cwl1-0-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 2,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "aacd65be250d08e1e2abcaccff8c709bca638c8fde960dd692e05865c20bd99f0"
      },
      "label": "SBG File Selector",
      "sbg:x": 773.6970825195312,
      "sbg:y": -57.96084976196289
    },
    {
      "id": "stringtie_2_1_3",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "in_gene_annotation"
        },
        {
          "id": "in_alignments",
          "source": "hisat2_2_2_1/out_alignment"
        }
      ],
      "out": [
        {
          "id": "out_assembled_transcripts"
        },
        {
          "id": "out_gene_abundance"
        },
        {
          "id": "out_covered_ref_transcripts"
        },
        {
          "id": "out_archived_ballgown_input_tables"
        },
        {
          "id": "out_deseq2_gene_count_matrix"
        },
        {
          "id": "out_deseq2_transcript_count_matrix"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "nevena_vukojicic/stringtie-2-1-3-demo/stringtie-2-1-3/7",
        "baseCommand": [
          "/opt/stringtie-2.1.3b.Linux_x86_64/stringtie"
        ],
        "inputs": [
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "2",
            "id": "num_of_threads",
            "type": "int?",
            "inputBinding": {
              "prefix": "-p",
              "shellQuote": false,
              "position": 6,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.num_of_threads = null ;\n    };\n\n\n    if (inputs.num_of_threads) { ;\n        return inputs.num_of_threads ;\n    } else { ;\n        return 2 ;\n    } ;\n\n}"
            },
            "label": "Number of threads",
            "doc": "Specify the number of processing threads (CPUs) to use for transcript assembly.",
            "default": 0
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_gene_annotation",
            "type": "File?",
            "inputBinding": {
              "prefix": "-G",
              "shellQuote": false,
              "position": 7
            },
            "label": "Reference annotation file",
            "doc": "Use the reference annotation file (in GTF or GFF3 format) to guide the assembly process. The output will include expressed reference transcripts as well as any novel transcripts that are assembled.",
            "sbg:fileTypes": "GTF, GFF3"
          },
          {
            "sbg:toolDefaultValue": "STRG",
            "sbg:category": "Execution",
            "id": "transcripts_name_prefix",
            "type": "string?",
            "inputBinding": {
              "prefix": "-l",
              "shellQuote": false,
              "position": 8
            },
            "label": "Transcripts name prefix",
            "doc": "Sets the prefix for the name of the output transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0.01",
            "id": "minimum_isoform_abundance",
            "type": "float?",
            "inputBinding": {
              "prefix": "-f",
              "shellQuote": false,
              "position": 9
            },
            "label": "Minimum isoform abundance",
            "doc": "Sets the minimum isoform abundance of the predicted transcripts as a fraction of the most abundant transcript assembled at a given locus. Lower abundance transcripts are often artifacts of incompletely spliced precursors of processed transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "200",
            "id": "minimum_length",
            "type": "int?",
            "inputBinding": {
              "prefix": "-m",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum isoform length",
            "doc": "Sets the minimum length allowed for the predicted transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "gene_abundance",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-A",
              "shellQuote": false,
              "position": 21,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.gene_abundance = null ;\n    };\n\n\n    if (inputs.gene_abundance) { ;\n        var cmd = \"./\" ;\n        if (inputs.output_prefix) { ;\n            var base_file_name = inputs.output_prefix ;\n    }   else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    }   else { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].nameroot\n    };\n        cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.gene_abundance.tab\") ;\n    return cmd ;\n    };\n}"
            },
            "label": "Output gene abundance",
            "doc": "Tells StringTie to output a file (tab delimited format) in which gene abundance estimation will be reported.",
            "default": 0
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "covered_ref_transcripts",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-C",
              "shellQuote": false,
              "position": 22,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.covered_ref_transcripts = null ;\n    };\n\n\n    if (inputs.covered_ref_transcripts) { ;\n        var cmd = \"./\" ;\n        if (inputs.output_prefix) { ; \n            var base_file_name = inputs.output_prefix ;\n    }   else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    }   else { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].nameroot\n    };\n        cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.covered_transcripts.gtf\") ;\n        return cmd ;\n    };\n}"
            },
            "label": "Output covered reference transcripts",
            "doc": "Tell StringTie to output a file with all transcripts in the provided reference file that are fully covered by the reads. This option requires reference annotation file to be provided.",
            "default": 0
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "junction_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-j",
              "shellQuote": false,
              "position": 13
            },
            "label": "Minimum junction coverage",
            "doc": "There should be at least this many spliced reads that align across a junction (i.e. junction coverage). This number can be fractional, since some reads align in more than one place. A read that aligns in n places will contribute 1/n to the junction coverage."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "disable_trimming",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-t",
              "shellQuote": false,
              "position": 18
            },
            "label": "Disable trimming",
            "doc": "This parameter disables trimming at the ends of the assembled transcripts. By default StringTie adjusts the predicted transcript's start and/or stop coordinates based on sudden drops in coverage of the assembled transcript."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "minimum_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-c",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum read coverage",
            "doc": "Sets the minimum read coverage allowed for the predicted transcripts. A transcript with a lower coverage than this value is not shown in the output."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "50",
            "id": "minimum_locus_gap",
            "type": "int?",
            "inputBinding": {
              "prefix": "-g",
              "shellQuote": false,
              "position": 16
            },
            "label": "Minimum locus gap separation value",
            "doc": "Reads that are mapped closer than this distance (distance is measured in bp) are merged together in the same processing bundle."
          },
          {
            "sbg:category": "Execution",
            "id": "ballgown_and_deseq2_preprocessing",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-B",
              "shellQuote": false,
              "position": 31
            },
            "label": "Create input files for Ballgown and DESeq2",
            "doc": "This switch enables the output of Ballgown input table files (*.ctab) containing coverage data for the reference transcripts given with the -G option. With this option StringTie can be used as a direct replacement of the tablemaker program included with the Ballgown distribution. In addition to Ballgown input tables count matrix for DESeq2 will be also created."
          },
          {
            "sbg:category": "Execution",
            "id": "keep_annotated_transcripts",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-e",
              "shellQuote": false,
              "position": 26
            },
            "label": "Keep annotated transcripts only",
            "doc": "Limits the processing of read alignments to only estimate and output the assembled transcripts matching the reference transcripts given in the reference annotation file. With this option, read bundles with no reference transcripts will be entirely skipped, which may provide a considerable speed boost when the given set of reference transcripts is limited to a set of target genes, for example."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0.95",
            "id": "multiply_mapped_reads",
            "type": "float?",
            "inputBinding": {
              "prefix": "-M",
              "shellQuote": false,
              "position": 17
            },
            "label": "Maximum fraction of multiply mapped reads",
            "doc": "Sets the maximum fraction of multiple-location-mapped reads that are allowed to be present at a given locus."
          },
          {
            "sbg:category": "Execution",
            "id": "seqid_list",
            "type": "string?",
            "inputBinding": {
              "prefix": "-x",
              "shellQuote": false,
              "position": 27
            },
            "label": "Ignore alignments on the specified sequence",
            "doc": "Ignore all read alignments (and thus do not attempt to perform transcript assembly) on the specified reference sequences. Parameter <seqid_list> can be a single reference sequence name (e.g. -x chrM) or a comma-delimited list of sequence names (e.g. -x 'chrM,chrX,chrY'). The reference sequence names are case sensitive, they must match identically the names of chromosomes/contigs of the target genome against which the RNA-Seq reads were aligned in the first place."
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_alignments",
            "type": "File",
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Aligned reads",
            "doc": "Aligned reads in binary SAM (BAM) format sorted by coordinate.",
            "sbg:fileTypes": "BAM"
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "10",
            "id": "anchor_length_for_junctions",
            "type": "int?",
            "inputBinding": {
              "prefix": "-a",
              "shellQuote": false,
              "position": 12
            },
            "label": "Minimum anchor length for junctions",
            "doc": "Junctions that don't have spliced reads that align across them with at least this amount of bases on both sides are filtered out."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "firststrand",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--rf",
              "shellQuote": false,
              "position": 10
            },
            "label": "Stranded library - firststrand",
            "doc": "Assumes a stranded library fr-firststrand."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "secondstrand",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--fr",
              "shellQuote": false,
              "position": 10
            },
            "label": "Stranded library - secondstrand",
            "doc": "Assumes a stranded library fr-secondstrand."
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_feature_file",
            "type": "File?",
            "inputBinding": {
              "prefix": "--ptf",
              "shellQuote": false,
              "position": 10
            },
            "label": "Text feature file",
            "doc": "Loads a list of point-features from a text feature file <f_tab> to guide the transcriptome assembly. Accepted point features are transcription start sites (TSS) and polyadenylation sites (CPAS). There are four tab-delimited columns in the feature file. The first three define the location of the point feature on the cromosome (sequence name, coordinate and strand), and the last is the type of the feature (TSS or CPAS). For instance:\nchrI\t35608\t-\tTSS\nchrI\t1634\t+\tCPAS\nare two examples for potential lines in the feature file.",
            "sbg:fileTypes": "TAB"
          },
          {
            "sbg:toolDefaultValue": "4.75",
            "sbg:category": "Execution",
            "id": "minimum_single_exon_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-s",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum coverage for single-exon transcripts",
            "doc": "Sets the minimum read coverage allowed for single-exon transcripts."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "conservative_mode",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--conservative",
              "shellQuote": false,
              "position": 11
            },
            "label": "Conservative mode",
            "doc": "Assembles transcripts in a conservative mode. Same as -t -c 1.5 -f 0.05"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "multi_mapping_correction",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-u",
              "shellQuote": false,
              "position": 30
            },
            "label": "Multi-mapping correction",
            "doc": "Turn off multi-mapping correction. In the default case this correction is enabled, and each read that is mapped in n places only contributes 1/n to the transcript coverage instead of 1."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "long_reads",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-L",
              "shellQuote": false,
              "position": 20
            },
            "label": "Long reads processing",
            "doc": "Long reads processing; also enforces -s 1.5 -g 0"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "long_reads_alternative",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-R",
              "shellQuote": false,
              "position": 20
            },
            "label": "-L alternative",
            "doc": "Outputs unassembled, cleaned, and non-redundant long read alignments (collapsing similar long reads alignments at the same location)."
          },
          {
            "sbg:toolDefaultValue": "25",
            "sbg:category": "Execution",
            "id": "splice_sites_window",
            "type": "int?",
            "inputBinding": {
              "prefix": "-E",
              "shellQuote": false,
              "position": 20
            },
            "label": "Long reads splice sites window",
            "doc": "Define window around possibly erroneous splice sites from long reads to look out for correct splice sites"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "viral_data",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--viral",
              "shellQuote": false,
              "position": 20
            },
            "label": "Viral long reads",
            "doc": "Only relevant for long reads from viral data where splice sites do not follow consensus"
          },
          {
            "sbg:category": "Platform options",
            "sbg:toolDefaultValue": "3000",
            "id": "mem_per_job",
            "type": "int?",
            "label": "Memory per job [MB]",
            "doc": "Memory per job [MB]."
          },
          {
            "sbg:category": "Output",
            "id": "output_prefix",
            "type": "string?",
            "label": "Output prefix",
            "doc": "Prefix for output file."
          }
        ],
        "outputs": [
          {
            "id": "out_assembled_transcripts",
            "doc": "GTF file containing assembled transcripts.",
            "label": "Assembled transcripts",
            "type": "File",
            "outputBinding": {
              "glob": "*assembled_transcripts.gtf",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "GTF"
          },
          {
            "id": "out_gene_abundance",
            "doc": "Tab delimited file containing gene abundance level estimation.",
            "label": "Gene abundance estimation",
            "type": "File?",
            "outputBinding": {
              "glob": "*gene_abundance.tab",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "TAB"
          },
          {
            "id": "out_covered_ref_transcripts",
            "doc": "GTF file containing all transcripts in the provided reference file that are fully covered by the reads.",
            "label": "Covered reference transcripts",
            "type": "File?",
            "outputBinding": {
              "glob": "*covered_transcripts.gtf",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "GTF"
          },
          {
            "id": "out_archived_ballgown_input_tables",
            "doc": "Archived file containing all .ctab tables required for differential expression analysis using Ballgown R package.",
            "label": "Archived ballgown input tables",
            "type": "File?",
            "outputBinding": {
              "glob": "*.tar",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "TAR"
          },
          {
            "id": "out_deseq2_gene_count_matrix",
            "doc": "CSV file containing raw counts for genes that can be directly fed to DESeq2 or EdgeR to perform differential expression analysis.",
            "label": "DESeq2 gene count matrix",
            "type": "File?",
            "outputBinding": {
              "glob": "*gene_count_matrix.csv",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "CSV"
          },
          {
            "id": "out_deseq2_transcript_count_matrix",
            "doc": "CSV file containing raw counts for transcripts that can be directly fed to DESeq2 or EdgeR to perform differential expression ananlysis.",
            "label": "DESeq2 transcript count matrix",
            "type": "File?",
            "outputBinding": {
              "glob": "*transcript_count_matrix.csv",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "CSV"
          }
        ],
        "doc": "**StringTie** is a fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional *de novo* assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus. Its input can include not only alignments of short reads that can also be used by other transcript assemblers, but also alignments of longer sequences that have been assembled from those reads.  In order to identify differentially expressed genes between experiments, **StringTie**'s output can be processed by specialized software like **Ballgown**, **Cuffdiff** or other programs (**DESeq2**, **edgeR**, etc.) [1].\n\n*A list of __all inputs and parameters__ with corresponding descriptions can be found at the bottom of this page.*\n\n*__Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.__*\n\n### Common Use Cases\n\n* __StringTie__ can be used as a transcriptome assembler. It takes aligned reads as input (note that the provided BAM file has to be sorted by coordinate) and estimates expression level of genes and transcripts as it assembles them [3]. __Reference annotation file__ (`-G`) can be provided to guide the assembly process, though this is optional. If the ultimate goal is differential expression analysis assembled transcripts for each sample have to be merged into unified set of transcripts for all samples using __StringTie Merge__. After the merging step is done additional run of __StringTie__ is required to re-estimate merged transcripts for each sample using __Keep annotated transcripts only__ (`-e`) option that tells __StringTie__ to estimate expression levels only for reference transcripts and the __Create input files for Ballgown and DESeq2__ (`-B`) option that enables creating count-data input files for __Ballgown__ and __DESeq2__. For more details refer to StringTie protocol paper [3].\n* __StringTie__ can be used just for quantification. For this purpose __Reference annotation file__ (`-G`) has to be provided and the __Keep annotated transcripts only__ (`-e`) parameter should be set to True, telling StringTie to only estimate expression levels of genes and transcripts present in the annotation file. This mode should be used in experiments when there is a predefined list of genes or transcripts of interest or in case of re-estimating merged transcripts as described above.\n* __Text feature file__ input loads a list of point-features to guide the transcriptome assembly. Accepted point features are transcription start sites (TSS) and polyadenylation sites (CPAS). Details on how this file should look like can be found in the input's description info.\n* To output a TAB file in which gene abundance estimation will be reported, set the __Output gene abundance__ (`-A`) parameter to True.\n* To output a file with all transcripts in the provided reference file that are fully covered by the reads, set the __Output covered reference transcripts__ (`-C`) parameter to True. This option requires **Reference annotation file** (`-G`) to be provided.\n\n### Changes Introduced by Seven Bridges\n\n* In order to enable __StringTie__ to produce quantification tables tailored for __DESeq2__ or [EdgeR](http://bioconductor.org/packages/release/bioc/html/edgeR.html), the [`prepDE.py`](https://ccb.jhu.edu/software/stringtie/dl/prepDE.py) python script [2] that extracts raw counts from **Ballgown** input tables is embedded within the app. Parameters of the scripts have default values except names of gene and transcript count matrices. To obtain raw counts suitable for __DESeq2__ set **Create input files for Ballgown and DESeq2** (`-B`) to True. This will also produce __Ballgown__ input tables as these tables are needed for obtaining __DESeq2__ raw counts.\n* __Ballgown__ input tables (5 CTAB files) are outputted as an archive TAR file containing all 5 files. This TAR file can be directly fed to __Ballgown__ without any further modification given the metadata field __Sample ID__ is properly set (check the Common Issues and Important Notes section).\n\n### Common Issues and Important Notes\n\n* If you want to perform differential expression analysis using quantification produced by __StringTie__, make sure that all input BAM files on the **Aligned reads** input have metadata field __Sample ID__ properly set. The value of __Sample ID__ metadata field will be used to match corresponding expression (count) and phenotype data by downstream tools for differential expression (__DESeq2__ and __Ballgown__).\n* All BAM files on the **Aligned reads** input need to be sorted by coordinates.\n\n### Performance Benchmarking\n\nThe execution time for quantification/assembly+quantification for human RNA-Seq data (~ 160M of reads/12GB) takes somewhat less than 15 minutes on the default instance; the price is very low (~ 0.05$). Unless specified otherwise, the default instance used to run the __StringTie__ tool will be c4.xlarge (AWS).\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### References\n\n[1] [StringTie home page](https://ccb.jhu.edu/software/stringtie/index.shtml)\n\n[2] [StringTie manual page - using StringTie with DESeq2 and EdgeR](https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual#deseq)\n\n[3] [HISAT, StringTie, Ballgown protocol paper](http://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html)",
        "label": "StringTie",
        "arguments": [
          {
            "prefix": "-o",
            "shellQuote": false,
            "position": 4,
            "valueFrom": "${\n    var cmd = \"./\" ;\n    \n    if (inputs.output_prefix) { ;\n        var base_file_name = inputs.output_prefix ;\n    } else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n        var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    } else { ;\n        var base_file_name = [].concat(inputs.in_alignments)[0].nameroot ;\n    }\n    cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.assembled_transcripts.gtf\") ;\n    return cmd ;\n} "
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 41,
            "valueFrom": "${\n    if (inputs.ballgown_and_deseq2_preprocessing) { ;\n        if (inputs.output_prefix) { ;\n            var sample_file_name = inputs.output_prefix ;\n      } else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var sample_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n      } else { ;\n            var sample_file_name = [].concat(inputs.in_alignments)[0].nameroot ;\n    }\n    \n        // part of the name corresponding to the sample that is being processed\n        if (inputs.in_alignments.metadata && inputs.in_alignments.metadata.sample_id) { ;\n            var sample_identifier = inputs.in_alignments.metadata.sample_id\n        } else { ;\n            sample_identifier = sample_file_name ;\n        }\n\n        var archive_name = sample_file_name.concat(\".StringTie.2.1.3.ballgown_input_tables.tar\")\n\n\n        return \"&& mkdir ballgown && mkdir ballgown/\".concat(sample_identifier, \" && mkdir \", sample_identifier, \" && mv *.ctab ballgown/\", sample_identifier, \" && cp *assembled_transcripts.gtf ballgown/\", sample_identifier, \" && python prepDE.py --input=ballgown -g \", sample_file_name, \".StringTie.2.1.3.gene_count_matrix.csv -t \", sample_file_name, \".StringTie.2.1.3.transcript_count_matrix.csv && mv ballgown/\", sample_identifier, \"/*.ctab \", sample_identifier, \" && (tar cf \", archive_name, \" \", sample_identifier, \" --warning=no-file-changed || [ $? -eq 1 ]) \") ;\n\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${ \n    if (inputs.mem_per_job) { ;\n        return inputs.mem_per_job ;\n}\n    else if (inputs.num_of_threads && inputs.num_of_threads > 0) { ;\n        return inputs.num_of_threads * 1500 ;\n}  \n    else { ;\n        return 3000 ;\n    } ;\n\n}\n\n",
            "coresMin": "${\n    if (inputs.num_of_threads && inputs.num_of_threads > 0) { ;\n        return inputs.num_of_threads ;\n        \n  } else { ;\n        return 2 ;\n    };\n\n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/nevena_vukojicic/stringtie:2.1.3"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              {
                "entryname": "prepDE.py",
                "entry": "#!/usr/bin/env python2\nimport re, csv, sys, os, glob, warnings, itertools\nfrom math import ceil\nfrom optparse import OptionParser\nfrom operator import itemgetter\n#note that the gtf files in the sample folders have same # of lines, just different order(?)\n\nparser=OptionParser(description='Generates two CSV files containing the count matrices for genes and transcripts, using the coverage values found in the output of `stringtie -e`')\nparser.add_option('-i', '--input', '--in', default='ballgown', help=\"the parent directory of the sample sub-directories or a textfile listing the paths to GTF files [default: %default]\")\nparser.add_option('-g', default='gene_count_matrix.csv', help=\"where to output the gene count matrix [default: %default\")\nparser.add_option('-t', default='transcript_count_matrix.csv', help=\"where to output the transcript count matrix [default: %default]\")\nparser.add_option('-l', '--length', default=75, type='int', help=\"the average read length [default: %default]\")\nparser.add_option('-p', '--pattern', default=\".\", help=\"a regular expression that selects the sample subdirectories\")\nparser.add_option('-c', '--cluster', action=\"store_true\", help=\"whether to cluster genes that overlap with different gene IDs, ignoring ones with geneID pattern (see below)\")\nparser.add_option('-s', '--string', default=\"MSTRG\", help=\"if a different prefix is used for geneIDs assigned by StringTie [default: %default]\")\nparser.add_option('-k', '--key', default=\"prepG\", help=\"if clustering, what prefix to use for geneIDs assigned by this script [default: %default]\")\nparser.add_option('--legend', default=\"legend.csv\", help=\"if clustering, where to output the legend file mapping transcripts to assigned geneIDs [default: %default]\")\n(opts, args)=parser.parse_args()\n\nsamples = [] # List of tuples. If sample list, (first column, path). Else, (subdirectory name, path to gtf file in subdirectory)\nif (os.path.isfile(opts.input)):\n    # gtfList = True\n    try:\n        fin = open(opts.input, 'r')\n        for line in fin:\n            if line[0] != '#':\n                lineLst = tuple(line.strip().split())\n                if (len(lineLst) != 2):\n                    print \"Error: Text file with sample ID and path invalid (%s)\" % (line.strip())\n                    exit(1)\n                if lineLst[0] in samples:\n                    print \"Error: Sample ID duplicated (%s)\" % (lineLst[0])\n                    exit(1)\n                if not os.path.isfile(lineLst[1]):\n                    print \"Error: GTF file not found (%s)\" % (lineLst[1])\n                    exit(1)\n                samples.append(lineLst)\n    except IOError:\n        print \"Error: List of .gtf files, %s, doesn't exist\" % (opts.input)\n        exit(1)\nelse:\n    # gtfList = False\n    ## Check that opts.input directory exists\n    if not os.path.isdir(opts.input):\n      parser.print_help()\n      print \" \"\n      print \"Error: sub-directory '%s' not found!\" % (opts.input)\n      sys.exit(1)\n\n    #####\n    ## Collect all samples file paths and if empty print help message and quit\n    #####\n    samples = [(i,glob.iglob(os.path.join(opts.input,i,\"*.gtf\")).next()) for i in next(os.walk(opts.input))[1] if re.search(opts.pattern,i)]\n\nif len(samples) == 0:\n  parser.print_help()\n  print \" \"\n  print \"Error: no GTF files found under ./%s !\" % (opts.input)\n  sys.exit(1)\n\nRE_GENE_ID=re.compile('gene_id \"([^\"]+)\"')\nRE_GENE_NAME=re.compile('gene_name \"([^\"]+)\"')\nRE_TRANSCRIPT_ID=re.compile('transcript_id \"([^\"]+)\"')\nRE_COVERAGE=re.compile('cov \"([\\-\\+\\d\\.]+)\"')\nRE_STRING=re.compile(re.escape(opts.string))\n\n#####\n## Sort the sample names by the sample ID\n#####\nsamples.sort()\n\n#####\n## Checks whether a given row is a transcript \n## other options: ex. exon, transcript, mRNA, 5'UTR\n#####\ndef is_transcript(x):\n  return len(x)>2 and x[2]==\"transcript\"\n\ndef getGeneID(s, ctg, tid):\n  r=RE_GENE_ID.search(s)\n  if r: return r.group(1)\n  r=RE_GENE_NAME.search(s)\n  if r: return ctg+'|'+r.group(1)\n  return tid\n\ndef getCov(s):\n  r=RE_COVERAGE.search(s)\n  if r:\n    v=float(r.group(1))\n    if v<0.0: v=0.0\n    return v\n  return 0.0\n\ndef is_overlap(x,y): #NEEDS TO BE INTS!\n  return x[0]<=y[1] and y[0]<=x[1]\n\n\ndef t_overlap(t1, t2): #from badGenes: chromosome, strand, cluster, start, end, (e1start, e1end)...\n    if t1[0] != t2[0] or t1[1] != t2[1] or t1[5]<t2[4]: return False\n    for i in range(6, len(t1)):\n        for j in range(6, len(t2)):\n            if is_overlap(t1[i], t2[j]): return True\n    return False\n\n## Average Readlength\nread_len=opts.length\n\n## Variables/Matrices to store t/g_counts\nt_count_matrix, g_count_matrix=[],[]\n\n##Get ready for clustering, stuff is once for all samples##\ngeneIDs={} #key=transcript, value=cluster/gene_id\n\n\n## For each of the sorted sample paths\nfor s in samples:\n    badGenes=[] #list of bad genes (just ones that aren't MSTRG)\n    try:\n        ## opts.input = parent directory of sample subdirectories\n        ## s = sample currently iterating through\n        ## os.path.join(opts.input,s,\"*.gtf\") path to current sample's GTF\n        ## split = list of lists: [[chromosome, ...],...]\n\n        #with open(glob.iglob(os.path.join(opts.input,s,\"*.gtf\")).next()) as f:\n        #    split=[l.split('\\t') for l in f.readlines()]\n#        if not gtfList:\n#            f = open(glob.iglob(os.path.join(opts.input,s[1],\"*.gtf\")).next())\n#        else:\n#            f = open(s[1])\n        with open(s[1]) as f:\n            split=[l.split('\\t') for l in f.readlines()]\n\n        ## i = numLine; v = corresponding i-th GTF row\n        for i,v in enumerate(split):\n            if is_transcript(v):\n                t_id=RE_TRANSCRIPT_ID.search(v[len(v)-1]).group(1)\n                try:\n                  g_id=getGeneID(v[len(v)-1], v[0], t_id)\n                except:\n                  print \"Problem at line:\\n:%s\\n\" % (v)\n                  print \"i='%s', len(v)=%s\" % (i, len(v));\n                  sys.exit(1)\n                geneIDs.setdefault(t_id, g_id)\n                if not RE_STRING.match(g_id):\n                    badGenes.append([v[0],v[6], t_id, g_id, min(int(v[3]),int(v[4])), max(int(v[3]),int(v[4]))]) #chromosome, strand, cluster/transcript id, start, end\n                    j=i+1\n                    while j<len(split) and split[j][2]==\"exon\":\n                        badGenes[len(badGenes)-1].append((min(int(split[j][3]), int(split[j][4])), max(int(split[j][3]), int(split[j][4]))))\n                        j+=1\n\n    except StopIteration:\n        warnings.warn(\"Didn't get a GTF in that directory. Looking in another...\")\n\n    else: #we found the \"bad\" genes!\n        break\n\n##THE CLUSTERING BEGINS!##\nif opts.cluster and len(badGenes)>0:\n    clusters=[] #lists of lists (could be sets) or something of transcripts\n    badGenes.sort(key=itemgetter(3)) #sort by start coord...?\n    i=0\n    while i<len(badGenes): #rather un-pythonic\n        temp_cluster=[badGenes[i]]\n\n        k=0\n        while k<len(temp_cluster):\n            j=i+1\n            while j<len(badGenes):\n                if t_overlap(temp_cluster[k], badGenes[j]):\n                    temp_cluster.append(badGenes[j])\n                    del badGenes[j]\n                else:\n                    j+=1\n            k+=1\n        if len(temp_cluster)>1:\n            clusters.append([t[2] for t in temp_cluster])\n        i+=1\n\n    print len(clusters)\n\n    for c in clusters:\n        c.sort()\n\n    clusters.sort(key=itemgetter(0))\n    legend=[]\n    for u,c in enumerate(clusters):\n        my_ID=opts.key+str((u+1))\n        legend.append(list(itertools.chain.from_iterable([[my_ID],c]))) #my_ID, clustered transcript IDs\n        for t in c:\n            geneIDs[t]=my_ID\n##            geneIDs[t]=\"|\".join(c) #duct-tape transcript IDs together, disregarding ref_gene_names and things like that\n\n    with open(opts.legend, 'w') as l_file:\n        my_writer=csv.writer(l_file)\n        my_writer.writerows(legend)\n\ngeneDict={} #key=gene/cluster, value=dictionary with key=sample, value=summed counts\nt_dict={}\nfor q, s in enumerate(samples):\n    print q, s[0]\n\n    try:\n        #with open(glob.iglob(os.path.join(opts.input,s,\"*.gtf\")).next()) as f: #grabs first .gtf file it finds inside the sample subdirectory\n#        if not gtfList:\n#            f = open(glob.iglob(os.path.join(opts.input,s[1],\"*.gtf\")).next())\n#        else:\n        f = open(s[1])\n        \n            # s = s.split('/')[len(s.split('/')) - 1].split('.gtf')[0].split('_')[0]\n            # s = sample_IDs[q]\n\n##        split=[t[:len(t)-1]+t[len(t)-1].split(\";\") for t in split]\n##        split=[t[:len(t)-1] for t in split] #eliminate '\\n' at end\n##        split=[[e.lstrip() for e in t] for t in split]\n        #should consider making stuff into dictionaries, maybe each split line\n\n##            transcriptList=[]\n        transcript_len=0\n        for l in f:\n            if l.startswith(\"#\"):\n                continue\n            v=l.split('\\t')\n            if v[2]==\"transcript\":\n                if transcript_len>0:\n##                        transcriptList.append((g_id, t_id, int(ceil(coverage*transcript_len/read_len))))\n                    t_dict.setdefault(t_id, {})\n                    t_dict[t_id].setdefault(s[0], int(ceil(coverage*transcript_len/read_len)))\n                t_id=RE_TRANSCRIPT_ID.search(v[len(v)-1]).group(1)\n                #g_id=RE_GENE_ID.search(v[len(v)-1]).group(1)\n                g_id=getGeneID(v[len(v)-1], v[0], t_id)\n                #coverage=float(RE_COVERAGE.search(v[len(v)-1]).group(1))\n                coverage=getCov(v[len(v)-1])\n                transcript_len=0\n            if v[2]==\"exon\":\n                transcript_len+=int(v[4])-int(v[3])+1 #because end coordinates are inclusive in GTF\n\n##            transcriptList.append((g_id, t_id, int(ceil(coverage*transcript_len/read_len))))\n        t_dict.setdefault(t_id, {})\n        t_dict[t_id].setdefault(s[0], int(ceil(coverage*transcript_len/read_len)))\n\n    except StopIteration:\n#        if not gtfList:\n#            warnings.warn(\"No GTF file found in \" + os.path.join(opts.input,s[1]))\n#        else:\n        warnings.warn(\"No GTF file found in \" + s[1])\n\n\n##        transcriptList.sort(key=lambda bla: bla[1]) #gene_id\n\n    for i,v in t_dict.iteritems():\n##        print i,v\n        geneDict.setdefault(geneIDs[i],{}) #gene_id\n        geneDict[geneIDs[i]].setdefault(s[0],0)\n        geneDict[geneIDs[i]][s[0]]+=v[s[0]]\n\n\nwith open(opts.t, 'w') as csvfile:\n    my_writer = csv.DictWriter(csvfile, fieldnames = [\"transcript_id\"] + [x for x,y in samples])\n    my_writer.writerow(dict((fn,fn) for fn in my_writer.fieldnames))\n    for i in t_dict:\n        t_dict[i][\"transcript_id\"] = i\n        my_writer.writerow(t_dict[i])\n\nwith open(opts.g, 'w') as csvfile:\n    my_writer = csv.DictWriter(csvfile, fieldnames = [\"gene_id\"] + [x for x,y in samples])\n##    my_writer.writerow([\"\"]+samples)\n##    my_writer.writerows(geneDict)\n    my_writer.writerow(dict((fn,fn) for fn in my_writer.fieldnames))\n    for i in geneDict:\n        geneDict[i][\"gene_id\"] = i #add gene_id to row\n        my_writer.writerow(geneDict[i])",
                "writable": false
              }
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "hints": [
          {
            "class": "sbg:AWSInstanceType",
            "value": "c4.xlarge;ebs-gp2;128"
          },
          {
            "class": "sbg:GoogleInstanceType",
            "value": "n1-highcpu-8;pd-ssd;128"
          },
          {
            "class": "sbg:AzureInstanceType",
            "value": "Standard_F4s_v2;StandardSSD;120"
          }
        ],
        "sbg:categories": [
          "Quantification",
          "RNA-Seq"
        ],
        "sbg:image_url": null,
        "sbg:toolkitVersion": "2.1.3",
        "sbg:license": "Artistic License 2.0",
        "sbg:links": [
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml#contact",
            "label": "Homepage"
          },
          {
            "id": "https://github.com/gpertea/stringtie",
            "label": "Source Code"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/dl/stringtie-2.1.3b.Linux_x86_64.tar.gz",
            "label": "Download"
          },
          {
            "id": "https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1910-1",
            "label": "Publications"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
            "label": "Documentation"
          }
        ],
        "sbg:toolkit": "StringTie",
        "sbg:toolAuthor": "Johns Hopkins University, Center for Computational Biology",
        "sbg:projectName": "StringTie 2.1.3 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597776801,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777452,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777509,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598955611,
            "sbg:revisionNotes": "tar warning ignore added"
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1599829953,
            "sbg:revisionNotes": "description updated"
          },
          {
            "sbg:revision": 5,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1612179274,
            "sbg:revisionNotes": "description changed"
          },
          {
            "sbg:revision": 6,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1621608814,
            "sbg:revisionNotes": "hints added for Azure and Google"
          },
          {
            "sbg:revision": 7,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1645535926,
            "sbg:revisionNotes": "categories changed"
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-be66e15c/h-43cc6305/h-d905a4c3/0",
        "sbg:revision": 7,
        "sbg:revisionNotes": "categories changed",
        "sbg:modifiedOn": 1645535926,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1597776801,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "nevena_vukojicic/stringtie-2-1-3-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 7,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "aa094252ea5e6988cfbcc1472b7d955b33ddf709ad32843ad71982687b92128e1",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "StringTie",
      "scatter": [
        "in_alignments"
      ],
      "sbg:x": 163.9895477294922,
      "sbg:y": -56.39857864379883
    },
    {
      "id": "stringtie_2_1_4",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "sbg_file_selector_2/out"
        },
        {
          "id": "gene_abundance",
          "default": true
        },
        {
          "id": "ballgown_and_deseq2_preprocessing",
          "default": true
        },
        {
          "id": "keep_annotated_transcripts",
          "default": true
        },
        {
          "id": "in_alignments",
          "source": "hisat2_2_2_1/out_alignment"
        }
      ],
      "out": [
        {
          "id": "out_assembled_transcripts"
        },
        {
          "id": "out_gene_abundance"
        },
        {
          "id": "out_covered_ref_transcripts"
        },
        {
          "id": "out_archived_ballgown_input_tables"
        },
        {
          "id": "out_deseq2_gene_count_matrix"
        },
        {
          "id": "out_deseq2_transcript_count_matrix"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "nevena_vukojicic/stringtie-2-1-3-demo/stringtie-2-1-3/7",
        "baseCommand": [
          "/opt/stringtie-2.1.3b.Linux_x86_64/stringtie"
        ],
        "inputs": [
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "2",
            "id": "num_of_threads",
            "type": "int?",
            "inputBinding": {
              "prefix": "-p",
              "shellQuote": false,
              "position": 6,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.num_of_threads = null ;\n    };\n\n\n    if (inputs.num_of_threads) { ;\n        return inputs.num_of_threads ;\n    } else { ;\n        return 2 ;\n    } ;\n\n}"
            },
            "label": "Number of threads",
            "doc": "Specify the number of processing threads (CPUs) to use for transcript assembly.",
            "default": 0
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_gene_annotation",
            "type": "File?",
            "inputBinding": {
              "prefix": "-G",
              "shellQuote": false,
              "position": 7
            },
            "label": "Reference annotation file",
            "doc": "Use the reference annotation file (in GTF or GFF3 format) to guide the assembly process. The output will include expressed reference transcripts as well as any novel transcripts that are assembled.",
            "sbg:fileTypes": "GTF, GFF3"
          },
          {
            "sbg:toolDefaultValue": "STRG",
            "sbg:category": "Execution",
            "id": "transcripts_name_prefix",
            "type": "string?",
            "inputBinding": {
              "prefix": "-l",
              "shellQuote": false,
              "position": 8
            },
            "label": "Transcripts name prefix",
            "doc": "Sets the prefix for the name of the output transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0.01",
            "id": "minimum_isoform_abundance",
            "type": "float?",
            "inputBinding": {
              "prefix": "-f",
              "shellQuote": false,
              "position": 9
            },
            "label": "Minimum isoform abundance",
            "doc": "Sets the minimum isoform abundance of the predicted transcripts as a fraction of the most abundant transcript assembled at a given locus. Lower abundance transcripts are often artifacts of incompletely spliced precursors of processed transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "200",
            "id": "minimum_length",
            "type": "int?",
            "inputBinding": {
              "prefix": "-m",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum isoform length",
            "doc": "Sets the minimum length allowed for the predicted transcripts."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "gene_abundance",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-A",
              "shellQuote": false,
              "position": 21,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.gene_abundance = null ;\n    };\n\n\n    if (inputs.gene_abundance) { ;\n        var cmd = \"./\" ;\n        if (inputs.output_prefix) { ;\n            var base_file_name = inputs.output_prefix ;\n    }   else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    }   else { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].nameroot\n    };\n        cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.gene_abundance.tab\") ;\n    return cmd ;\n    };\n}"
            },
            "label": "Output gene abundance",
            "doc": "Tells StringTie to output a file (tab delimited format) in which gene abundance estimation will be reported.",
            "default": 0
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "covered_ref_transcripts",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-C",
              "shellQuote": false,
              "position": 22,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.covered_ref_transcripts = null ;\n    };\n\n\n    if (inputs.covered_ref_transcripts) { ;\n        var cmd = \"./\" ;\n        if (inputs.output_prefix) { ; \n            var base_file_name = inputs.output_prefix ;\n    }   else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    }   else { ;\n            var base_file_name = [].concat(inputs.in_alignments)[0].nameroot\n    };\n        cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.covered_transcripts.gtf\") ;\n        return cmd ;\n    };\n}"
            },
            "label": "Output covered reference transcripts",
            "doc": "Tell StringTie to output a file with all transcripts in the provided reference file that are fully covered by the reads. This option requires reference annotation file to be provided.",
            "default": 0
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "junction_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-j",
              "shellQuote": false,
              "position": 13
            },
            "label": "Minimum junction coverage",
            "doc": "There should be at least this many spliced reads that align across a junction (i.e. junction coverage). This number can be fractional, since some reads align in more than one place. A read that aligns in n places will contribute 1/n to the junction coverage."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "disable_trimming",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-t",
              "shellQuote": false,
              "position": 18
            },
            "label": "Disable trimming",
            "doc": "This parameter disables trimming at the ends of the assembled transcripts. By default StringTie adjusts the predicted transcript's start and/or stop coordinates based on sudden drops in coverage of the assembled transcript."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "minimum_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-c",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum read coverage",
            "doc": "Sets the minimum read coverage allowed for the predicted transcripts. A transcript with a lower coverage than this value is not shown in the output."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "50",
            "id": "minimum_locus_gap",
            "type": "int?",
            "inputBinding": {
              "prefix": "-g",
              "shellQuote": false,
              "position": 16
            },
            "label": "Minimum locus gap separation value",
            "doc": "Reads that are mapped closer than this distance (distance is measured in bp) are merged together in the same processing bundle."
          },
          {
            "sbg:category": "Execution",
            "id": "ballgown_and_deseq2_preprocessing",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-B",
              "shellQuote": false,
              "position": 31
            },
            "label": "Create input files for Ballgown and DESeq2",
            "doc": "This switch enables the output of Ballgown input table files (*.ctab) containing coverage data for the reference transcripts given with the -G option. With this option StringTie can be used as a direct replacement of the tablemaker program included with the Ballgown distribution. In addition to Ballgown input tables count matrix for DESeq2 will be also created."
          },
          {
            "sbg:category": "Execution",
            "id": "keep_annotated_transcripts",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-e",
              "shellQuote": false,
              "position": 26
            },
            "label": "Keep annotated transcripts only",
            "doc": "Limits the processing of read alignments to only estimate and output the assembled transcripts matching the reference transcripts given in the reference annotation file. With this option, read bundles with no reference transcripts will be entirely skipped, which may provide a considerable speed boost when the given set of reference transcripts is limited to a set of target genes, for example."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0.95",
            "id": "multiply_mapped_reads",
            "type": "float?",
            "inputBinding": {
              "prefix": "-M",
              "shellQuote": false,
              "position": 17
            },
            "label": "Maximum fraction of multiply mapped reads",
            "doc": "Sets the maximum fraction of multiple-location-mapped reads that are allowed to be present at a given locus."
          },
          {
            "sbg:category": "Execution",
            "id": "seqid_list",
            "type": "string?",
            "inputBinding": {
              "prefix": "-x",
              "shellQuote": false,
              "position": 27
            },
            "label": "Ignore alignments on the specified sequence",
            "doc": "Ignore all read alignments (and thus do not attempt to perform transcript assembly) on the specified reference sequences. Parameter <seqid_list> can be a single reference sequence name (e.g. -x chrM) or a comma-delimited list of sequence names (e.g. -x 'chrM,chrX,chrY'). The reference sequence names are case sensitive, they must match identically the names of chromosomes/contigs of the target genome against which the RNA-Seq reads were aligned in the first place."
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_alignments",
            "type": "File",
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Aligned reads",
            "doc": "Aligned reads in binary SAM (BAM) format sorted by coordinate.",
            "sbg:fileTypes": "BAM"
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "10",
            "id": "anchor_length_for_junctions",
            "type": "int?",
            "inputBinding": {
              "prefix": "-a",
              "shellQuote": false,
              "position": 12
            },
            "label": "Minimum anchor length for junctions",
            "doc": "Junctions that don't have spliced reads that align across them with at least this amount of bases on both sides are filtered out."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "firststrand",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--rf",
              "shellQuote": false,
              "position": 10
            },
            "label": "Stranded library - firststrand",
            "doc": "Assumes a stranded library fr-firststrand."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "secondstrand",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--fr",
              "shellQuote": false,
              "position": 10
            },
            "label": "Stranded library - secondstrand",
            "doc": "Assumes a stranded library fr-secondstrand."
          },
          {
            "sbg:category": "File Inputs",
            "id": "in_feature_file",
            "type": "File?",
            "inputBinding": {
              "prefix": "--ptf",
              "shellQuote": false,
              "position": 10
            },
            "label": "Text feature file",
            "doc": "Loads a list of point-features from a text feature file <f_tab> to guide the transcriptome assembly. Accepted point features are transcription start sites (TSS) and polyadenylation sites (CPAS). There are four tab-delimited columns in the feature file. The first three define the location of the point feature on the cromosome (sequence name, coordinate and strand), and the last is the type of the feature (TSS or CPAS). For instance:\nchrI\t35608\t-\tTSS\nchrI\t1634\t+\tCPAS\nare two examples for potential lines in the feature file.",
            "sbg:fileTypes": "TAB"
          },
          {
            "sbg:toolDefaultValue": "4.75",
            "sbg:category": "Execution",
            "id": "minimum_single_exon_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-s",
              "shellQuote": false,
              "position": 11
            },
            "label": "Minimum coverage for single-exon transcripts",
            "doc": "Sets the minimum read coverage allowed for single-exon transcripts."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "conservative_mode",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--conservative",
              "shellQuote": false,
              "position": 11
            },
            "label": "Conservative mode",
            "doc": "Assembles transcripts in a conservative mode. Same as -t -c 1.5 -f 0.05"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "multi_mapping_correction",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-u",
              "shellQuote": false,
              "position": 30
            },
            "label": "Multi-mapping correction",
            "doc": "Turn off multi-mapping correction. In the default case this correction is enabled, and each read that is mapped in n places only contributes 1/n to the transcript coverage instead of 1."
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "long_reads",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-L",
              "shellQuote": false,
              "position": 20
            },
            "label": "Long reads processing",
            "doc": "Long reads processing; also enforces -s 1.5 -g 0"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "long_reads_alternative",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-R",
              "shellQuote": false,
              "position": 20
            },
            "label": "-L alternative",
            "doc": "Outputs unassembled, cleaned, and non-redundant long read alignments (collapsing similar long reads alignments at the same location)."
          },
          {
            "sbg:toolDefaultValue": "25",
            "sbg:category": "Execution",
            "id": "splice_sites_window",
            "type": "int?",
            "inputBinding": {
              "prefix": "-E",
              "shellQuote": false,
              "position": 20
            },
            "label": "Long reads splice sites window",
            "doc": "Define window around possibly erroneous splice sites from long reads to look out for correct splice sites"
          },
          {
            "sbg:toolDefaultValue": "False",
            "sbg:category": "Execution",
            "id": "viral_data",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--viral",
              "shellQuote": false,
              "position": 20
            },
            "label": "Viral long reads",
            "doc": "Only relevant for long reads from viral data where splice sites do not follow consensus"
          },
          {
            "sbg:category": "Platform options",
            "sbg:toolDefaultValue": "3000",
            "id": "mem_per_job",
            "type": "int?",
            "label": "Memory per job [MB]",
            "doc": "Memory per job [MB]."
          },
          {
            "sbg:category": "Output",
            "id": "output_prefix",
            "type": "string?",
            "label": "Output prefix",
            "doc": "Prefix for output file."
          }
        ],
        "outputs": [
          {
            "id": "out_assembled_transcripts",
            "doc": "GTF file containing assembled transcripts.",
            "label": "Assembled transcripts",
            "type": "File",
            "outputBinding": {
              "glob": "*assembled_transcripts.gtf",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "GTF"
          },
          {
            "id": "out_gene_abundance",
            "doc": "Tab delimited file containing gene abundance level estimation.",
            "label": "Gene abundance estimation",
            "type": "File?",
            "outputBinding": {
              "glob": "*gene_abundance.tab",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "TAB"
          },
          {
            "id": "out_covered_ref_transcripts",
            "doc": "GTF file containing all transcripts in the provided reference file that are fully covered by the reads.",
            "label": "Covered reference transcripts",
            "type": "File?",
            "outputBinding": {
              "glob": "*covered_transcripts.gtf",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "GTF"
          },
          {
            "id": "out_archived_ballgown_input_tables",
            "doc": "Archived file containing all .ctab tables required for differential expression analysis using Ballgown R package.",
            "label": "Archived ballgown input tables",
            "type": "File?",
            "outputBinding": {
              "glob": "*.tar",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "TAR"
          },
          {
            "id": "out_deseq2_gene_count_matrix",
            "doc": "CSV file containing raw counts for genes that can be directly fed to DESeq2 or EdgeR to perform differential expression analysis.",
            "label": "DESeq2 gene count matrix",
            "type": "File?",
            "outputBinding": {
              "glob": "*gene_count_matrix.csv",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "CSV"
          },
          {
            "id": "out_deseq2_transcript_count_matrix",
            "doc": "CSV file containing raw counts for transcripts that can be directly fed to DESeq2 or EdgeR to perform differential expression ananlysis.",
            "label": "DESeq2 transcript count matrix",
            "type": "File?",
            "outputBinding": {
              "glob": "*transcript_count_matrix.csv",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_alignments) ;\n\n}"
            },
            "sbg:fileTypes": "CSV"
          }
        ],
        "doc": "**StringTie** is a fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional *de novo* assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus. Its input can include not only alignments of short reads that can also be used by other transcript assemblers, but also alignments of longer sequences that have been assembled from those reads.  In order to identify differentially expressed genes between experiments, **StringTie**'s output can be processed by specialized software like **Ballgown**, **Cuffdiff** or other programs (**DESeq2**, **edgeR**, etc.) [1].\n\n*A list of __all inputs and parameters__ with corresponding descriptions can be found at the bottom of this page.*\n\n*__Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.__*\n\n### Common Use Cases\n\n* __StringTie__ can be used as a transcriptome assembler. It takes aligned reads as input (note that the provided BAM file has to be sorted by coordinate) and estimates expression level of genes and transcripts as it assembles them [3]. __Reference annotation file__ (`-G`) can be provided to guide the assembly process, though this is optional. If the ultimate goal is differential expression analysis assembled transcripts for each sample have to be merged into unified set of transcripts for all samples using __StringTie Merge__. After the merging step is done additional run of __StringTie__ is required to re-estimate merged transcripts for each sample using __Keep annotated transcripts only__ (`-e`) option that tells __StringTie__ to estimate expression levels only for reference transcripts and the __Create input files for Ballgown and DESeq2__ (`-B`) option that enables creating count-data input files for __Ballgown__ and __DESeq2__. For more details refer to StringTie protocol paper [3].\n* __StringTie__ can be used just for quantification. For this purpose __Reference annotation file__ (`-G`) has to be provided and the __Keep annotated transcripts only__ (`-e`) parameter should be set to True, telling StringTie to only estimate expression levels of genes and transcripts present in the annotation file. This mode should be used in experiments when there is a predefined list of genes or transcripts of interest or in case of re-estimating merged transcripts as described above.\n* __Text feature file__ input loads a list of point-features to guide the transcriptome assembly. Accepted point features are transcription start sites (TSS) and polyadenylation sites (CPAS). Details on how this file should look like can be found in the input's description info.\n* To output a TAB file in which gene abundance estimation will be reported, set the __Output gene abundance__ (`-A`) parameter to True.\n* To output a file with all transcripts in the provided reference file that are fully covered by the reads, set the __Output covered reference transcripts__ (`-C`) parameter to True. This option requires **Reference annotation file** (`-G`) to be provided.\n\n### Changes Introduced by Seven Bridges\n\n* In order to enable __StringTie__ to produce quantification tables tailored for __DESeq2__ or [EdgeR](http://bioconductor.org/packages/release/bioc/html/edgeR.html), the [`prepDE.py`](https://ccb.jhu.edu/software/stringtie/dl/prepDE.py) python script [2] that extracts raw counts from **Ballgown** input tables is embedded within the app. Parameters of the scripts have default values except names of gene and transcript count matrices. To obtain raw counts suitable for __DESeq2__ set **Create input files for Ballgown and DESeq2** (`-B`) to True. This will also produce __Ballgown__ input tables as these tables are needed for obtaining __DESeq2__ raw counts.\n* __Ballgown__ input tables (5 CTAB files) are outputted as an archive TAR file containing all 5 files. This TAR file can be directly fed to __Ballgown__ without any further modification given the metadata field __Sample ID__ is properly set (check the Common Issues and Important Notes section).\n\n### Common Issues and Important Notes\n\n* If you want to perform differential expression analysis using quantification produced by __StringTie__, make sure that all input BAM files on the **Aligned reads** input have metadata field __Sample ID__ properly set. The value of __Sample ID__ metadata field will be used to match corresponding expression (count) and phenotype data by downstream tools for differential expression (__DESeq2__ and __Ballgown__).\n* All BAM files on the **Aligned reads** input need to be sorted by coordinates.\n\n### Performance Benchmarking\n\nThe execution time for quantification/assembly+quantification for human RNA-Seq data (~ 160M of reads/12GB) takes somewhat less than 15 minutes on the default instance; the price is very low (~ 0.05$). Unless specified otherwise, the default instance used to run the __StringTie__ tool will be c4.xlarge (AWS).\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### References\n\n[1] [StringTie home page](https://ccb.jhu.edu/software/stringtie/index.shtml)\n\n[2] [StringTie manual page - using StringTie with DESeq2 and EdgeR](https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual#deseq)\n\n[3] [HISAT, StringTie, Ballgown protocol paper](http://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html)",
        "label": "StringTie",
        "arguments": [
          {
            "prefix": "-o",
            "shellQuote": false,
            "position": 4,
            "valueFrom": "${\n    var cmd = \"./\" ;\n    \n    if (inputs.output_prefix) { ;\n        var base_file_name = inputs.output_prefix ;\n    } else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n        var base_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n    } else { ;\n        var base_file_name = [].concat(inputs.in_alignments)[0].nameroot ;\n    }\n    cmd = cmd.concat(base_file_name, \".StringTie.2.1.3.assembled_transcripts.gtf\") ;\n    return cmd ;\n} "
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 41,
            "valueFrom": "${\n    if (inputs.ballgown_and_deseq2_preprocessing) { ;\n        if (inputs.output_prefix) { ;\n            var sample_file_name = inputs.output_prefix ;\n      } else if ([].concat(inputs.in_alignments)[0].metadata && [].concat(inputs.in_alignments)[0].metadata.sample_id) { ;\n            var sample_file_name = [].concat(inputs.in_alignments)[0].metadata.sample_id ;\n      } else { ;\n            var sample_file_name = [].concat(inputs.in_alignments)[0].nameroot ;\n    }\n    \n        // part of the name corresponding to the sample that is being processed\n        if (inputs.in_alignments.metadata && inputs.in_alignments.metadata.sample_id) { ;\n            var sample_identifier = inputs.in_alignments.metadata.sample_id\n        } else { ;\n            sample_identifier = sample_file_name ;\n        }\n\n        var archive_name = sample_file_name.concat(\".StringTie.2.1.3.ballgown_input_tables.tar\")\n\n\n        return \"&& mkdir ballgown && mkdir ballgown/\".concat(sample_identifier, \" && mkdir \", sample_identifier, \" && mv *.ctab ballgown/\", sample_identifier, \" && cp *assembled_transcripts.gtf ballgown/\", sample_identifier, \" && python prepDE.py --input=ballgown -g \", sample_file_name, \".StringTie.2.1.3.gene_count_matrix.csv -t \", sample_file_name, \".StringTie.2.1.3.transcript_count_matrix.csv && mv ballgown/\", sample_identifier, \"/*.ctab \", sample_identifier, \" && (tar cf \", archive_name, \" \", sample_identifier, \" --warning=no-file-changed || [ $? -eq 1 ]) \") ;\n\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${ \n    if (inputs.mem_per_job) { ;\n        return inputs.mem_per_job ;\n}\n    else if (inputs.num_of_threads && inputs.num_of_threads > 0) { ;\n        return inputs.num_of_threads * 1500 ;\n}  \n    else { ;\n        return 3000 ;\n    } ;\n\n}\n\n",
            "coresMin": "${\n    if (inputs.num_of_threads && inputs.num_of_threads > 0) { ;\n        return inputs.num_of_threads ;\n        \n  } else { ;\n        return 2 ;\n    };\n\n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/nevena_vukojicic/stringtie:2.1.3"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              {
                "entryname": "prepDE.py",
                "entry": "#!/usr/bin/env python2\nimport re, csv, sys, os, glob, warnings, itertools\nfrom math import ceil\nfrom optparse import OptionParser\nfrom operator import itemgetter\n#note that the gtf files in the sample folders have same # of lines, just different order(?)\n\nparser=OptionParser(description='Generates two CSV files containing the count matrices for genes and transcripts, using the coverage values found in the output of `stringtie -e`')\nparser.add_option('-i', '--input', '--in', default='ballgown', help=\"the parent directory of the sample sub-directories or a textfile listing the paths to GTF files [default: %default]\")\nparser.add_option('-g', default='gene_count_matrix.csv', help=\"where to output the gene count matrix [default: %default\")\nparser.add_option('-t', default='transcript_count_matrix.csv', help=\"where to output the transcript count matrix [default: %default]\")\nparser.add_option('-l', '--length', default=75, type='int', help=\"the average read length [default: %default]\")\nparser.add_option('-p', '--pattern', default=\".\", help=\"a regular expression that selects the sample subdirectories\")\nparser.add_option('-c', '--cluster', action=\"store_true\", help=\"whether to cluster genes that overlap with different gene IDs, ignoring ones with geneID pattern (see below)\")\nparser.add_option('-s', '--string', default=\"MSTRG\", help=\"if a different prefix is used for geneIDs assigned by StringTie [default: %default]\")\nparser.add_option('-k', '--key', default=\"prepG\", help=\"if clustering, what prefix to use for geneIDs assigned by this script [default: %default]\")\nparser.add_option('--legend', default=\"legend.csv\", help=\"if clustering, where to output the legend file mapping transcripts to assigned geneIDs [default: %default]\")\n(opts, args)=parser.parse_args()\n\nsamples = [] # List of tuples. If sample list, (first column, path). Else, (subdirectory name, path to gtf file in subdirectory)\nif (os.path.isfile(opts.input)):\n    # gtfList = True\n    try:\n        fin = open(opts.input, 'r')\n        for line in fin:\n            if line[0] != '#':\n                lineLst = tuple(line.strip().split())\n                if (len(lineLst) != 2):\n                    print \"Error: Text file with sample ID and path invalid (%s)\" % (line.strip())\n                    exit(1)\n                if lineLst[0] in samples:\n                    print \"Error: Sample ID duplicated (%s)\" % (lineLst[0])\n                    exit(1)\n                if not os.path.isfile(lineLst[1]):\n                    print \"Error: GTF file not found (%s)\" % (lineLst[1])\n                    exit(1)\n                samples.append(lineLst)\n    except IOError:\n        print \"Error: List of .gtf files, %s, doesn't exist\" % (opts.input)\n        exit(1)\nelse:\n    # gtfList = False\n    ## Check that opts.input directory exists\n    if not os.path.isdir(opts.input):\n      parser.print_help()\n      print \" \"\n      print \"Error: sub-directory '%s' not found!\" % (opts.input)\n      sys.exit(1)\n\n    #####\n    ## Collect all samples file paths and if empty print help message and quit\n    #####\n    samples = [(i,glob.iglob(os.path.join(opts.input,i,\"*.gtf\")).next()) for i in next(os.walk(opts.input))[1] if re.search(opts.pattern,i)]\n\nif len(samples) == 0:\n  parser.print_help()\n  print \" \"\n  print \"Error: no GTF files found under ./%s !\" % (opts.input)\n  sys.exit(1)\n\nRE_GENE_ID=re.compile('gene_id \"([^\"]+)\"')\nRE_GENE_NAME=re.compile('gene_name \"([^\"]+)\"')\nRE_TRANSCRIPT_ID=re.compile('transcript_id \"([^\"]+)\"')\nRE_COVERAGE=re.compile('cov \"([\\-\\+\\d\\.]+)\"')\nRE_STRING=re.compile(re.escape(opts.string))\n\n#####\n## Sort the sample names by the sample ID\n#####\nsamples.sort()\n\n#####\n## Checks whether a given row is a transcript \n## other options: ex. exon, transcript, mRNA, 5'UTR\n#####\ndef is_transcript(x):\n  return len(x)>2 and x[2]==\"transcript\"\n\ndef getGeneID(s, ctg, tid):\n  r=RE_GENE_ID.search(s)\n  if r: return r.group(1)\n  r=RE_GENE_NAME.search(s)\n  if r: return ctg+'|'+r.group(1)\n  return tid\n\ndef getCov(s):\n  r=RE_COVERAGE.search(s)\n  if r:\n    v=float(r.group(1))\n    if v<0.0: v=0.0\n    return v\n  return 0.0\n\ndef is_overlap(x,y): #NEEDS TO BE INTS!\n  return x[0]<=y[1] and y[0]<=x[1]\n\n\ndef t_overlap(t1, t2): #from badGenes: chromosome, strand, cluster, start, end, (e1start, e1end)...\n    if t1[0] != t2[0] or t1[1] != t2[1] or t1[5]<t2[4]: return False\n    for i in range(6, len(t1)):\n        for j in range(6, len(t2)):\n            if is_overlap(t1[i], t2[j]): return True\n    return False\n\n## Average Readlength\nread_len=opts.length\n\n## Variables/Matrices to store t/g_counts\nt_count_matrix, g_count_matrix=[],[]\n\n##Get ready for clustering, stuff is once for all samples##\ngeneIDs={} #key=transcript, value=cluster/gene_id\n\n\n## For each of the sorted sample paths\nfor s in samples:\n    badGenes=[] #list of bad genes (just ones that aren't MSTRG)\n    try:\n        ## opts.input = parent directory of sample subdirectories\n        ## s = sample currently iterating through\n        ## os.path.join(opts.input,s,\"*.gtf\") path to current sample's GTF\n        ## split = list of lists: [[chromosome, ...],...]\n\n        #with open(glob.iglob(os.path.join(opts.input,s,\"*.gtf\")).next()) as f:\n        #    split=[l.split('\\t') for l in f.readlines()]\n#        if not gtfList:\n#            f = open(glob.iglob(os.path.join(opts.input,s[1],\"*.gtf\")).next())\n#        else:\n#            f = open(s[1])\n        with open(s[1]) as f:\n            split=[l.split('\\t') for l in f.readlines()]\n\n        ## i = numLine; v = corresponding i-th GTF row\n        for i,v in enumerate(split):\n            if is_transcript(v):\n                t_id=RE_TRANSCRIPT_ID.search(v[len(v)-1]).group(1)\n                try:\n                  g_id=getGeneID(v[len(v)-1], v[0], t_id)\n                except:\n                  print \"Problem at line:\\n:%s\\n\" % (v)\n                  print \"i='%s', len(v)=%s\" % (i, len(v));\n                  sys.exit(1)\n                geneIDs.setdefault(t_id, g_id)\n                if not RE_STRING.match(g_id):\n                    badGenes.append([v[0],v[6], t_id, g_id, min(int(v[3]),int(v[4])), max(int(v[3]),int(v[4]))]) #chromosome, strand, cluster/transcript id, start, end\n                    j=i+1\n                    while j<len(split) and split[j][2]==\"exon\":\n                        badGenes[len(badGenes)-1].append((min(int(split[j][3]), int(split[j][4])), max(int(split[j][3]), int(split[j][4]))))\n                        j+=1\n\n    except StopIteration:\n        warnings.warn(\"Didn't get a GTF in that directory. Looking in another...\")\n\n    else: #we found the \"bad\" genes!\n        break\n\n##THE CLUSTERING BEGINS!##\nif opts.cluster and len(badGenes)>0:\n    clusters=[] #lists of lists (could be sets) or something of transcripts\n    badGenes.sort(key=itemgetter(3)) #sort by start coord...?\n    i=0\n    while i<len(badGenes): #rather un-pythonic\n        temp_cluster=[badGenes[i]]\n\n        k=0\n        while k<len(temp_cluster):\n            j=i+1\n            while j<len(badGenes):\n                if t_overlap(temp_cluster[k], badGenes[j]):\n                    temp_cluster.append(badGenes[j])\n                    del badGenes[j]\n                else:\n                    j+=1\n            k+=1\n        if len(temp_cluster)>1:\n            clusters.append([t[2] for t in temp_cluster])\n        i+=1\n\n    print len(clusters)\n\n    for c in clusters:\n        c.sort()\n\n    clusters.sort(key=itemgetter(0))\n    legend=[]\n    for u,c in enumerate(clusters):\n        my_ID=opts.key+str((u+1))\n        legend.append(list(itertools.chain.from_iterable([[my_ID],c]))) #my_ID, clustered transcript IDs\n        for t in c:\n            geneIDs[t]=my_ID\n##            geneIDs[t]=\"|\".join(c) #duct-tape transcript IDs together, disregarding ref_gene_names and things like that\n\n    with open(opts.legend, 'w') as l_file:\n        my_writer=csv.writer(l_file)\n        my_writer.writerows(legend)\n\ngeneDict={} #key=gene/cluster, value=dictionary with key=sample, value=summed counts\nt_dict={}\nfor q, s in enumerate(samples):\n    print q, s[0]\n\n    try:\n        #with open(glob.iglob(os.path.join(opts.input,s,\"*.gtf\")).next()) as f: #grabs first .gtf file it finds inside the sample subdirectory\n#        if not gtfList:\n#            f = open(glob.iglob(os.path.join(opts.input,s[1],\"*.gtf\")).next())\n#        else:\n        f = open(s[1])\n        \n            # s = s.split('/')[len(s.split('/')) - 1].split('.gtf')[0].split('_')[0]\n            # s = sample_IDs[q]\n\n##        split=[t[:len(t)-1]+t[len(t)-1].split(\";\") for t in split]\n##        split=[t[:len(t)-1] for t in split] #eliminate '\\n' at end\n##        split=[[e.lstrip() for e in t] for t in split]\n        #should consider making stuff into dictionaries, maybe each split line\n\n##            transcriptList=[]\n        transcript_len=0\n        for l in f:\n            if l.startswith(\"#\"):\n                continue\n            v=l.split('\\t')\n            if v[2]==\"transcript\":\n                if transcript_len>0:\n##                        transcriptList.append((g_id, t_id, int(ceil(coverage*transcript_len/read_len))))\n                    t_dict.setdefault(t_id, {})\n                    t_dict[t_id].setdefault(s[0], int(ceil(coverage*transcript_len/read_len)))\n                t_id=RE_TRANSCRIPT_ID.search(v[len(v)-1]).group(1)\n                #g_id=RE_GENE_ID.search(v[len(v)-1]).group(1)\n                g_id=getGeneID(v[len(v)-1], v[0], t_id)\n                #coverage=float(RE_COVERAGE.search(v[len(v)-1]).group(1))\n                coverage=getCov(v[len(v)-1])\n                transcript_len=0\n            if v[2]==\"exon\":\n                transcript_len+=int(v[4])-int(v[3])+1 #because end coordinates are inclusive in GTF\n\n##            transcriptList.append((g_id, t_id, int(ceil(coverage*transcript_len/read_len))))\n        t_dict.setdefault(t_id, {})\n        t_dict[t_id].setdefault(s[0], int(ceil(coverage*transcript_len/read_len)))\n\n    except StopIteration:\n#        if not gtfList:\n#            warnings.warn(\"No GTF file found in \" + os.path.join(opts.input,s[1]))\n#        else:\n        warnings.warn(\"No GTF file found in \" + s[1])\n\n\n##        transcriptList.sort(key=lambda bla: bla[1]) #gene_id\n\n    for i,v in t_dict.iteritems():\n##        print i,v\n        geneDict.setdefault(geneIDs[i],{}) #gene_id\n        geneDict[geneIDs[i]].setdefault(s[0],0)\n        geneDict[geneIDs[i]][s[0]]+=v[s[0]]\n\n\nwith open(opts.t, 'w') as csvfile:\n    my_writer = csv.DictWriter(csvfile, fieldnames = [\"transcript_id\"] + [x for x,y in samples])\n    my_writer.writerow(dict((fn,fn) for fn in my_writer.fieldnames))\n    for i in t_dict:\n        t_dict[i][\"transcript_id\"] = i\n        my_writer.writerow(t_dict[i])\n\nwith open(opts.g, 'w') as csvfile:\n    my_writer = csv.DictWriter(csvfile, fieldnames = [\"gene_id\"] + [x for x,y in samples])\n##    my_writer.writerow([\"\"]+samples)\n##    my_writer.writerows(geneDict)\n    my_writer.writerow(dict((fn,fn) for fn in my_writer.fieldnames))\n    for i in geneDict:\n        geneDict[i][\"gene_id\"] = i #add gene_id to row\n        my_writer.writerow(geneDict[i])",
                "writable": false
              }
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "hints": [
          {
            "class": "sbg:AWSInstanceType",
            "value": "c4.xlarge;ebs-gp2;128"
          },
          {
            "class": "sbg:GoogleInstanceType",
            "value": "n1-highcpu-8;pd-ssd;128"
          },
          {
            "class": "sbg:AzureInstanceType",
            "value": "Standard_F4s_v2;StandardSSD;120"
          }
        ],
        "sbg:categories": [
          "Quantification",
          "RNA-Seq"
        ],
        "sbg:image_url": null,
        "sbg:toolkitVersion": "2.1.3",
        "sbg:license": "Artistic License 2.0",
        "sbg:links": [
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml#contact",
            "label": "Homepage"
          },
          {
            "id": "https://github.com/gpertea/stringtie",
            "label": "Source Code"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/dl/stringtie-2.1.3b.Linux_x86_64.tar.gz",
            "label": "Download"
          },
          {
            "id": "https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1910-1",
            "label": "Publications"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
            "label": "Documentation"
          }
        ],
        "sbg:toolkit": "StringTie",
        "sbg:toolAuthor": "Johns Hopkins University, Center for Computational Biology",
        "sbg:projectName": "StringTie 2.1.3 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597776801,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777452,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777509,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1598955611,
            "sbg:revisionNotes": "tar warning ignore added"
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1599829953,
            "sbg:revisionNotes": "description updated"
          },
          {
            "sbg:revision": 5,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1612179274,
            "sbg:revisionNotes": "description changed"
          },
          {
            "sbg:revision": 6,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1621608814,
            "sbg:revisionNotes": "hints added for Azure and Google"
          },
          {
            "sbg:revision": 7,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1645535926,
            "sbg:revisionNotes": "categories changed"
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-74de15b6/h-d28c72b4/h-6d6b99ed/0",
        "sbg:revision": 7,
        "sbg:revisionNotes": "categories changed",
        "sbg:modifiedOn": 1645535926,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1597776801,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "nevena_vukojicic/stringtie-2-1-3-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 7,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "aa094252ea5e6988cfbcc1472b7d955b33ddf709ad32843ad71982687b92128e1",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "StringTie",
      "scatter": [
        "in_alignments"
      ],
      "sbg:x": 970.4917602539062,
      "sbg:y": 170.87466430664062
    },
    {
      "id": "stringtie_merge_2_1_3",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "in_gene_annotation"
        },
        {
          "id": "in_transcripts",
          "source": [
            "stringtie_2_1_3/out_assembled_transcripts"
          ]
        }
      ],
      "out": [
        {
          "id": "out_merged_transcripts"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "nevena_vukojicic/stringtie-2-1-3-demo/stringtie-merge-2-1-3/5",
        "baseCommand": [
          "/opt/stringtie-2.1.3b.Linux_x86_64/stringtie"
        ],
        "inputs": [
          {
            "sbg:category": "File inputs",
            "id": "in_gene_annotation",
            "type": "File?",
            "inputBinding": {
              "prefix": "-G",
              "shellQuote": false,
              "position": 2
            },
            "label": "Reference annotation file",
            "doc": "Reference annotation file to include in the merging.",
            "sbg:fileTypes": "GTF, GFF3"
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "50",
            "id": "minimum_length",
            "type": "int?",
            "inputBinding": {
              "prefix": "-m",
              "shellQuote": false,
              "position": 4
            },
            "label": "Minimum transcript length",
            "doc": "Minimum input transcript length to include in the merge."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0",
            "id": "minimum_coverage",
            "type": "float?",
            "inputBinding": {
              "prefix": "-c",
              "shellQuote": false,
              "position": 5
            },
            "label": "Minimum transcript coverage",
            "doc": "Minimum input transcript coverage to include in the merge."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "minimum_fpkm",
            "type": "float?",
            "inputBinding": {
              "prefix": "-F",
              "shellQuote": false,
              "position": 6
            },
            "label": "Minimum transcript FPKM",
            "doc": "Minimum input transcript FPKM to include in the merge."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "1",
            "id": "minimum_tpm",
            "type": "float?",
            "inputBinding": {
              "prefix": "-T",
              "shellQuote": false,
              "position": 7
            },
            "label": "Minimum transcript TPM",
            "doc": "Minimum input transcript TPM to include in the merge."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "0.01",
            "id": "minimum_isoform_abundance",
            "type": "float?",
            "inputBinding": {
              "prefix": "-f",
              "shellQuote": false,
              "position": 8
            },
            "label": "Minimum isoform abundance",
            "doc": "Sets the minimum isoform abundance of the predicted transcripts as a fraction of the most abundant transcript assembled at a given locus."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "False",
            "id": "retain_introns",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-i",
              "shellQuote": false,
              "position": 10
            },
            "label": "Keep transcripts with retained introns",
            "doc": "Keep merged transcripts with retained introns; by default these are not kept unless there is strong evidence for them."
          },
          {
            "sbg:category": "Execution",
            "sbg:toolDefaultValue": "MSTRG",
            "id": "transcripts_name_prefix",
            "type": "string?",
            "inputBinding": {
              "prefix": "-l",
              "shellQuote": false,
              "position": 11
            },
            "label": "Transcripts name prefix",
            "doc": "Name prefix for output transcripts."
          },
          {
            "sbg:category": "File inputs",
            "id": "in_transcripts",
            "type": "File[]",
            "label": "Input GTF/GFF files",
            "doc": "Input GTF/GFF files to merge.",
            "sbg:fileTypes": "GTF, GFF"
          },
          {
            "sbg:toolDefaultValue": "250",
            "sbg:category": "Execution",
            "id": "gap_length",
            "type": "int?",
            "inputBinding": {
              "prefix": "-g",
              "shellQuote": false,
              "position": 9
            },
            "label": "Gap length",
            "doc": "Gap between transcripts to merge together."
          },
          {
            "sbg:category": "Output",
            "id": "output_prefix",
            "type": "string?",
            "label": "Output prefix",
            "doc": "Prefix for output file."
          },
          {
            "sbg:category": "Platform options",
            "id": "mem_per_job",
            "type": "int?",
            "label": "Memory per job [MB]",
            "doc": "Memory per job [MB]."
          },
          {
            "sbg:category": "Platform options",
            "id": "cpu_per_job",
            "type": "int?",
            "label": "CPU per job",
            "doc": "Number of CPUs per job."
          }
        ],
        "outputs": [
          {
            "id": "out_merged_transcripts",
            "doc": "Merged transcripts.",
            "label": "Merged transcripts",
            "type": "File?",
            "outputBinding": {
              "glob": "*.gtf",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_gene_annotation) ;\n\n}"
            },
            "sbg:fileTypes": "GTF"
          }
        ],
        "doc": "The **StringTie Merge** tool takes a list of GTF/GFF files as its input and merges/assembles these transcripts into a non-redundant set of transcripts [1]. This tool is used as an intermediate step in the new Tuxedo differential expression analysis pipeline described in [2] to generate a global, unified set of transcripts (isoforms) across multiple RNA-Seq samples.\n\n*A list of __all inputs and parameters__ with corresponding descriptions can be found at the bottom of this page.*\n\n*__Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.__*\n\n### Common Use Cases\n\n* This tool should be used after __StringTie__ transcript assembling of each sample in the experiment. This tool creates a set of transcripts that is consistent across all samples, so that the transcripts can be compared in subsequent steps of the analysis [2]. For more details refer to the StringTie protocol paper [2].\n\n### Changes Introduced by Seven Bridges\n\n* No modifications to the original tool representation have been made.\n\n### Common Issues and Important Notes\n\n* No common issues specific to the tool's execution on the Seven Bridges Platform have been detected. \n\n### Performance Benchmarking\n\n* The execution time for merging 8 assembled transcripts takes several minutes on the default instance; the price is negligible (~ 0.01$). Unless specified otherwise, the default instance used to run the __StringTie Merge__ tool will be c4.large (AWS).\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### References\n\n[1] [StringTie manual page](http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual)\n\n[2] [HISAT, StringTie, Ballgown protocol paper](http://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html)",
        "label": "StringTie Merge",
        "arguments": [
          {
            "prefix": "-o",
            "shellQuote": false,
            "position": 3,
            "valueFrom": "${\n    var cmd = \"./\" ;\n    \n    if (inputs.output_prefix) { ;\n        var file_name = inputs.output_prefix ;\n        cmd = cmd.concat(file_name,\".StringTie_Merge.2.1.3.merged_transcripts.gtf\") ;\n        return cmd ;\n  } else ;\n        return \"./StringTie_Merge.2.1.3.merged_transcripts.gtf\" ;\n}"
          },
          {
            "prefix": "--merge",
            "shellQuote": false,
            "position": 1,
            "valueFrom": "${\n    var out = \"\" ;\n    for (var i = 0; i < inputs.in_transcripts.length; i++) \n        out += \" \" + inputs.in_transcripts[i].path ;\n    return out ;\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${\n    if (inputs.mem_per_job) { ;\n        return inputs.mem_per_job ;\n    } else ;\n        return 1000 ;\n    \n}",
            "coresMin": "${\n    if (inputs.cpu_per_job) { ;\n        return inputs.cpu_per_job ;\n    } else ;\n        return 1 ;\n    \n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/nevena_vukojicic/stringtie:2.1.3"
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "hints": [
          {
            "class": "sbg:AWSInstanceType",
            "value": "c4.xlarge;ebs-gp2;128"
          },
          {
            "class": "sbg:GoogleInstanceType",
            "value": "n1-highcpu-8;pd-ssd;128"
          },
          {
            "class": "sbg:AzureInstanceType",
            "value": "Standard_F4s_v2;StandardSSD;120"
          }
        ],
        "sbg:categories": [
          "Quantification",
          "RNA-Seq"
        ],
        "sbg:image_url": null,
        "sbg:license": "Artistic License 2.0",
        "sbg:links": [
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml#contact",
            "label": "Homepage"
          },
          {
            "id": "https://github.com/gpertea/stringtie",
            "label": "Source Code"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/dl/stringtie-2.1.3b.Linux_x86_64.tar.gz",
            "label": "Download"
          },
          {
            "id": "https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1910-1",
            "label": "Publications"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual",
            "label": "Documentation"
          }
        ],
        "sbg:toolAuthor": "Johns Hopkins University, Center for Computational Biology",
        "sbg:toolkit": "StringTie",
        "sbg:toolkitVersion": "2.1.3",
        "sbg:projectName": "StringTie 2.1.3 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777640,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777707,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1599829996,
            "sbg:revisionNotes": "description updated"
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1612179399,
            "sbg:revisionNotes": "description changed"
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1621608902,
            "sbg:revisionNotes": "hints added for Azure and Google"
          },
          {
            "sbg:revision": 5,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1645535955,
            "sbg:revisionNotes": "categories changed"
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-8ebd7dc9/h-97fb4c1e/h-e118aa7f/0",
        "sbg:revision": 5,
        "sbg:revisionNotes": "categories changed",
        "sbg:modifiedOn": 1645535955,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1597777640,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "nevena_vukojicic/stringtie-2-1-3-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 5,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "a6d8b6e1c8feb38514fc543974c41df3c32b7801cc079a241dd81df85cd2fd57d",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "StringTie Merge",
      "sbg:x": 439.24786376953125,
      "sbg:y": -297.260498046875
    },
    {
      "id": "gffcompare_0_11_6",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "in_gene_annotation"
        },
        {
          "id": "in_assembled_transcripts",
          "source": [
            "stringtie_merge_2_1_3/out_merged_transcripts"
          ]
        }
      ],
      "out": [
        {
          "id": "out_gffcmp_stats_files"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "nevena_vukojicic/stringtie-2-1-3-demo/gffcompare-0-11-6/5",
        "baseCommand": [
          "/opt/gffcompare-0.11.6.Linux_x86_64/gffcompare"
        ],
        "inputs": [
          {
            "sbg:category": "Basic Options",
            "id": "tmap_refmap_files",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-T",
              "shellQuote": false,
              "position": 15
            },
            "label": "Don't generate .tmap and .refmap files",
            "doc": "Don't generate .tmap and .refmap files for each input file."
          },
          {
            "sbg:category": "Input files",
            "id": "in_gene_annotation",
            "type": "File",
            "inputBinding": {
              "prefix": "-r",
              "shellQuote": false,
              "position": 2
            },
            "label": "Reference transcripts",
            "doc": "Reference GFF/GTF file containing annotated transcripts.",
            "sbg:fileTypes": "GTF, GFF"
          },
          {
            "sbg:category": "Basic Options",
            "id": "ref_transcripts_only",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-R",
              "shellQuote": false,
              "position": 3
            },
            "label": "Reference transcripts only",
            "doc": "Consider only the reference transcripts that overlap any of the input transfrags (Sn correction)."
          },
          {
            "sbg:toolDefaultValue": "TCONS",
            "sbg:category": "Basic Options",
            "id": "prefix_cons_transcripts",
            "type": "string?",
            "inputBinding": {
              "prefix": "-p",
              "shellQuote": false,
              "position": 10
            },
            "label": "Prefix name for consensus transcripts",
            "doc": "The name prefix to use for consensus transcripts in the <outprefix>.combined.gtf file."
          },
          {
            "sbg:category": "Basic Options",
            "id": "outprefix",
            "type": "string?",
            "inputBinding": {
              "prefix": "-o",
              "shellQuote": false,
              "position": 10,
              "valueFrom": "${\n    if (self == 0) { ;\n        self = null;\n        inputs.outprefix = null ;\n    };\n\n\n    if (inputs.outprefix) { ;\n        var prefix = inputs.outprefix ;\n        return prefix.concat(\".GffCompare.0.11.6\") ;\n    } else { ;\n        var in_assembled_transcripts = [].concat(inputs.in_assembled_transcripts) ;\n        var prefix_name = in_assembled_transcripts[0].nameroot ;\n        return prefix_name.concat(\".GffCompare.0.11.6\") ;\n    };\n}"
            },
            "label": "Output prefix name",
            "doc": "Prefix name for output files.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "100",
            "sbg:category": "Basic Options",
            "id": "max_tss_distance",
            "type": "int?",
            "inputBinding": {
              "prefix": "-d",
              "shellQuote": false,
              "position": 9
            },
            "label": "Maximum transcript start sites distance",
            "doc": "Maximum distance (range) for grouping transcript start sites."
          },
          {
            "sbg:toolDefaultValue": "100",
            "sbg:category": "Basic Options",
            "id": "max_exon_distance",
            "type": "int?",
            "inputBinding": {
              "prefix": "-e",
              "shellQuote": false,
              "position": 8
            },
            "label": "Maximum exon distance",
            "doc": "Maximum distance (range) allowed from free ends of terminal exons of reference transcripts when assessing exon accuracy."
          },
          {
            "sbg:category": "Basic Options",
            "id": "matching_reference_transfrags",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-K",
              "shellQuote": false,
              "position": 14
            },
            "label": "Don't discard matching reference transfrags",
            "doc": "For -C/-A/-X options, do not discard any redundant transfrag matching a reference."
          },
          {
            "sbg:category": "Basic Options",
            "id": "keep_alternate_tss",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-A",
              "shellQuote": false,
              "position": 12
            },
            "label": "Keep alternate TSS",
            "doc": "Similar to -C option, but will not discard intron-redundant transfrags if they start on a different 5' exon (keep alternate TSS)."
          },
          {
            "sbg:category": "Basic Options",
            "id": "input_transcripts_only",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-Q",
              "shellQuote": false,
              "position": 4
            },
            "label": "Input transcripts only",
            "doc": "Consider only the input transcripts that overlap any of the reference transcripts (Precision correction). Warning: this will discard all \"novel\" loci!"
          },
          {
            "sbg:category": "Input files",
            "id": "in_genome_reference",
            "type": "File?",
            "inputBinding": {
              "prefix": "-s",
              "shellQuote": false,
              "position": 7
            },
            "label": "Genome sequence",
            "doc": "This can be either a multi-FASTA file or a directory containing single-fasta files (one for each contig). Repeats must be soft-masked (lower case) in order to be able to classify transfrags as repeats.",
            "sbg:fileTypes": "FAS"
          },
          {
            "sbg:category": "Basic Options",
            "id": "discard_sticking_out_transfrags",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-X",
              "shellQuote": false,
              "position": 13
            },
            "label": "Discard sticking out transfrags",
            "doc": "Like -C but also discard contained transfrags if transfrag ends stick out within the container's introns."
          },
          {
            "sbg:category": "Basic Options",
            "id": "discard_se_transfrags",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-M",
              "shellQuote": false,
              "position": 5
            },
            "label": "Discard single exon transfrags and reference transcripts",
            "doc": "Discard (ignore) single exon transfrags and reference transcripts."
          },
          {
            "sbg:category": "Basic Options",
            "id": "discard_se_reftran",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-N",
              "shellQuote": false,
              "position": 6
            },
            "label": "Discard single exon reference transcripts",
            "doc": "Discard (ignore) single exon reference transcripts."
          },
          {
            "sbg:category": "Basic Options",
            "id": "discard_contained_transfrags",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "-C",
              "shellQuote": false,
              "position": 11
            },
            "label": "Discard 'contained' transfrags",
            "doc": "Discard the \"contained\" transfrags in the .combined.gtf file (i.e. collapse intron-redundant transfrags across all query files)."
          },
          {
            "sbg:category": "Input files",
            "id": "in_assembled_transcripts",
            "type": "File[]",
            "inputBinding": {
              "shellQuote": false,
              "position": 31,
              "valueFrom": "${\n    var in_assembled_transcripts = [].concat(inputs.in_assembled_transcripts);\n    var cmd = \"\" ;\n    for (var i = 0; i < in_assembled_transcripts.length; i++) { ;\n        cmd = cmd.concat(in_assembled_transcripts[i].path, \" \") ;\n    } ;\n    return cmd ;\n}"
            },
            "label": "Assembled transcripts",
            "doc": "List of GTF/GFF files containing assembled transcripts to be compared with provided reference GTF file.",
            "sbg:fileTypes": "GTF, GFF"
          },
          {
            "sbg:category": "Platform options",
            "id": "mem_per_job",
            "type": "int?",
            "label": "Memory per job [MB]",
            "doc": "Memory per job [MB]."
          },
          {
            "sbg:category": "Platform options",
            "id": "cpu_per_job",
            "type": "int?",
            "label": "CPU per job",
            "doc": "Number of CPUs per job."
          }
        ],
        "outputs": [
          {
            "id": "out_gffcmp_stats_files",
            "doc": "GffCompare stats files.",
            "label": "GffCompare stats files",
            "type": "File[]",
            "outputBinding": {
              "glob": "*.GffCompare.*",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_assembled_transcripts) ;\n\n}"
            },
            "sbg:fileTypes": "TRACKING, LOCI, STATS, GTF, REFMAP, TMAP"
          }
        ],
        "doc": "__GffCompare__ [1] is a part of the GFF utility toolkit and can be used to:\n\n-  compare and evaluate the accuracy of RNA-Seq transcript assemblers (__Cufflinks__, __Stringtie__).\n-  collapse (merge) duplicate transcripts from multiple GTF/GFF3 files (e.g. resulted from assembly of different samples)\n- classify transcripts from one or multiple GTF/GFF3 files as they relate to reference transcripts provided in an annotation file (also in GTF/GFF3 format)\n\nThe original form of this program is also distributed as part of the Cufflinks suite, under the name \"__CuffCompare__\". Most of the options and parameters of __CuffCompare__ are supported by __GffCompare__, while new features will likely be added to __GffCompare__ in the future.\n\n*A list of __all inputs and parameters__ with corresponding descriptions can be found at the bottom of this page.*\n\n*__Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.__*\n\n### Common Use Cases\n\n* This tool should be used after __StringTie__ and __StringTie Merge__ transcript assembling and merging. The GffCompare program then compares the genes and transcripts with the annotation and reports statistics on this comparison. For more details refer to the StringTie protocol paper [2].\n\n### Changes Introduced by Seven Bridges\n\n* No modifications to the original tool representation have been made.\n\n### Common Issues and Important Notes\n\n* No common issues specific to the tool's execution on the Seven Bridges Platform have been detected.\n\n### Performance Benchmarking\n\n* The execution time for comparing 8 assembled transcripts takes several minutes on the default instance; the price is negligible (~ 0.01$). Unless specified otherwise, the default instance used to run the __GffCompare__ tool will be c4.large (AWS).\n\n*Cost can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n### References\n\n[1] [GffCompare manual page](http://ccb.jhu.edu/software/stringtie/gff.shtml#gffcompare)\n\n[2] [HISAT, StringTie, Ballgown protocol paper](http://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html)",
        "label": "GffCompare",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 101,
            "valueFrom": "${ // there is a bug when using -o option in gffcompare. Namely, when -o argument contains a dot (\".\") stats file will be produced without .stats extension so the full name of the stats file will be the value of the -o argument.\n\n    {\n        var cmd = \" && \" ;\n        if (inputs.outprefix) { ;\n            var prefix = inputs.outprefix ;\n            var stats_file_name = prefix.concat(\".GffCompare.0.11.6\") ;\n        } else { ;\n            var in_assembled_transcripts = [].concat(inputs.in_assembled_transcripts) ;\n            prefix = in_assembled_transcripts[0].nameroot ;\n            stats_file_name = prefix.concat(\".GffCompare.0.11.6\") ;\n        } ;\n        var new_stats_file_name = stats_file_name.concat(\".stats\") ;\n        cmd = cmd.concat(\"mv \", stats_file_name, \" \", new_stats_file_name) ;\n        \n        return cmd ;\n\n    };\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 131,
            "valueFrom": "${\n    // GffCompare puts .refmap and .tmap files in the directory where the input files are stored. They should be moved in the current directory to enable having them on the output.\n\n    // getting output prefix \nif (!inputs.tmap_refmap_files) { ;\n    var cmd = \"\" ;\n    if (inputs.outprefix) { ;\n        var prefix = inputs.outprefix.concat(\".GffCompare.0.11.6\") ;\n    } else { ;\n        var in_assembled_transcripts = [].concat(inputs.in_assembled_transcripts) ;\n        prefix = in_assembled_transcripts[0].nameroot.concat(\".GffCompare.0.11.6\") ;\n    };\n\n    in_assembled_transcripts = [].concat(inputs.in_assembled_transcripts) ;\n\n    var input_files_path = in_assembled_transcripts[0].path ;\n    input_files_path = input_files_path.split(\"/\").slice(0, -1) ;\n    input_files_path = input_files_path.join(\"/\") ;\n\n    var input_query_files = [].concat(inputs.in_assembled_transcripts) ;\n\n    for (var i = 0; i < input_query_files.length; i++) { ;\n        var query_file = input_query_files[i].path ;\n        var query_file_name = query_file.split(\"/\").slice(-1)[0] ;\n\n        var query_file_name_without_ext = query_file_name.split(\".\").slice(0, -1).join(\".\") ;\n\n        var old_refmap_name = prefix.concat(\".\", query_file_name, \".refmap\") ;\n        var old_tmap_name = prefix.concat(\".\", query_file_name, \".tmap\") ;\n        var new_refmap_name = query_file_name_without_ext.concat(\".GffCompare.0.11.6.refmap\") ;\n        var new_tmap_name = query_file_name_without_ext.concat(\".GffCompare.0.11.6.tmap\") ;\n\n        cmd = cmd.concat(\" && mv \", input_files_path, \"/\", old_refmap_name, \" ./\", new_refmap_name, \" && mv \", input_files_path, \"/\", old_tmap_name, \" ./\", new_tmap_name) ;\n\n    };\n    return cmd }\nelse ;\n    {return \"\" ;\n    };\n\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${\n    if (inputs.mem_per_job) { ;\n        return inputs.mem_per_job ;\n    } else ;\n        return 1000 ;\n    \n}",
            "coresMin": "${\n    if (inputs.cpu_per_job) { ;\n        return inputs.cpu_per_job ;\n    } else ;\n        return 1 ;\n    \n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/nevena_vukojicic/gffcompare-0-11-6:0"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": []
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "hints": [
          {
            "class": "sbg:AWSInstanceType",
            "value": "c4.large;ebs-gp2;256"
          },
          {
            "class": "sbg:GoogleInstanceType",
            "value": "n1-highcpu-4;pd-ssd;256"
          },
          {
            "class": "sbg:AzureInstanceType",
            "value": "Standard_F2s_v2;StandardSSD;250"
          }
        ],
        "sbg:toolkitVersion": "0.11.6",
        "sbg:toolAuthor": "Johns Hopkins University, Center for Computational Biology",
        "sbg:categories": [
          "Quantification",
          "RNA-Seq"
        ],
        "sbg:image_url": null,
        "sbg:links": [
          {
            "id": "http://ccb.jhu.edu/software/stringtie/gff.shtml",
            "label": "Homepage"
          },
          {
            "id": "https://github.com/gpertea/gffcompare",
            "label": "Source Code"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/dl/gffcompare-0.11.6.Linux_x86_64.tar.gz",
            "label": "Download"
          },
          {
            "id": "http://ccb.jhu.edu/software/stringtie/gff.shtml#gffcompare",
            "label": "Documentation"
          }
        ],
        "sbg:license": "Artistic License 2.0",
        "sbg:toolkit": "GffCompare",
        "sbg:projectName": "StringTie 2.1.3 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777806,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1597777832,
            "sbg:revisionNotes": ""
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1599830046,
            "sbg:revisionNotes": "description updated"
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1612179345,
            "sbg:revisionNotes": "description changed"
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1621609420,
            "sbg:revisionNotes": "hints added for Azure and Google"
          },
          {
            "sbg:revision": 5,
            "sbg:modifiedBy": "nevena_vukojicic",
            "sbg:modifiedOn": 1645535893,
            "sbg:revisionNotes": "categories changed"
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-e0148746/h-b3f32764/h-96f15c6a/0",
        "sbg:revision": 5,
        "sbg:revisionNotes": "categories changed",
        "sbg:modifiedOn": 1645535893,
        "sbg:modifiedBy": "nevena_vukojicic",
        "sbg:createdOn": 1597777806,
        "sbg:createdBy": "nevena_vukojicic",
        "sbg:project": "nevena_vukojicic/stringtie-2-1-3-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nevena_vukojicic"
        ],
        "sbg:latestRevision": 5,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "ad0995d3719935689011a804b7bd0c316e1a9a4dc5156fb5e28078de62c6e055a",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "GffCompare",
      "sbg:x": 660.1704711914062,
      "sbg:y": -506.98138427734375
    },
    {
      "id": "hisat2_extractsplicesites_2_2_1",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "in_gene_annotation"
        },
        {
          "id": "in_references_or_index",
          "source": [
            "in_references_or_index"
          ]
        }
      ],
      "out": [
        {
          "id": "out_extracted_splice_sites"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "jasmina_miscevic/rna-seq-quantification-hisat2-stringtie-novel-isoform-quantification/hisat2-extractsplicesites-2-2-1/1",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:category": "Input files",
            "id": "in_gene_annotation",
            "type": "File",
            "label": "Gene annotation file",
            "doc": "Input GTF file to extract splice sites from.",
            "sbg:fileTypes": "GTF, GTF.GZ"
          },
          {
            "sbg:category": "Additional options",
            "id": "out_prefix",
            "type": "string?",
            "label": "Output file prefix",
            "doc": "Output file prefix."
          },
          {
            "id": "in_references_or_index",
            "type": "File[]?",
            "label": "Reference or index files",
            "doc": "Port is added just to check if HISAT2 index is provided (to skip extracting step)."
          }
        ],
        "outputs": [
          {
            "id": "out_extracted_splice_sites",
            "doc": "Extracted splice sites in HISAT2 format.",
            "label": "Extracted splice sites",
            "type": "File",
            "outputBinding": {
              "glob": "*.txt",
              "outputEval": "${\n    if(inputs.in_gene_annotation) {\n        \n        return inheritMetadata(self, inputs.in_gene_annotation); \n        \n    }\n        \n\n}"
            },
            "sbg:fileTypes": "TXT"
          }
        ],
        "doc": "__HISAT2 ExtractSpliceSites__ extracts a list of splice sites from a GTF file in the **HISAT2**'s own format as follows (4 tab-delimited columns):   \n(1) chromosome name; (2) zero-offset based genomic position of the flanking base on the left side of an intron; (3) zero-offset based genomic position of the flanking base on the right; (4) strand.\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the end of the page.*\n\n### Common Use Cases\n\n* This tool can be used as a preprocessing step for __HISAT2 Build__. It is used to create a file containing splice sites that can be forwarded to __HISAT2 Build__ in order to create an index that can improve alignment accuracy.\n\n### Changes Introduced by Seven Bridges\n\n* Output file will be prefixed by the input gene annotation filename, unless the __Output file prefix__ option is explicitly specified.\n\n### Common Issues and Important Notes\n\n* No common issues specific to the tool's execution on the Seven Bridges platform have been detected. \n\n### Performance Benchmarking\n\nThe execution time for human gene annotation takes several minutes on the default instance; the price is negligible (~ $0.02) using on-demand AWS instances.\n\n*Cost can be significantly reduced by **spot instance** usage. Visit [knowledge center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*",
        "label": "HISAT2 ExtractSpliceSites",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format == \"tar\") {\n        return \"echo 'HISAT2 index is provided at the input, no extracting splice sites.'\";\n    } else { \n        \n        if(inputs.in_gene_annotation){\n        \n        var cmd = \"\";\n        var input_file = inputs.in_gene_annotation.path;\n        var input_file_ext = input_file.split(\".\").slice(-1);\n\n        if (input_file_ext == \"gz\") {\n            \n            var uncompressed_input_file = input_file.split(\".\").slice(0, -1).join(\".\");\n        \n            if(inputs.out_prefix && inputs.out_prefix.trim()!='') {\n                \n                cmd = \"gunzip -c \".concat(input_file, \" > \", uncompressed_input_file, \" && /opt/hisat2-2.2.1/hisat2_extract_splice_sites.py \", uncompressed_input_file, \" > \", inputs.out_prefix, \".extractedSpliceSites.txt\");\n                \n            } else{\n                \n                var output_name_prefix = uncompressed_input_file.split(\"/\").slice(-1)[0].split(\".\").slice(0, -1).join(\".\");\n\n                cmd = \"gunzip -c \".concat(input_file, \" > \", uncompressed_input_file, \" && /opt/hisat2-2.2.1/hisat2_extract_splice_sites.py \", uncompressed_input_file, \" > \", output_name_prefix, \".extractedSpliceSites.txt\");\n                \n            }\n\n        } else {\n            \n            if(inputs.out_prefix && inputs.out_prefix.trim()!='') {\n                \n                cmd = \"/opt/hisat2-2.2.1/hisat2_extract_splice_sites.py \".concat(input_file, \" > \", inputs.out_prefix, \".extractedSpliceSites.txt\");\n                \n            } else {\n                \n                output_name_prefix = input_file.split(\"/\").slice(-1)[0].split(\".\").slice(0, -1).join(\".\");\n\n                cmd = \"/opt/hisat2-2.2.1/hisat2_extract_splice_sites.py \".concat(input_file, \" > \", output_name_prefix, \".extractedSpliceSites.txt\");\n                \n            }\n            \n        }\n\n             return cmd;  \n        \n    } else {\n        \n        return \"echo 'Skipping extracting of splice sites since gene annotation file is not provided.' \";\n    }\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1000,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/jasmina_miscevic/hisat2-2.2.1:0"
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "sbg:toolkitVersion": "2.2.1",
        "sbg:toolAuthor": "Johns Hopkins University",
        "sbg:categories": [
          "Indexing",
          "CWL1.0"
        ],
        "sbg:license": "GNU General Public License v3.0 only",
        "sbg:image_url": null,
        "sbg:links": [
          {
            "id": "https://daehwankimlab.github.io/hisat2/",
            "label": "HISAT2 Homepage"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-source/download",
            "label": "HISAT2 Source Code"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-Linux_x86_64/download",
            "label": "HISAT2 Download"
          },
          {
            "id": "http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html",
            "label": "HISAT2 Publications"
          },
          {
            "id": "https://daehwankimlab.github.io/hisat2/manual/",
            "label": "HISAT2 Documentation"
          }
        ],
        "sbg:toolkit": "HISAT2",
        "sbg:expand_workflow": false,
        "sbg:wrapperAuthor": "",
        "sbg:projectName": "RNA-Seq Quantification (HISAT2, StringTie) + novel isoform quantification ",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1598956408,
            "sbg:revisionNotes": "Copy of jasmina_miscevic/hisat2-2-2-1-demo/hisat2-extractsplicesites-2-2-1/1"
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1598956670,
            "sbg:revisionNotes": "in_ref_or_index port added in order to skip extracting in wf if HISAT2 index is provided."
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-2b7e7b9e/h-a12a81c3/h-e2a535ae/0",
        "sbg:revision": 1,
        "sbg:revisionNotes": "in_ref_or_index port added in order to skip extracting in wf if HISAT2 index is provided.",
        "sbg:modifiedOn": 1598956670,
        "sbg:modifiedBy": "jasmina_miscevic",
        "sbg:createdOn": 1598956408,
        "sbg:createdBy": "jasmina_miscevic",
        "sbg:project": "jasmina_miscevic/rna-seq-quantification-hisat2-stringtie-novel-isoform-quantification",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "jasmina_miscevic"
        ],
        "sbg:latestRevision": 1,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "a4f6f217b47760233eff28d2d0c3602c27ba4d2bab21821cd316aad4344c8d09f"
      },
      "label": "HISAT2 ExtractSpliceSites",
      "sbg:x": -632.2255859375,
      "sbg:y": 12.379179000854492
    },
    {
      "id": "hisat2_extractexons_2_2_1",
      "in": [
        {
          "id": "in_gene_annotation",
          "source": "in_gene_annotation"
        },
        {
          "id": "in_references_or_index",
          "source": [
            "in_references_or_index"
          ]
        }
      ],
      "out": [
        {
          "id": "out_extracted_exons"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "jasmina_miscevic/rna-seq-quantification-hisat2-stringtie-novel-isoform-quantification/hisat2-extractexons-2-2-1/1",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:category": "Input files",
            "id": "in_gene_annotation",
            "type": "File",
            "label": "Gene annotation file",
            "doc": "GTF file to extract exons from.",
            "sbg:fileTypes": "GTF, GTF.GZ"
          },
          {
            "sbg:category": "Additional options",
            "id": "out_prefix",
            "type": "string?",
            "label": "Output file prefix",
            "doc": "Output file prefix."
          },
          {
            "id": "in_references_or_index",
            "type": "File[]?",
            "label": "Reference or Index files",
            "doc": "Port is added just to check if HISAT2 index is provided (to skip extracting step)."
          }
        ],
        "outputs": [
          {
            "id": "out_extracted_exons",
            "doc": "Extracted exons in HISAT2 format.",
            "label": "Extracted exons",
            "type": "File",
            "outputBinding": {
              "glob": "*.txt",
              "outputEval": "${\n    if(inputs.in_gene_annotation){\n        \n        return inheritMetadata(self, inputs.in_gene_annotation);\n    }\n\n}"
            },
            "sbg:fileTypes": "TXT"
          }
        ],
        "doc": "__HISAT2 ExtractExons__ extracts a list of exons from a GTF file in the **HISAT2**'s own format which is a tab-delimited file with the following columns: (1) chromosome name; (2) zero-offset based left genomic position of an exon; and (3) zero-offset based right genomic position of an exon.\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the end of the page.*\n\n### Common Use Cases\n\n* This tool can be used as a preprocessing step for __HISAT2 Build__. It is used to create a file containing exons that can be further fed to __HISAT2 Build__ in order to create an index that can improve alignment accuracy.\n\n### Changes Introduced by Seven Bridges\n\n* Output file will be prefixed by the input gene annotation filename, unless the __Output file prefix__ option is explicitly specified.\n\n### Common Issues and Important Notes\n\n* No common issues specific to the tool's execution on the Seven Bridges platform have been detected.\n\n### Performance Benchmarking\n\nThe execution time for human gene annotation takes several minutes on the default instance; the price is negligible (~ $0.02) using on-demand AWS instances. \n\n*Cost can be significantly reduced by **spot instance** usage. Visit [knowledge center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*",
        "label": "HISAT2 ExtractExons",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${  \n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format == \"tar\") {\n        return \"echo 'HISAT2 index is provided at the input, no extracting exons.'\";\n    } else { \n        \n        if(inputs.in_gene_annotation){\n        \n        var cmd = \"\";\n        var input_file = inputs.in_gene_annotation.path;\n        var input_file_ext = input_file.split(\".\").slice(-1);\n\n\n        if (input_file_ext == \"gz\") {\n            \n            var uncompressed_input_file = input_file.split(\".\").slice(0, -1).join(\".\");\n        \n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                \n                cmd = \"gunzip -c \".concat(input_file, \" > \", uncompressed_input_file, \" && /opt/hisat2-2.2.1/hisat2_extract_exons.py \", uncompressed_input_file, \" > \", inputs.out_prefix, \".extractedExons.txt\");\n                \n            } else {\n                \n                var output_name_prefix = uncompressed_input_file.split(\"/\").slice(-1)[0].split(\".\").slice(0, -1).join(\".\");\n\n                cmd = \"gunzip -c \".concat(input_file, \" > \", uncompressed_input_file, \" && /opt/hisat2-2.2.1/hisat2_extract_exons.py \", uncompressed_input_file, \" > \", output_name_prefix, \".extractedExons.txt\");\n            }\n\n        } else {\n            \n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n            \n            cmd = \"/opt/hisat2-2.2.1/hisat2_extract_exons.py \".concat(input_file, \" > \", inputs.out_prefix, \".extractedExons.txt\");\n        \n        } else {\n            \n            output_name_prefix = input_file.split(\"/\").slice(-1)[0].split(\".\").slice(0, -1).join(\".\");\n\n            cmd = \"/opt/hisat2-2.2.1/hisat2_extract_exons.py \".concat(input_file, \" > \", output_name_prefix, \".extractedExons.txt\");\n            \n        }\n    }\n\n        return cmd; \n        \n    }\n    \n    else {\n        \n        return \"echo 'Skipping extracting of exons since gene annotation file is not provided.' \";\n    }\n    }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1000,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/jasmina_miscevic/hisat2-2.2.1:0"
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "sbg:toolkitVersion": "2.2.1",
        "sbg:toolAuthor": "Johns Hopkins University",
        "sbg:categories": [
          "Indexing",
          "CWL1.0"
        ],
        "sbg:license": "GNU General Public License v3.0 only",
        "sbg:image_url": null,
        "sbg:links": [
          {
            "id": "https://daehwankimlab.github.io/hisat2/",
            "label": "HISAT2 Homepage"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-source/download",
            "label": "HISAT2 Source Code"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-Linux_x86_64/download",
            "label": "HISAT2 Download"
          },
          {
            "id": "http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html",
            "label": "HISAT2 Publications"
          },
          {
            "id": "https://daehwankimlab.github.io/hisat2/manual/",
            "label": "HISAT2 Documentation"
          }
        ],
        "sbg:toolkit": "HISAT2",
        "sbg:expand_workflow": false,
        "sbg:wrapperAuthor": "",
        "sbg:projectName": "RNA-Seq Quantification (HISAT2, StringTie) + novel isoform quantification ",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1598956724,
            "sbg:revisionNotes": "Copy of jasmina_miscevic/hisat2-2-2-1-demo/hisat2-extractexons-2-2-1/1"
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1598956887,
            "sbg:revisionNotes": "in_ref_or_index port added in order to skip extracting in wf if HISAT2 index is provided."
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-e4481002/h-e3176c61/h-818c08fd/0",
        "sbg:revision": 1,
        "sbg:revisionNotes": "in_ref_or_index port added in order to skip extracting in wf if HISAT2 index is provided.",
        "sbg:modifiedOn": 1598956887,
        "sbg:modifiedBy": "jasmina_miscevic",
        "sbg:createdOn": 1598956724,
        "sbg:createdBy": "jasmina_miscevic",
        "sbg:project": "jasmina_miscevic/rna-seq-quantification-hisat2-stringtie-novel-isoform-quantification",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "jasmina_miscevic"
        ],
        "sbg:latestRevision": 1,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "a4d51251a427d072cb970ecb60d8b9e2bd98806a918bd9c2e6feeb24879818dd1"
      },
      "label": "HISAT2 ExtractExons",
      "sbg:x": -612.419189453125,
      "sbg:y": 283.9919738769531
    },
    {
      "id": "hisat2_build_2_2_1",
      "in": [
        {
          "id": "in_references_or_index",
          "source": [
            "in_references_or_index"
          ]
        },
        {
          "id": "in_splice_sites",
          "source": "hisat2_extractsplicesites_2_2_1/out_extracted_splice_sites"
        },
        {
          "id": "in_exon",
          "source": "hisat2_extractexons_2_2_1/out_extracted_exons"
        }
      ],
      "out": [
        {
          "id": "out_archive"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "jasmina_miscevic/hisat2-2-2-1-demo/hisat2-build-2-2-1/4",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:category": "Input files",
            "id": "in_references_or_index",
            "type": "File[]",
            "label": "Reference or Index files",
            "doc": "Reference FASTA files for indexing or TAR bundle containing already indexed reference. If TAR bundle is provided indexing part will be skipped and TAR bundle will be forwarded to the output.",
            "sbg:fileTypes": "FASTA, FA, FASTA.GZ, FA.GZ, TAR, TAR.GZ"
          },
          {
            "sbg:category": "Input files",
            "id": "in_snp",
            "type": "File?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.in_snp) {\n\n            var cmd = \"--snp \";\n            cmd = cmd.concat(inputs.in_snp.path);\n            return cmd;\n        }\n    }\n}"
            },
            "label": "SNP file",
            "doc": "SNP file produced by HISAT2 Extract SNPs-Haplotypes UCSC/VCF.",
            "sbg:fileTypes": "SNP"
          },
          {
            "sbg:category": "Input files",
            "id": "in_haplotype",
            "type": "File?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.in_haplotype) {\n            var cmd = \"--haplotype \";\n            cmd = cmd.concat(inputs.in_haplotype.path);\n            return cmd;\n        }\n    }\n}"
            },
            "label": "Haplotype file",
            "doc": "Haplotype file HISAT2 produced by Extract SNPs-Haplotypes UCSC/VCF.",
            "sbg:fileTypes": "HAPLOTYPE"
          },
          {
            "sbg:category": "Input files",
            "id": "in_splice_sites",
            "type": "File?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.in_splice_sites) {\n\n            var cmd = \"--ss \";\n            cmd = cmd.concat(inputs.in_splice_sites.path);\n            return cmd;\n        }\n    }\n\n}"
            },
            "label": "Splice sites file",
            "doc": "Splice sites file produces by HISAT2 Extract Splice Sites.",
            "sbg:fileTypes": "TXT"
          },
          {
            "sbg:category": "Input files",
            "id": "in_exon",
            "type": "File?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.in_exon) {\n\n            var cmd = \"--exon \";\n            cmd = cmd.concat(inputs.in_exon.path);\n            return cmd;\n\n        }\n    }\n}"
            },
            "label": "Exon file",
            "doc": "Exon file produced by HISAT2 Extract Exons.",
            "sbg:fileTypes": "TXT"
          },
          {
            "sbg:category": "Basic Options",
            "id": "seed",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.seed = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.seed) {\n\n            var cmd = \"--seed \";\n            cmd = cmd.concat(inputs.seed);\n            return cmd;\n\n        }\n    }\n\n}"
            },
            "label": "Seed",
            "doc": "Seed for pseudo number generator.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Options",
            "id": "large_index",
            "type": "boolean?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.large_index = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.large_index) {\n\n            return \"--large_index\";\n\n        }\n    }\n}"
            },
            "label": "Force large index",
            "doc": "Force HISAT2 Build to build a large index, even if the reference is less than ~ 4 billion nucleotides long.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Options",
            "sbg:altPrefix": "--noauto",
            "id": "no_auto",
            "type": "boolean?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.no_auto = null;\n    }\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.no_auto) {\n\n            return \"-a\";\n\n        }\n    }\n}"
            },
            "label": "Disable automatic memory fitting",
            "doc": "Disable automatic --bmax/--dcv/--packed fitting according to available memory.",
            "default": 0
          },
          {
            "sbg:category": "Options",
            "id": "bmax",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.bmax = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.bmax) {\n\n            var cmd = \"--bmax \";\n            cmd = cmd.concat(inputs.bmax);\n            return cmd;\n\n        }\n    }\n\n}"
            },
            "label": "Max bucket size",
            "doc": "The maximum number of suffixes allowed in a block. Allowing more suffixes per block makes indexing faster, but increases peak memory usage. This option is configured automatically by default; use -a/--noauto to configure manually.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "4",
            "sbg:category": "Options",
            "id": "bmaxdivn",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.bmaxdivn = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.bmaxdivn) {\n\n            var cmd = \"--bmaxdivn \";\n            cmd = cmd.concat(inputs.bmaxdivn);\n            return cmd;\n        }\n    }\n\n}"
            },
            "label": "Max bucket size (as divisior)",
            "doc": "The maximum number of suffixes allowed in a block, expressed as a fraction of the length of the reference. This option is configured automatically by default; use -a/--noauto to configure manually.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "1024",
            "sbg:category": "Options",
            "id": "dcv",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.dcv = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.dcv) {\n\n            var cmd = \"--dcv \";\n            cmd = cmd.concat(inputs.dcv);\n            return cmd;\n\n        }\n\n    }\n\n\n}"
            },
            "label": "Diff-cover period",
            "doc": "Period for the difference-cover sample. A larger period yields less memory overhead, but may make suffix sorting slower, especially if repeats are present. Must be a power of 2 no greater than 4096. This option is configured automatically by default; use -a/--noauto to configure manually.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Options",
            "id": "nodc",
            "type": "boolean?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.nodc = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.nodc) {\n\n            return \"--nodc\";\n\n        }\n    }\n\n}"
            },
            "label": "No diff-cover",
            "doc": "Disable use of the difference-cover sample. Suffix sorting becomes quadratic-time in the worst case (where the worst case is an extremely repetitive reference).",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Options",
            "sbg:altPrefix": "--noref",
            "id": "noref",
            "type": "boolean?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.noref = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.noref) {\n\n            return \"-r\";\n        }\n    }\n\n}"
            },
            "label": "Disable building packed reference",
            "doc": "Do not build the .3.ht2/.4.ht2 portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Options",
            "sbg:altPrefix": "--justref",
            "id": "justref",
            "type": "boolean?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.justref = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.justref) {\n\n            return \"-3\";\n\n        }\n    }\n}"
            },
            "label": "Build only packed portion",
            "doc": "Build only the .3.ht2/.4.ht2 portions of the index, which contain a bitpacked version of the reference sequences and are used for paired-end alignment.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "4",
            "sbg:category": "Options",
            "sbg:altPrefix": "--offrate",
            "id": "offrate",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.offrate = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.offrate) {\n\n            var cmd = \"-o \";\n            cmd = cmd.concat(inputs.offrate);\n            return cmd;\n        }\n    }\n}"
            },
            "label": "Global marking rate",
            "doc": "To map alignments back to positions on the reference sequences, it's necessary to annotate (\"mark\") some or all of the Burrows-Wheeler rows with their corresponding location on the genome. -o/--offrate governs how many rows get marked: the indexer will mark every 2^<int> rows. Marking more rows makes reference-position lookups faster, but requires more memory to hold the annotations at runtime. The default is 4 (every 16th row is marked; for human genome, annotations occupy about 680 megabytes).",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "10",
            "sbg:category": "Options",
            "sbg:altPrefix": "--ftabchars",
            "id": "ftabchars",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.ftabchars = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.ftabchars) {\n\n            var cmd = \"-t \";\n            cmd = cmd.concat(inputs.ftabchars);\n            return cmd;\n        }\n    }\n\n}"
            },
            "label": "Number of chars in lookup",
            "doc": "The ftab is the lookup table used to calculate an initial Burrows-Wheeler range with respect to the first <int> characters of the query. A larger <int> yields a larger lookup table but faster query times. The ftab has size 4^(<int>+1) bytes.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "3",
            "sbg:category": "Options",
            "id": "localoffrate",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.localoffrate = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.localoffrate) {\n\n            var cmd = \"--localoffrate \";\n            cmd = cmd.concat(inputs.localoffrate);\n            return cmd;\n        }\n    }\n\n}"
            },
            "label": "Local marking rate",
            "doc": "This option governs how many rows get marked in a local index: the indexer will mark every 2^<int> rows. Marking more rows makes reference-position lookups faster, but requires more memory to hold the annotations at runtime. The default is 3 (every 8th row is marked, this occupies about 16KB per local index).",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "6",
            "sbg:category": "Options",
            "id": "localftabchars",
            "type": "int?",
            "inputBinding": {
              "shellQuote": false,
              "position": 3,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.localftabchars = null;\n    }\n\n\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        if (inputs.localftabchars) {\n\n            var cmd = \"--localftabchars \";\n            cmd = cmd.concat(inputs.localftabchars);\n            return cmd;\n        }\n    }\n}"
            },
            "label": "Number of chars in lookup (local index)",
            "doc": "The local ftab is the lookup table in a local index. The default setting is 6 (ftab is 8KB per local index).",
            "default": 0
          },
          {
            "sbg:category": "Additional options",
            "id": "out_prefix",
            "type": "string?",
            "label": "Output file prefix",
            "doc": "Output file prefix."
          },
          {
            "sbg:toolDefaultValue": "16",
            "sbg:category": "Performance options",
            "id": "nthreads",
            "type": "int?",
            "label": "Number of threads",
            "doc": "Launch a specified number of parallel build threads."
          }
        ],
        "outputs": [
          {
            "id": "out_archive",
            "doc": "Archived HISAT2 index files.",
            "label": "Index files",
            "type": "File?",
            "outputBinding": {
              "glob": "*{.tar,.tar.gz}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_references_or_index);\n\n}"
            },
            "sbg:fileTypes": "TAR, TAR.GZ"
          }
        ],
        "doc": "__HISAT2 Build__\u00a0tool builds a HISAT2 index necessary for the __HISAT2__ alignment method.  To create an index, __HISAT2 Build__ uses a genome reference file(s) in FASTA format and outputs a set of 8 files with suffixes .1.ht2, .2.ht2, .3.ht2, .4.ht2, .5.ht2, .6.ht2, .7.ht2, and .8.ht2. In the case of a large index these suffixes will have an ht2l termination. These files together constitute the index: they are all that is needed to align reads to that reference [1].\n\nThe __HISAT2__ indexing scheme is called Hierarchical Graph Ferragina Manzini (HGFM) index. In addition to using one global GFM index that represents the general population,\u00a0__HISAT2__\u00a0uses a large set of small GFM indexes that collectively cover the whole genome (each index representing a genomic region of 56 Kbp, with 55,000 indexes needed to cover the human population). These small indexes (called local indexes) combined with several alignment strategies enable effective alignment of sequencing reads [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of this page.*\n\n***Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.***\n\n### Common Use Cases\n\n* This tool is used to create an index for the __HISAT2__ splice aware aligner.\n* __HISAT2 Build__ can take advantage of known splice sites, exons, SNPs and haplotypes to create an index that will enable the __HISAT2__ aligner to create more accurate alignments. These files can be created using __HISAT2 ExtractExons__, __HISAT2 ExtractSpliceSites__ and __HISAT2 Extract SNPsHaplotypes__. Pre-built index files using these options can be also found on [HISAT2 home page](https://daehwankimlab.github.io/hisat2/download/).\n* __HISAT2 Build__ can generate either small or large indexes. The wrapper will decide which one to generate based on the length of the input genome. If the reference does not exceed 4 billion characters but a large index is preferred, the user can specify `--large-index` to force __HISAT2 Build__  to build a large index instead [1].\n\n### Changes Introduced by Seven Bridges\n\n* The directory containing the index files will be outputted as a TAR bundle (the __Index files__ output). This bundle can then be provided to the __HISAT2__ aligner, which will automatically take care of untarring it and preparing it to run successfully without further issues.\n* __HISAT2 Build__ can accept a TAR bundle containing an already indexed reference instead of a reference FASTA file(s), to skip indexing and reduce processing time if this tool is a part of a workflow.\n* Output file will be prefixed by the input reference file name, unless the **Output file prefix** option is explicitly specified.\n\n### Common Issues and Important Notes\n\n* __Exon__ (`--exon`) and __Splice sites__ (`--ss`) files have to be used together. If exactly one of these options is used, __HISAT2 Build__ will fail. Input files for these two options can be generated from  __HISAT2 ExtractExons__  and __HISAT2 ExtractSpliceSites__ tools.\n* The **Max bucket size** (`--bmax`), **Max bucket size (as divisior)** (`--bmaxdivn`), and **Diff-cover period** (`--dcv`) options are governing the trade off between running time and memory usage and should only be set by advanced users.  __HISAT2 Build__ automatically sets these parameters to their optimal values, that yield the best running time without exhausting memory. This behavior can be disabled using the\u00a0-a/--noauto\u00a0option [1].\n\n### Performance Benchmarking\n\nIn the following table you can find estimates of __HISAT2 Build__ duration and cost. Two different instances were used for benchmarking because __HISAT2 Build__ requires significantly more memory (~ 200GB for human reference [1]) when using some of the following options: __Splice sites file__ (`--ss`), __Exon file__ (`--exon`) and/or __SNP file__ (`--snp`), __Haplotype file__ (`--haplotype`)  opposed to situations where these options are not used. The Seven Bridges version of the tool will dynamically choose an appropriate instance based on the provided inputs. The results shown here are obtained by indexing the human reference genome.  Execution time and cost can vary for other genomes.\n\n*Cost can be significantly reduced by **spot instances** usage. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n| Settings                      | Duration | Cost | Instance (AWS)|\n|-------------------------------|--------------|------------------|---------------|\n| Default (no additional files) | 18min.       | $0.25            | c5.4xlarge    |\n| Using `--ss` and `--exon` options | 51min.    | $1.84           | r5.8xlarge    |\n| Using `--ss`, `--exon` ,`--snp` and `--haplotype` options  | 1h 12min.    | $2.60           | r5.8xlarge    |\n\n### References\n\n[1] [HISAT2 manual page](https://daehwankimlab.github.io/hisat2/manual/)",
        "label": "HISAT2 Build",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format == \"tar\") {\n        return \"echo 'TAR bundle provided at the input, no indexing.'\";\n    } else {\n        if ((inputs.in_splice_sites && !inputs.in_exon) || (!inputs.in_splice_sites && inputs.in_exon)) {\n            return \"echo 'Exon and Splice Sites file should be used together!' && exit 55 && \";\n        }\n\n    }\n\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 1,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        var reference_input_files = [].concat(inputs.in_references_or_index);\n        var cmd = \"\";\n        for (var i = 0; i < reference_input_files.length; i++) {\n\n            var file_path = reference_input_files[i].path;\n            var extension = file_path.split(\".\").slice(-1);\n            if (extension == \"gz\") {\n\n                var new_file_path = file_path.split(\".\").slice(0, -1).join(\".\");\n                cmd = cmd.concat(\"gunzip -c \", file_path, \" > \", new_file_path, \" && \");\n            }\n\n        }\n        return cmd;\n    }\n\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 2,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n        return \"mkdir index_files && /opt/hisat2-2.2.1/hisat2-build\";\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 102,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        var reference_input_files = [].concat(inputs.in_references_or_index);\n        var reference_files_path = [];\n        for (var i = 0; i < reference_input_files.length; i++) {\n\n            var file_path = reference_input_files[i].path;\n            var extension = file_path.split(\".\").slice(-1);\n            if (extension == \"gz\") {\n\n                file_path = file_path.split(\".\").slice(0, -1).join(\".\");\n\n            }\n            reference_files_path.push(file_path);\n        }\n        return reference_files_path.join(\",\");\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 103,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n        var cmd = \"index_file && mv index_file.* index_files && tar -vcf \";\n        var references = [].concat(inputs.in_references_or_index);\n        \n        if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n            if(references.length!=1){\n                cmd=cmd.concat(inputs.out_prefix,\".\",references.length,\".HISAT2-2.2.1.index_files.tar index_files/\");\n            } else {\n                cmd=cmd.concat(inputs.out_prefix,\".HISAT2-2.2.1.index_files.tar index_files/\");\n            }\n            return cmd;\n            \n        } else{\n            \n        if(references.length!=1){\n            \n        var ref_list=[];\n        \n        for (var i = 0; i < references.length; i++) {\n\n            var ref_file = references[i].path.split(\"/\").slice(-1)[0];\n            var ext = ref_file.split(\".\").slice(-1)[0];\n            if (ext == \"gz\") {\n                ref_file = ref_file.split(\".\").slice(0, -2).join(\".\");\n            } else {\n                ref_file = ref_file.split(\".\").slice(0, -1).join(\".\");\n            }\n            \n            ref_list.push(ref_file);\n        }\n        \n        cmd = cmd.concat(ref_list.sort()[0],\".\",references.length,\".HISAT2-2.2.1.index_files.tar index_files/\"); }\n        \n        else {\n            ref_file = references[0].path.split(\"/\").slice(-1)[0];\n            \n            ext = ref_file.split(\".\").slice(-1)[0];\n            \n            if (ext == \"gz\") {\n                ref_file = ref_file.split(\".\").slice(0, -2).join(\".\");\n            } else {\n                ref_file = ref_file.split(\".\").slice(0, -1).join(\".\");\n            }\n            \n            cmd=cmd.concat(ref_file,\".HISAT2-2.2.1.index_files.tar index_files/\");\n        }\n        return cmd;\n\n    }\n    }\n}"
          },
          {
            "prefix": "-p",
            "shellQuote": false,
            "position": 3,
            "valueFrom": "${\n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n        if (inputs.nthreads && inputs.nthreads>0) {\n              return inputs.nthreads;\n        } else if (inputs.in_exon || inputs.in_splice_sites || inputs.in_snp) {  return 32;\n        } else {\n        return 16; }\n    } else {\n        return null; }\n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${ \n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n\n    if (inputs.in_exon || inputs.in_splice_sites || inputs.in_snp) {\n        return 200000;\n    } else {\n        return 10000;\n    }\n    } else {\n        return 1000;\n    }\n\n\n}",
            "coresMin": "${\n    \n    var input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n    if (input_format == \"gz\") {\n        input_format = [].concat(inputs.in_references_or_index)[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n    }\n    if (input_format != \"tar\") {\n    if (inputs.nthreads && inputs.nthreads>0) {\n            return inputs.nthreads;\n        }\n    else if (inputs.in_exon || inputs.in_splice_sites || inputs.in_snp) {\n        return 32;\n    } else {\n        return 16;\n    }\n    } else {\n        return 1;\n    }\n\n\n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/jasmina_miscevic/hisat2-2.2.1:0"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.in_references_or_index)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "sbg:expand_workflow": false,
        "sbg:image_url": null,
        "sbg:toolkitVersion": "2.2.1",
        "sbg:toolkit": "HISAT2",
        "sbg:links": [
          {
            "id": "https://daehwankimlab.github.io/hisat2/",
            "label": "HISAT2 Homepage"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-source/download",
            "label": "HISAT2 Source Code"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-Linux_x86_64/download",
            "label": "HISAT2 Download"
          },
          {
            "id": "http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html",
            "label": "HISAT2 Publications"
          },
          {
            "id": "https://daehwankimlab.github.io/hisat2/manual/",
            "label": "HISAT2 Documentation"
          }
        ],
        "sbg:toolAuthor": "Johns Hopkins University",
        "sbg:license": "GNU General Public License v3.0 only",
        "sbg:categories": [
          "RNA-Seq",
          "Alignment"
        ],
        "sbg:projectName": "HISAT2 2.2.1 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1597960723,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1597960916,
            "sbg:revisionNotes": "HISAT2 Build 2.2.1"
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1599834691,
            "sbg:revisionNotes": "Description modified."
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1612172681,
            "sbg:revisionNotes": "Description and tool categories modified."
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1645090941,
            "sbg:revisionNotes": "Category modified."
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-d8f9bd59/h-9e483d97/h-97120761/0",
        "sbg:revision": 4,
        "sbg:revisionNotes": "Category modified.",
        "sbg:modifiedOn": 1645090941,
        "sbg:modifiedBy": "jasmina_miscevic",
        "sbg:createdOn": 1597960723,
        "sbg:createdBy": "jasmina_miscevic",
        "sbg:project": "jasmina_miscevic/hisat2-2-2-1-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "jasmina_miscevic"
        ],
        "sbg:latestRevision": 4,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "a4ef5ec996ecd8675c8e6acd1b8f804ee744dde7dafb0284cdea074fa925a2574",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "HISAT2 Build",
      "sbg:x": -380.4192199707031,
      "sbg:y": 137.79039001464844
    },
    {
      "id": "hisat2_2_2_1",
      "in": [
        {
          "id": "in_archive",
          "source": "hisat2_build_2_2_1/out_archive"
        },
        {
          "id": "in_reads",
          "source": [
            "sbg_pair_fastqs_by_metadata/tuple_list"
          ]
        },
        {
          "id": "downstream_transcriptome_assembly",
          "default": true
        },
        {
          "id": "remove_chrname",
          "source": "remove_chrname"
        },
        {
          "id": "add_chrname",
          "source": "add_chrname"
        }
      ],
      "out": [
        {
          "id": "out_alignment"
        },
        {
          "id": "out_novel_splicesite"
        },
        {
          "id": "out_metrics_file"
        },
        {
          "id": "out_alignment_summary"
        },
        {
          "id": "out_unpaired_unaligned"
        },
        {
          "id": "out_unpaired_aligned"
        },
        {
          "id": "out_unaligned_concordantly"
        },
        {
          "id": "out_aligned_concordantly"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "jasmina_miscevic/hisat2-2-2-1-demo/hisat2-2-2-1/4",
        "baseCommand": [],
        "inputs": [
          {
            "sbg:category": "Input files",
            "id": "in_archive",
            "type": "File",
            "label": "Indexed reference",
            "doc": "Indexed reference files produced by HISAT2 Build 2.2.1.",
            "sbg:fileTypes": "TAR, TAR.GZ, TAR.BZ2"
          },
          {
            "sbg:category": "Input files",
            "id": "in_reads",
            "type": "File[]",
            "inputBinding": {
              "shellQuote": false,
              "position": 102,
              "valueFrom": "${\n    if (inputs.in_reads) {\n        var cmd = \"\";\n        var reads = [].concat(inputs.in_reads);\n        var reads1 = [];\n        var reads2 = [];\n        var u_reads = [];\n        for (var i = 0; i < reads.length; i++) {\n            if (reads[i].metadata && reads[i].metadata.paired_end) {\n                if (reads[i].metadata.paired_end == 1) {\n                    reads1.push(reads[i].path);\n                } else if (reads[i].metadata.paired_end == 2) {\n                    reads2.push(reads[i].path);\n                }\n            } else {\n                u_reads.push(reads[i].path);\n            }\n        }\n        if (reads1.length > 0 && reads1.length == reads2.length) {\n            cmd = \"-1 \" + reads1.join(\",\") + \" -2 \" + reads2.join(\",\");\n        }\n        if (u_reads.length > 0) {\n            cmd = \" -U \" + u_reads.join(\",\");\n        }\n        return cmd;\n    }\n}"
            },
            "label": "Reads",
            "doc": "Read files in FASTQ or FASTA format. Could be also gzip'ed (extension .gz) or bzip2'ed (extension .bz2).",
            "sbg:fileTypes": "FASTQ, FQ, FASTQ.GZ, FQ.GZ, FASTQ.BZ2, FQ.BZ2, FASTA, FA, FASTA.GZ, FA.GZ, FASTA.BZ2, FA.BZ2"
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Input options",
            "sbg:altPrefix": "-s",
            "id": "skip",
            "type": "int?",
            "inputBinding": {
              "prefix": "--skip",
              "shellQuote": false,
              "position": 1
            },
            "label": "Skip first <n> reads",
            "doc": "Skip (i.e. do not align) the first <n> reads or pairs of reads in the input."
          },
          {
            "sbg:toolDefaultValue": "No limit.",
            "sbg:category": "Input options",
            "sbg:altPrefix": "-u",
            "id": "upto",
            "type": "int?",
            "inputBinding": {
              "prefix": "--upto",
              "shellQuote": false,
              "position": 1
            },
            "label": "Align first <n> reads",
            "doc": "Align the first <n> reads or read pairs from the input (after the -s/--skip reads or pairs have been skipped), then stop. Default: no limit."
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Input options",
            "sbg:altPrefix": "-5",
            "id": "trim5",
            "type": "int?",
            "inputBinding": {
              "prefix": "--trim5",
              "shellQuote": false,
              "position": 1
            },
            "label": "Trim 5' end",
            "doc": "Trim <n> bases from 5' (left) end of each read before alignment."
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Input options",
            "sbg:altPrefix": "-3",
            "id": "trim3",
            "type": "int?",
            "inputBinding": {
              "prefix": "--trim3",
              "shellQuote": false,
              "position": 1
            },
            "label": "Trim 3' end",
            "doc": "Trim <n> bases from 3' (right) end of each read before alignment."
          },
          {
            "sbg:category": "Input options",
            "sbg:toolDefaultValue": "FALSE",
            "id": "phred64",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--phred64",
              "shellQuote": false,
              "position": 1
            },
            "label": "Phred +64 encoding",
            "doc": "Input qualities are ASCII chars equal to the Phred quality plus 64. This is also called the \"Phred+64\" encoding. \nDefault in HISAT2 is \"Phred+33\" encoding, which is used by the very latest Illumina pipelines (starting from Illumina 1.8)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Input options",
            "id": "solexa_qual",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--solexa-quals",
              "shellQuote": false,
              "position": 1
            },
            "label": "Solexa qualities",
            "doc": "Convert input qualities from Solexa (which can be negative) to Phred (which can't). This scheme was used in older Illumina GA Pipeline versions (prior to 1.3)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Input options",
            "id": "int_quals",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--int-quals",
              "shellQuote": false,
              "position": 1
            },
            "label": "Integer qualities",
            "doc": "Quality values are represented in the read input file as space-separated ASCII integers, e.g., 40 40 30 40..., rather than ASCII characters, e.g., II?I.... Integers are treated as being on the Phred quality scale unless --solexa-quals is also specified."
          },
          {
            "sbg:toolDefaultValue": "L,0,0.15",
            "sbg:category": "Alignment options",
            "id": "n_ceil",
            "type": "string?",
            "inputBinding": {
              "prefix": "--n-ceil",
              "shellQuote": false,
              "position": 1
            },
            "label": "Maximum number of ambiguous characters",
            "doc": "Sets a function governing the maximum number of ambiguous characters (usually Ns and/or .s) allowed in a read as a function of read length. For instance, specifying -L,0,0.15 sets the N-ceiling function f to f(x) = 0 + 0.15 * x, where x is the read length. Reads exceeding this ceiling are filtered out."
          },
          {
            "sbg:category": "Alignment options",
            "id": "ignore_qulas",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--ignore-quals",
              "shellQuote": false,
              "position": 1
            },
            "label": "Ignore quality",
            "doc": "When calculating a mismatch penalty, always consider the quality value at the mismatched position to be the highest possible, regardless of the actual value. I.e. input is treated as though all quality values are high. This is also the default behavior when the input doesn\u2019t specify quality values (e.g. reads are in FASTA files)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Alignment options",
            "id": "nofw",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--nofw",
              "shellQuote": false,
              "position": 1
            },
            "label": "No forward",
            "doc": "If --nofw is specified, HISAT2 will not attempt to align unpaired reads to the forward (Watson) reference strand."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Alignment options",
            "id": "norc",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--norc",
              "shellQuote": false,
              "position": 1
            },
            "label": "No reverse complement",
            "doc": "If --norc is specified, HISAT2 will not attempt to align unpaired reads against the reverse-complement (Crick) reference strand."
          },
          {
            "sbg:toolDefaultValue": "MX = 6, MN = 2",
            "sbg:category": "Scoring options",
            "id": "mp",
            "type": [
              "null",
              {
                "type": "record",
                "fields": [
                  {
                    "sbg:toolDefaultValue": "2",
                    "name": "mp_min",
                    "type": "int?",
                    "inputBinding": {
                      "prefix": "--mp",
                      "shellQuote": false,
                      "position": 0,
                      "sbg:cmdInclude": "true"
                    },
                    "label": "MIN"
                  },
                  {
                    "sbg:stageInput": null,
                    "sbg:toolDefaultValue": "6",
                    "name": "mp_max",
                    "type": "int?",
                    "label": "MAX"
                  }
                ],
                "name": "mp"
              }
            ],
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Mismatch penalties",
            "doc": "Sets the maximum (MX) and minimum (MN) mismatch penalties. A number less than or equal to MX and greater than or equal to MN is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an N. If --ignore-quals is specified, the number subtracted equals MX. Otherwise, the number subtracted is MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) ) where Q is the Phred quality value."
          },
          {
            "sbg:toolDefaultValue": "MX = 2, MN = 1",
            "sbg:category": "Scoring options",
            "id": "sp",
            "type": [
              "null",
              {
                "type": "record",
                "fields": [
                  {
                    "sbg:toolDefaultValue": "1",
                    "name": "sp_min",
                    "type": "int?",
                    "inputBinding": {
                      "prefix": "--sp",
                      "shellQuote": false,
                      "position": 0,
                      "sbg:cmdInclude": "true"
                    },
                    "label": "MIN"
                  },
                  {
                    "sbg:stageInput": null,
                    "sbg:toolDefaultValue": "2",
                    "name": "sp_max",
                    "type": "int?",
                    "label": "MAX"
                  }
                ],
                "name": "sp"
              }
            ],
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Soft-clipping penalties",
            "doc": "Sets the maximum (MX) and minimum (MN) penalties for soft-clipping per base. A number less than or equal to MX and greater than or equal to MN is subtracted from the alignment score for each position. The number subtracted is MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) ) where Q is the Phred quality value."
          },
          {
            "sbg:category": "Scoring options",
            "id": "no_softclip",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-softclip",
              "shellQuote": false,
              "position": 1
            },
            "label": "No soft-clipping",
            "doc": "Disallow soft-clipping"
          },
          {
            "sbg:toolDefaultValue": "1",
            "sbg:category": "Scoring options",
            "id": "np",
            "type": "int?",
            "inputBinding": {
              "prefix": "--np",
              "shellQuote": false,
              "position": 1
            },
            "label": "Penalty for missing positions",
            "doc": "Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as N."
          },
          {
            "sbg:category": "Scoring options",
            "id": "rdg",
            "type": [
              "null",
              {
                "type": "record",
                "fields": [
                  {
                    "sbg:toolDefaultValue": "5",
                    "name": "rdg_open",
                    "type": "int?",
                    "inputBinding": {
                      "prefix": "--rdg",
                      "shellQuote": false,
                      "position": 0,
                      "sbg:cmdInclude": "true"
                    },
                    "label": "Gap open penalties"
                  },
                  {
                    "sbg:toolDefaultValue": "3",
                    "name": "rdg_extend",
                    "type": "int?",
                    "label": "Gap extended penalties"
                  }
                ],
                "name": "rdg"
              }
            ],
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Read gap penalty",
            "doc": "Sets the read gap open (<n1>) and extend (<n2>) penalties. A read gap of length N gets a penalty of <n1> + N * <n2>."
          },
          {
            "sbg:category": "Scoring options",
            "id": "rfg",
            "type": [
              "null",
              {
                "type": "record",
                "fields": [
                  {
                    "sbg:toolDefaultValue": "5",
                    "name": "rfg_open",
                    "type": "int?",
                    "inputBinding": {
                      "prefix": "--rfg",
                      "shellQuote": false,
                      "position": 0,
                      "sbg:cmdInclude": "true"
                    },
                    "label": "Reference open penalties"
                  },
                  {
                    "sbg:toolDefaultValue": "3",
                    "name": "rfg_extend",
                    "type": "int?",
                    "label": "Reference extended penalties"
                  }
                ],
                "name": "rfg"
              }
            ],
            "inputBinding": {
              "shellQuote": false,
              "position": 2
            },
            "label": "Reference gap penalty",
            "doc": "Sets the reference gap open (<n1>) and extend (<n2>) penalties. A reference gap of length N gets a penalty of <n1> + N * <n2>."
          },
          {
            "sbg:toolDefaultValue": "L,0,-0.2",
            "sbg:category": "Scoring options",
            "id": "score_min",
            "type": "string?",
            "inputBinding": {
              "prefix": "--score-min",
              "shellQuote": false,
              "position": 1
            },
            "label": "Minimum-score function",
            "doc": "Sets a function governing the minimum alignment score needed for an alignment to be considered \"valid\" (i.e. good enough to report). This is a function of read length. For instance, specifying L,0,-0.6 sets the minimum-score function f to f(x) = 0 + -0.6 * x, where x is the read length."
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Spliced alignment options",
            "id": "pen_cansplice",
            "type": "int?",
            "inputBinding": {
              "prefix": "--pen-cansplice",
              "shellQuote": false,
              "position": 1
            },
            "label": "Canonical splice site penalty",
            "doc": "Sets the penalty for each pair of canonical splice sites (e.g. GT/AG)."
          },
          {
            "sbg:toolDefaultValue": "12",
            "sbg:category": "Spliced alignment options",
            "id": "pen_noncansplice",
            "type": "int?",
            "inputBinding": {
              "prefix": "--pen-noncansplice",
              "shellQuote": false,
              "position": 1
            },
            "label": "Non canonical splice site penalty",
            "doc": "Sets the penalty for each pair of non-canonical splice sites (e.g. non-GT/AG)."
          },
          {
            "sbg:toolDefaultValue": "G,-8,1",
            "sbg:category": "Spliced alignment options",
            "id": "pen_canintronlen",
            "type": "string?",
            "inputBinding": {
              "prefix": "--pen-canintronlen",
              "shellQuote": false,
              "position": 1
            },
            "label": "Long introns with canonical splice sites penalty",
            "doc": "Sets the penalty for long introns with canonical splice sites so that alignments with shorter introns are preferred to those with longer ones."
          },
          {
            "sbg:toolDefaultValue": "G,-8,1",
            "sbg:category": "Spliced alignment options",
            "id": "pen_noncanintronlen",
            "type": "string?",
            "inputBinding": {
              "prefix": "--pen-noncanintronlen",
              "shellQuote": false,
              "position": 1
            },
            "label": "Long introns with noncanonical splice sites penalty",
            "doc": "Sets the penalty for long introns with noncanonical splice sites so that alignments with shorter introns are preferred to those with longer ones."
          },
          {
            "sbg:toolDefaultValue": "20",
            "sbg:category": "Spliced alignment options",
            "id": "min_intronlen",
            "type": "int?",
            "inputBinding": {
              "prefix": "--min-intronlen",
              "shellQuote": false,
              "position": 1
            },
            "label": "Minimum intron length",
            "doc": "Sets minimum intron length."
          },
          {
            "sbg:toolDefaultValue": "500000",
            "sbg:category": "Spliced alignment options",
            "id": "max_intronlen",
            "type": "int?",
            "inputBinding": {
              "prefix": "--max-intronlen",
              "shellQuote": false,
              "position": 1
            },
            "label": "Maximum intron length",
            "doc": "Sets maximum intron length."
          },
          {
            "sbg:category": "Spliced alignment options",
            "id": "in_known_splicesites",
            "type": "File?",
            "inputBinding": {
              "prefix": "--known-splicesite-infile",
              "shellQuote": false,
              "position": 1
            },
            "label": "Known splice sites",
            "doc": "With this mode, you can provide a list of known splice sites, which HISAT2 makes use of to align reads with small anchors. You can create such a list using HISAT2 ExtractSpliceSites. Note that it is better to use indexes built using annotated transcripts, which works better than using this option. It has no effect to provide splice sites that are already included in the indexes.",
            "sbg:fileTypes": "TXT"
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Spliced alignment options",
            "id": "novel_splicesite_outfile",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--novel-splicesite-outfile",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.novel_splicesite_outfile = null\n    };\n\n\n    if (inputs.novel_splicesite_outfile) {\n        return \"novel_splice_sites.txt\";\n    }\n}"
            },
            "label": "Output novel splice sites",
            "doc": "In this mode, HISAT2 reports a list of splice sites in the file : chromosome name `` genomic position of the flanking base on the left side of an intron `` genomic position of the flanking base on the right `` strand.",
            "default": 0
          },
          {
            "sbg:category": "Spliced alignment options",
            "id": "in_novel_splicesites",
            "type": "File?",
            "inputBinding": {
              "prefix": "--novel-splicesite-infile",
              "shellQuote": false,
              "position": 1
            },
            "label": "Novel splice site input file",
            "doc": "With this mode, you can provide a list of novel splice sites that were generated from the option \"--novel-splicesite-outfile\".",
            "sbg:fileTypes": "TXT"
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Spliced alignment options",
            "id": "no_temp_splicesite",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-temp-splicesite",
              "shellQuote": false,
              "position": 1
            },
            "label": "No temp splice sites",
            "doc": "HISAT2, by default, makes use of splice sites found by earlier reads to align later reads in the same run, in particular, reads with small anchors (<= 15 bp). The option disables this default alignment strategy."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Spliced alignment options",
            "id": "no_spliced_alignement",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-spliced-alignment",
              "shellQuote": false,
              "position": 1
            },
            "label": "No splice alignment",
            "doc": "Disable splice alignment."
          },
          {
            "sbg:category": "Spliced alignment options",
            "id": "rna_strandness",
            "type": [
              "null",
              {
                "type": "enum",
                "symbols": [
                  "F",
                  "R",
                  "FR",
                  "RF"
                ],
                "name": "rna_strandness"
              }
            ],
            "inputBinding": {
              "prefix": "--rna-strandness",
              "shellQuote": false,
              "position": 1
            },
            "label": "RNA strandness",
            "doc": "Specify strand-specific information: the default is unstranded. For single-end reads, use F or R. 'F' means a read corresponds to a transcript. 'R' means a read corresponds to the reverse complemented counterpart of a transcript. For paired-end reads, use either FR or RF. With this option being used, every read alignment will have an XS attribute tag: '+' means a read belongs to a transcript on '+' strand of genome. '-' means a read belongs to a transcript on '-' strand of genome."
          },
          {
            "sbg:category": "Spliced alignment options",
            "sbg:altPrefix": "--tmo",
            "id": "transctiptome_mapping_only",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--transcriptome-mapping-only",
              "shellQuote": false,
              "position": 1
            },
            "label": "Transcriptome mapping only",
            "doc": "Report only those alignments within known transcripts."
          },
          {
            "sbg:category": "Spliced alignment options",
            "sbg:altPrefix": "--dta",
            "sbg:toolDefaultValue": "FALSE",
            "id": "downstream_transcriptome_assembly",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--downstream-transcriptome-assembly",
              "shellQuote": false,
              "position": 1
            },
            "label": "Downstream transcriptome assembly",
            "doc": "Report alignments tailored for transcript assemblers including StringTie. With this option, HISAT2 requires longer anchor lengths for de novo discovery of splice sites. This leads to fewer alignments with short-anchors, which helps transcript assemblers improve significantly in computation and memory usage."
          },
          {
            "sbg:category": "Spliced alignment options",
            "sbg:toolDefaultValue": "FALSE",
            "id": "dta_cufflinks",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--dta-cufflinks",
              "shellQuote": false,
              "position": 1
            },
            "label": "Downstream transcriptome assembly - Cufflinks",
            "doc": "Report alignments tailored specifically for Cufflinks. In addition to what HISAT2 does with the above option (--dta), it also looks for novel splice sites with three signals (GT/AG, GC/AG, AT/AC), but all user-provided splice sites are used irrespective of their signals. HISAT2 produces an optional field, XS:A:[+-], for every spliced alignment."
          },
          {
            "sbg:category": "Spliced alignment options",
            "id": "no_templatelen_adjustment",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-templatelen-adjustment",
              "shellQuote": false,
              "position": 1
            },
            "label": "No template length adjustment",
            "doc": "Disables template length adjustment"
          },
          {
            "sbg:toolDefaultValue": "5 (HFM) or 10 (HGFM)",
            "sbg:category": "Reporting options",
            "id": "distinct_alignments",
            "type": "int?",
            "inputBinding": {
              "prefix": "-k",
              "shellQuote": false,
              "position": 1
            },
            "label": "Max distinct alignments",
            "doc": "It searches for at most <n> distinct, primary alignments for each read. Primary alignments mean alignments whose alignment score is equal or higher than any other alignments. The search terminates when it can't find more distinct valid alignments, or when it finds <n>, whichever happens first. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM 'secondary' bit (which equals 256) set in its FLAGS field. For reads that have more than <n> distinct, valid alignments, hisat2 does not guarantee that the <n> alignments reported are the best possible in terms of alignment score. Default: 5 (HFM) or 10 (HGFM)  Note: HISAT2 is not designed with large values for -k in mind, and when aligning reads to long, repetitive genomes large -k can be very, very slow."
          },
          {
            "sbg:category": "Reporting options",
            "id": "max_seeds",
            "type": "int?",
            "inputBinding": {
              "prefix": "--max-seeds",
              "shellQuote": false,
              "position": 1
            },
            "label": "Maximum number of seeds",
            "doc": "HISAT2, like other aligners, uses seed-and-extend approaches. HISAT2 tries to extend seeds to full-length alignments. In HISAT2, --max-seeds is used to control the maximum number of seeds that will be extended. HISAT2 extends up to these many seeds and skips the rest of the seeds. Large values for --max-seeds may improve alignment sensitivity, but HISAT2 is not designed with large values for --max-seeds in mind, and when aligning reads to long, repetitive genomes large --max-seeds can be very, very slow. The default value is the maximum of 5 and the value that comes with-k."
          },
          {
            "sbg:category": "Reporting options",
            "id": "secondary",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--secondary",
              "shellQuote": false,
              "position": 1
            },
            "label": "Secondary alignment",
            "doc": "Report secondary alignment"
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Paired-end options",
            "sbg:altPrefix": "-I",
            "id": "minins",
            "type": "int?",
            "inputBinding": {
              "prefix": "--minins",
              "shellQuote": false,
              "position": 1
            },
            "label": "Minimum fragment length",
            "doc": "The minimum fragment length for valid paired-end alignments.This option is valid only with --no-spliced-alignment. E.g. if --minins 60 is specified and a paired-end alignment consists of two 20-bp alignments in the appropriate orientation with a 20-bp gap between them, that alignment is considered valid (as long as --maxins is also satisfied). A 19-bp gap would not be valid in that case. If trimming options -3 or -5 are also used, the --minins constraint is applied with respect to the untrimmed mates.  The larger the difference between --minins and --maxins, the slower HISAT2 will run. This is because larger differences between --minins and --maxins require that HISAT2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient.  Default: 0 (essentially imposing no minimum)"
          },
          {
            "sbg:toolDefaultValue": "500",
            "sbg:category": "Paired-end options",
            "sbg:altPrefix": "-X",
            "id": "maxins",
            "type": "int?",
            "inputBinding": {
              "prefix": "--maxins",
              "shellQuote": false,
              "position": 1
            },
            "label": "Maximum fragment length",
            "doc": "The maximum fragment length for valid paired-end alignments. This option is valid only with --no-spliced-alignment. E.g. if --maxins 100 is specified and a paired-end alignment consists of two 20-bp alignments in the proper orientation with a 60-bp gap between them, that alignment is considered valid (as long as --minins is also satisfied). A 61-bp gap would not be valid in that case. If trimming options -3 or -5 are also used, the --maxins constraint is applied with respect to the untrimmed mates, not the trimmed mates.  The larger the difference between --minins and --maxins, the slower HISAT2 will run. This is because larger differences between --minins and --maxins require that HISAT2 scan a larger window to determine if a concordant alignment exists. For typical fragment length ranges (200 to 400 nucleotides), HISAT2 is very efficient.  Default: 500."
          },
          {
            "sbg:toolDefaultValue": "Forward-reverse",
            "sbg:category": "Paired-end options",
            "id": "mate_orientations",
            "type": [
              "null",
              {
                "type": "enum",
                "symbols": [
                  "Forward-reverse",
                  "Reverse-forward",
                  "Forward-forward"
                ],
                "name": "mate_orientations"
              }
            ],
            "inputBinding": {
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.mate_orientations = null;\n    };\n\n\n    if (inputs.mate_orientations) {\n        var cmd = \"\";\n        if (inputs.mate_orientations == 'Forward-reverse') {\n            cmd = \"--fr\";\n        } else if (inputs.mate_orientations == 'Forward-forward') {\n            cmd = \"--ff\";\n        } else if (inputs.mate_orientations == 'Reverse-forward') {\n            cmd = \"--rf\";\n        }\n        return cmd;\n    }\n\n}"
            },
            "label": "Mate orientations",
            "doc": "The upstream/downstream mate orientations for a valid paired-end alignment against the forward reference strand. E.g., if --fr is specified and there is a candidate paired-end alignment where mate 1 appears upstream of the reverse complement of mate 2 and the fragment length constraints (--minins and --maxins) are met, that alignment is valid. Also, if mate 2 appears upstream of the reverse complement of mate 1 and all other constraints are met, that too is valid. --rf likewise requires that an upstream mate1 be reverse-complemented and a downstream mate2 be forward-oriented. --ff requires both an upstream mate 1 and a downstream mate 2 to be forward-oriented. Default: --fr (appropriate for Illumina's Paired-end Sequencing Assay).",
            "default": 0
          },
          {
            "sbg:category": "Paired-end options",
            "id": "no_mixed",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-mixed",
              "shellQuote": false,
              "position": 1
            },
            "label": "No mixed alignments",
            "doc": "By default, when hisat2 cannot find a concordant or discordant alignment for a pair, it then tries to find alignments for the individual mates. This option disables that behavior."
          },
          {
            "sbg:category": "Paired-end options",
            "id": "no_discordant",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-discordant",
              "shellQuote": false,
              "position": 1
            },
            "label": "No discordant alignments",
            "doc": "By default, hisat2 looks for discordant alignments if it cannot find any concordant alignments. A discordant alignment is an alignment where both mates align uniquely, but that does not satisfy the paired-end constraints (--fr/--rf/--ff, --minins, --maxins). This option disables that behavior."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Output options",
            "id": "unpaired_unaligned",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--un",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.unpaired_unaligned = null;\n    }\n\n\n    if (inputs.unpaired_unaligned) {\n        if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    var file_name=inputs.out_prefix + \".UnpairedUnaligned.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnpairedUnaligned.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnpairedUnaligned.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name + ext2;\n                }\n            \n            return file_name + ext;\n        } \n    }\n}"
            },
            "label": "Write unpaired unaligned reads",
            "doc": "Write unpaired reads that fail to align to file at <path>. These reads correspond to the SAM records with the FLAGS 0x4 bit set and neither the 0x40 nor 0x80 bits set. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Output options",
            "id": "unpaired_aligned",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--al",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.unpaired_aligned = null;\n    }\n\n\n    if (inputs.unpaired_aligned) {\n        if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".UnpairedAligned.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnpairedAligned.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnpairedAligned.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name + ext2;\n            }\n            return file_name + ext\n        } \n    }\n}"
            },
            "label": "Write unpaired aligned reads",
            "doc": "Write unpaired reads that align at least once to a file. These reads correspond to the SAM records with the FLAGS 0x4, 0x40, and 0x80 bits unset. Reads written in this way will appear exactly as they did in the input file, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the input.",
            "default": 0
          },
          {
            "sbg:category": "Output options",
            "id": "unaligned_concordantly",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--un-conc",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.unaligned_concordantly = null;\n    }\n\n\n    if (inputs.unaligned_concordantly) {\n        if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".UnalignedConcordantly_%.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnalignedConcordantly_%.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnalignedConcordantly_%.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name  + ext2;\n            }\n            return file_name + ext;\n        } \n    }\n}"
            },
            "label": "Write unaligned concordantly reads",
            "doc": "Write paired-end reads that fail to align concordantly to a file. These reads correspond to the SAM records with the FLAGS 0x4 bit set and either the 0x40 or 0x80 bit set (depending on whether it's mate #1 or #2). .1 and .2 strings are added to the filename to distinguish which file contains mate #1 and mate #2. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Output options",
            "id": "aligned_concordantly",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--al-conc",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.aligned_concordantly = null;\n    }\n\n\n    if (inputs.aligned_concordantly) {\n        if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".AlignedConcordantly_%.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".AlignedConcordantly_%.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".AlignedConcordantly_%.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name  + ext2;\n            }\n            return file_name  + ext;\n        } \n    }\n}"
            },
            "label": "Write aligned concordantly reads",
            "doc": "Write paired-end reads that align concordantly at least once to a file. These reads correspond to the SAM records with the FLAGS 0x4 bit unset and either the 0x40 or 0x80 bit set (depending on whether it's mate #1 or #2). '1' and '2' strings are added to the filename to distinguish which file contains mate #1 and mate #2. Reads written in this way will appear exactly as they did in the input files, without any modification (same sequence, same name, same quality string, same quality encoding). Reads will not necessarily appear in the same order as they did in the inputs.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Output options",
            "id": "metrics_file",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--met-file",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.metrics_file = null;\n    }\n\n\n    if (inputs.metrics_file) {\n        return \"metrics.txt\";\n    }\n}"
            },
            "label": "Metrics file",
            "doc": "Write hisat2 metrics to a file.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Output options",
            "id": "summary_file",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--summary-file",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (self == 0) {\n        self = null;\n        inputs.summary_file = null;\n    }\n\n\n    if (inputs.summary_file) {\n        return \"summary.txt\";\n    }\n}"
            },
            "label": "Summary file",
            "doc": "Write alignment summary to a file.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "no_unal",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-unal",
              "shellQuote": false,
              "position": 1
            },
            "label": "Dismiss unaligned reads",
            "doc": "Suppress SAM records for reads that failed to align."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "no_hd",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-hd",
              "shellQuote": false,
              "position": 1
            },
            "label": "No header",
            "doc": "Suppress SAM header lines (starting with @)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "no_sq",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--no-sq",
              "shellQuote": false,
              "position": 1
            },
            "label": "No @SQ lines",
            "doc": "Suppress @SQ SAM header lines."
          },
          {
            "sbg:category": "SAM options",
            "sbg:toolDefaultValue": "1",
            "id": "rg_id",
            "type": "string?",
            "label": "Read group ID",
            "doc": "Specify the read group ID for the SAM @RG header line. It also causes the RG:Z: extra field to be attached to each SAM output record, with value set to read group ID. \nNote: If not specified read group  ID will be set to 1."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "remove_chrname",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--remove-chrname",
              "shellQuote": false,
              "position": 1
            },
            "label": "Remove 'chr' string",
            "doc": "Remove 'chr' from reference names in alignment (e.g., chr18 to 18)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "add_chrname",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--add-chrname",
              "shellQuote": false,
              "position": 1
            },
            "label": "Add 'chr' string",
            "doc": "Add 'chr' to reference names in alignment (e.g., 18 to chr18)."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "SAM options",
            "id": "omit_sec_seq",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--omit-sec-seq",
              "shellQuote": false,
              "position": 1
            },
            "label": "Omit secondary sequence",
            "doc": "When printing secondary alignments, HISAT2 by default will write out the SEQ and QUAL strings. Specifying this option causes HISAT2 to print an asterisk in those fields instead."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Performance options",
            "id": "reorder",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--reorder",
              "shellQuote": false,
              "position": 1
            },
            "label": "Reorder reads",
            "doc": "Guarantees that output SAM records are printed in an order corresponding to the order of the reads in the original input file."
          },
          {
            "sbg:toolDefaultValue": "4",
            "sbg:category": "Other options",
            "sbg:altPrefix": "-p",
            "id": "nthreads",
            "type": "int?",
            "inputBinding": {
              "prefix": "--threads",
              "shellQuote": false,
              "position": 1,
              "valueFrom": "${\n    if (inputs.nthreads && inputs.nthreads > 0) {\n            return inputs.nthreads;\n        } else {\n        return 4;\n    }\n}"
            },
            "label": "Number of threads",
            "doc": "Number of parallel threads to be used during alignment.",
            "default": 0
          },
          {
            "sbg:toolDefaultValue": "0",
            "sbg:category": "Other options",
            "id": "seed",
            "type": "int?",
            "inputBinding": {
              "prefix": "--seed",
              "shellQuote": false,
              "position": 1
            },
            "label": "Seed",
            "doc": "Seed for pseudo-number generator."
          },
          {
            "sbg:toolDefaultValue": "FALSE",
            "sbg:category": "Other options",
            "id": "non_deterministic",
            "type": "boolean?",
            "inputBinding": {
              "prefix": "--non-deterministic",
              "shellQuote": false,
              "position": 1
            },
            "label": "Non deterministic seed",
            "doc": "Normally, HISAT2 re-initializes its pseudo-random generator for each read. It seeds the generator with a number derived from (a) the read name, (b) the nucleotide sequence, (c) the quality sequence, (d) the value of the 'seed' option. This means that if two reads are identical (same name, same nucleotides, same qualities) HISAT2 will find and report the same alignment(s) for both, even if there was ambiguity. When 'non-deterministic' is specified, HISAT2 re-initializes its pseudo-random generator for each read using the current time. This means that HISAT2 will not necessarily report the same alignment for two identical reads. This is counter-intuitive for some users, but might be more appropriate in situations where the input consists of many identical reads."
          },
          {
            "sbg:toolDefaultValue": "Sorted BAM",
            "sbg:category": "Output options",
            "id": "output_type",
            "type": [
              "null",
              {
                "type": "enum",
                "symbols": [
                  "Sorted BAM",
                  "Unsorted BAM",
                  "Unsorted SAM"
                ],
                "name": "output_type"
              }
            ],
            "label": "Output type",
            "doc": "Output type for aligned reads."
          },
          {
            "sbg:category": "SAM options - read group",
            "sbg:toolDefaultValue": "FALSE",
            "id": "no_rg",
            "type": "boolean?",
            "label": "No @RG line",
            "doc": "If this boolean argument is specified, no read group line will be set in the resulting SAM/BAM header."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_seq_center",
            "type": "string?",
            "label": "Read group sequencing center",
            "doc": "Specify the sequencing center for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_library",
            "type": "string?",
            "label": "Read group library ID",
            "doc": "Specify the library ID for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_median_insert_size",
            "type": "int?",
            "label": "Read group predicted median insert size",
            "doc": "Specify the median insert size for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_platform",
            "type": [
              "null",
              {
                "type": "enum",
                "symbols": [
                  "Helicos",
                  "Illumina",
                  "ABI SOLiD",
                  "Ion Torrent PGM",
                  "PacBio",
                  "LS 454"
                ],
                "name": "rg_platform"
              }
            ],
            "label": "Read group platform",
            "doc": "Specify the platform/version of technology used to produce the reads for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_platform_unit_id",
            "type": "string?",
            "label": "Read group platform unit ID",
            "doc": "Specify the platform unit ID for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "sbg:toolDefaultValue": "Inferred from metadata",
            "id": "rg_sample_id",
            "type": "string?",
            "label": "Read group sample ID",
            "doc": "Specify the sample ID for RG line."
          },
          {
            "sbg:category": "Read group - SAM options",
            "id": "rg_additional_fields",
            "type": "string[]?",
            "label": "Read group additional fields",
            "doc": "Specify additional fields for @RG line such as: \nDS - Description\nDT - Date the run was produced (ISO8601 date or date/time)\nFO - Flow order\nKS -\tThe array of nucleotide bases that correspond to the key sequence of each read\nPG - Programs used for processing the read group\nPM - Platform model\nSee the SAM Spec for details.\nNote: field should be of the form TAG:VAL,e.g. DS:AAA"
          },
          {
            "sbg:category": "Additional output options",
            "id": "out_prefix",
            "type": "string?",
            "label": "Output prefix",
            "doc": "Prefix to be added to all output files."
          },
          {
            "sbg:category": "Platform options",
            "sbg:toolDefaultValue": "1000",
            "id": "mem_per_job",
            "type": "int?",
            "label": "Memory per job [MB]",
            "doc": "This input allows a user to set the desired memory requirement when running a tool. This input needs to be defined in MB."
          }
        ],
        "outputs": [
          {
            "id": "out_alignment",
            "doc": "Alignment SAM or BAM file.",
            "label": "Output alignment",
            "type": "File",
            "outputBinding": {
              "glob": "{*.bam,*.sam}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads);\n\n}"
            },
            "secondaryFiles": [
              ".bai"
            ],
            "sbg:fileTypes": "SAM, BAM"
          },
          {
            "id": "out_novel_splicesite",
            "doc": "HISAT2 reports a list of splice sites in the file : chromosome name `` genomic position of the flanking base on the left side of an intron `` genomic position of the flanking base on the right `` strand.",
            "label": "Novel splice sites",
            "type": "File?",
            "outputBinding": {
              "glob": "*_novel_splice_sites.txt",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads);\n\n}"
            },
            "sbg:fileTypes": "TXT"
          },
          {
            "id": "out_metrics_file",
            "doc": "HISAT2 alignment metrics.",
            "label": "Metrics file",
            "type": "File?",
            "outputBinding": {
              "glob": "*_metrics.txt",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads);\n\n}"
            },
            "sbg:fileTypes": "TXT"
          },
          {
            "id": "out_alignment_summary",
            "doc": "HISAT2 alignment summary file.",
            "label": "Summary file",
            "type": "File?",
            "outputBinding": {
              "glob": "*_summary.txt",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads);\n\n}"
            },
            "sbg:fileTypes": "TXT"
          },
          {
            "id": "out_unpaired_unaligned",
            "doc": "Unpaired reads that fail to align.",
            "label": "Unpaired unaligned reads",
            "type": "File?",
            "outputBinding": {
              "glob": "${\n    if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    var file_name=inputs.out_prefix + \".UnpairedUnaligned.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnpairedUnaligned.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnpairedUnaligned.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name + ext2;\n                }\n            \n            return file_name + ext;\n            \n            \n        } \n}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads)\n\n}"
            },
            "sbg:fileTypes": "FA, FASTA, FQ, FASTQ, TXT"
          },
          {
            "id": "out_unpaired_aligned",
            "doc": "Unpaired reads that align at least once.",
            "label": "Unpaired aligned reads",
            "type": "File?",
            "outputBinding": {
              "glob": "${\n    if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".UnpairedAligned.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnpairedAligned.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnpairedAligned.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name + ext2;\n            }\n            return file_name + ext;\n        }\n}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads)\n\n}"
            },
            "sbg:fileTypes": "FA, FASTA, FQ, FASTQ, TXT"
          },
          {
            "id": "out_unaligned_concordantly",
            "doc": "Paired-end reads that fail to align concordantly.",
            "label": "Unaligned concordantly reads",
            "type": "File[]?",
            "outputBinding": {
              "glob": "${\n    if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".UnalignedConcordantly_*.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".UnalignedConcordantly_*.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".UnalignedConcordantly_*.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name  + ext2;\n            }\n            return file_name + ext;\n        } \n}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads)\n\n}"
            },
            "sbg:fileTypes": "FA, FASTA, FQ, FASTQ, TXT"
          },
          {
            "id": "out_aligned_concordantly",
            "doc": "Paired-end reads that align concordantly at least once.",
            "label": "Aligned concordantly reads",
            "type": "File[]?",
            "outputBinding": {
              "glob": "${\n    if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                    \n                    var file_name=inputs.out_prefix + \".AlignedConcordantly_*.\";\n                } else if(reads[0].metadata && reads[0].metadata.sample_id){\n                    file_name=reads[0].metadata.sample_id + \".AlignedConcordantly_*.\";\n                } else {\n                    file_name=reads[0].nameroot.split(\".\")[0] + \".AlignedConcordantly_*.\";\n                }\n            if (ext == 'gz' | ext == 'bz2') {\n                var ext2 = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n                return file_name  + ext2;\n            }\n            return file_name  + ext;\n        }\n    \n}",
              "outputEval": "${\n    return inheritMetadata(self, inputs.in_reads)\n\n}"
            },
            "sbg:fileTypes": "FA, FASTA, FQ, FASTQ, TXT"
          }
        ],
        "doc": "**HISAT2** is a fast and sensitive alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes as well as to a single reference genome [1]. \n\n__HISAT2__ (hierarchical indexing for spliced alignment of transcripts 2) aligns both DNA and RNA sequences using a graph Ferragina Manzini (GFM) index. In addition to using one global GFM index that represents the general population,\u00a0__HISAT2__\u00a0uses a large set of small GFM indexes that collectively cover the whole genome (each index representing a genomic region of 56 Kbp, with 55,000 indexes needed to cover the human population). These small indexes (called local indexes) combined with several alignment strategies enable effective alignment of sequencing reads. This new indexing scheme is called Hierarchical Graph FM (HGFM) index [1].\n\n*A list of **all inputs and parameters** with corresponding descriptions can be found at the bottom of this page.*\n\n***Please note that any cloud infrastructure costs resulting from app and pipeline executions, including the use of public apps, are the sole responsibility of you as a user. To avoid excessive costs, please read the app description carefully and set the app parameters and execution settings accordingly.***\n\n### Common Use Cases\n\n- Though **HISAT2** can be used for all types of next-generation sequencing reads, it is mostly used for aligning RNA-Seq data.\n- The __Downstream transcriptome assembly__ (`--downstream-transcriptome-assembly/--dta`) parameter tells __HISAT2__ to report alignments tailored for transcript assemblers including **StringTie**. With this option, __HISAT2__ requires longer anchor lengths for de novo discovery of splice sites. This leads to fewer alignments with short-anchors, which helps transcript assemblers significantly improve computation and memory usage.\n- The __Downstream transcriptome assembly__ - __Cufflinks__ (`--dta-cufflinks`) parameter tells __HISAT2__ to report alignments tailored specifically for **Cufflinks**. In addition to what __HISAT2__ does with the above option (__Downstream transcriptome assembly__), it also looks for novel splice sites with three signals (GT/AG, GC/AG, AT/AC). Nonetheless, all user-provided splice sites are used irrespective of their signals. __HISAT2__ produces an optional field, `XS:A:[+-]`, for every spliced alignment.\n\n\n### Changes Introduced by Seven Bridges\n\n* In order to facilitate and accelerate further RNA-Seq analysis, an additional toolkit __Sambamba (0.7.1)__ is integrated into the same Seven Bridges tool representation alongside __HISAT2 (2.2.1)__. Besides the standard __HISAT2__ SAM output, HISAT2 has been extended to provide two additional output file options: \n     * an **unsorted BAM** file created by piping standard __HISAT2__ output to __Sambamba view__ and \n     * a **coordinate-sorted BAM** file and its Index (BAI) file created by additional piping of the output through __Sambamba sort__ and __Sambamba index__. \n To select the desired output, use the __Output type__ parameter. The default output is a **coordinate-sorted BAM** file.\n* If the __Read group ID__ parameter is not defined, by default it will  be set to \u20181\u2019, unless the __No @RG line__ option is explicitly specified. If the tool is scattered within a workflow, it will assign the __Read group ID__ according to the order of the scattered folders. This also ensures a unique __Read group ID__ when processing multi-read group input data from one sample.\n* All output files will be prefixed by the input sample ID (inferred from the __Sample ID__ metadata field if existent, or from filename otherwise), unless the __Output prefix__ option is explicitly specified.\n\n### Common Issues and Important Notes\n\n- To run __HISAT2,__ properly indexed reference files are required. These files can be either created using the __HISAT2 Build__ tool or downloaded from the [HISAT2 home page](https://daehwankimlab.github.io/hisat2/download/).\n- Some __HISAT2__ options (i.e. __Maximum number of ambiguous characters__ (`--n-ceil`) or __Long introns with canonical splice sites penalty__ (`--pen-canintronlen`)) specify a function rather than an individual number or setting. In these cases, the user specifies three parameters: (a) a function type F, (b) a constant term B, and (c) a coefficient A. The available function types are constant (C), linear (L), square-root (S), and natural log (G). The parameters are specified as F,B,A - that is, the function type, the constant term, and the coefficient are separated by commas with no whitespace. The constant term and coefficient may be negative and/or floating-point numbers [1].\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Example 1: if the function specification is L,-0.4,-0.6, then the function defined is:\n`f(x) = -0.4 + -0.6 * x`\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Example 2: if the function specification is G,1,5.4, then the function defined is:\n`f(x) = 1.0 + 5.4 * ln(x)`\n\n- In a single run, __Reads__ should be either paired or unpaired. __Reads__ may be a mix of different lengths.\n- For paired-end __Reads__, the __Paired-end__ metadata field has to be set to 1 or 2. Paired-end __Reads__ must correspond to each other file-for-file and read-for-read.\n\n### Performance Benchmarking\n\nFor the human reference genome, __HISAT2__ requires about 9 GB of RAM to run properly. In the following table you can find estimates of __HISAT2__ running time and cost. All samples are aligned onto the hg38 human reference index built using reference transcriptome (i.e. using __Splice sites__ (`--ss`) and __Exon__ (`--exon`) options). \n\n*The cost of running __HISAT2__ can be significantly reduced by using **spot instances**. Visit the [Knowledge Center](https://docs.sevenbridges.com/docs/about-spot-instances) for more details.*\n\n| Experiment type | Input size | Paired-end | # of reads | Read length | Duration | Cost | Instance (AWS)|\n|-----------------------|-----------------|------------|-----------------|-------------|--------------|------------------|---------------|\n| RNA-Seq         | 2 x 21.5 GB     | Yes        | 95M            |  101       | 1h 50min.   | $0.99           | c4.2xlarge      |\n| RNA-Seq               | 2 x 10.8 GB       | Yes        | 47.5M            | 101         | 57min.    | $0.51            | c4.2xlarge      |\n| RNA-Seq               | 2 x 2.2 GB       | Yes        | 9.5M            | 101         |  16min.   | $0.14            | c4.2xlarge      |\n| RNA-Seq               | 3.9 GB         | No         | 17.6M           | 51         | 12min.    | $0.11            | c4.2xlarge      |\n\n### References\n\n[1] [HISAT2 manual page](https://daehwankimlab.github.io/hisat2/manual/)",
        "label": "HISAT2",
        "arguments": [
          {
            "prefix": "",
            "shellQuote": false,
            "position": 0,
            "valueFrom": "${  \n    var tar_argument = '';\n    \n    var index_files_extension = inputs.in_archive.nameext;\n    \n    if (index_files_extension == \".tar\") {\n        tar_argument = \" -xf \";\n    } else if (index_files_extension == \".gz\") {\n        tar_argument = \" -xzf \";\n    } else if (index_files_extension == \".bz2\") {\n        tar_argument = \" -xjf \";\n    }\n\n\n    // HISAT Buils doesn't always produce all 8 index files (.1.ht2 - .8.ht2). This depends on HISAT2 Build's input parameters\n    return '/bin/bash -c \"mkdir index_files_folder && tar' + tar_argument + inputs.in_archive.path + ' -C index_files_folder && index_files_path=\\'index_files_folder/*/*.ht2*\\' && index_files_path=\\\\$(echo \\\\$index_files_path) && index_files_path=(\\\\$index_files_path) && index_files_path=\\\\${index_files_path/.[12345678].ht2*/\\'\\'} && /opt/hisat2-2.2.1/hisat2';\n\n}\n"
          },
          {
            "prefix": "-x",
            "shellQuote": false,
            "position": 101,
            "valueFrom": "${\n    return '\\\\$index_files_path';\n}"
          },
          {
            "prefix": "-S",
            "shellQuote": false,
            "position": 103,
            "valueFrom": "${  \n    if (inputs.output_type == \"Unsorted SAM\") {\n        if (inputs.in_reads) {\n            var reads=[].concat(inputs.in_reads);\n            if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n                return inputs.out_prefix + \".HISAT-2.2.1.aligned.sam\";\n            }\n            else if(reads[0].metadata && reads[0].metadata.sample_id){\n                var sample_id=reads[0].metadata.sample_id;\n                return sample_id + \".HISAT-2.2.1.aligned.sam\";\n            }\n            else {\n                var read_name_base=reads[0].nameroot.split(\".\")[0];\n                return read_name_base + \".HISAT-2.2.1.aligned.sam\";\n            }\n        } \n    } else {\n        return \"/dev/stdout\";\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 1,
            "valueFrom": "${\n    if (inputs.in_reads) {\n        var cmd = \"\";\n        var reads = [].concat(inputs.in_reads);\n        var ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-1)[0];\n        if (ext == 'bz2' | ext == 'gz') {\n            ext = reads[0].path.split(\"/\").slice(-1)[0].split(\".\").slice(-2)[0];\n        }\n        \n        if (ext == 'fa' | ext == 'fasta' | ext == 'mfa') {\n            cmd = '-f';\n        }\n        return cmd;\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 151,
            "valueFrom": "${\n    var nthreads = 4;\n    if (inputs.nthreads && inputs.nthreads > 0) {\n        nthreads = inputs.nthreads;\n    }\n\n    if (inputs.in_reads) {\n        var reads=[].concat(inputs.in_reads);\n        \n         if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n             \n             var name_prefix = inputs.out_prefix + \".HISAT2-2.2.1.aligned\";\n             \n         } else if(reads[0].metadata && reads[0].metadata.sample_id) {\n             \n             name_prefix = reads[0].metadata.sample_id + \".HISAT2-2.2.1.aligned\";\n         } else {\n             \n             name_prefix = reads[0].nameroot.split(\".\")[0] + \".HISAT2-2.2.1.aligned\";\n         }\n    } \n\n    if (inputs.output_type == \"Unsorted SAM\") {\n        return \"\";\n    } else if (inputs.output_type == \"Unsorted BAM\") {\n        var cmd = \"| /opt/sambamba-0.7.1 view -t \".concat(nthreads, \" -l 7 -f bam -S /dev/stdin -o \", name_prefix, \".bam\");\n        return cmd;\n    } else {\n        cmd = \"| /opt/sambamba-0.7.1 view -t \".concat(nthreads, \" -l 7 -f bam -S /dev/stdin | /opt/sambamba-0.7.1 sort -t \", nthreads, \" --tmpdir ./ -l 7 -o \", name_prefix, \".sorted.bam /dev/stdin | /opt/sambamba-0.7.1 index -t \", nthreads, \"\");\n        return cmd;\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 201,
            "valueFrom": "${\n    // validation script\n    return ' ;declare -i pipe_statuses=(\\\\${PIPESTATUS[*]});len=\\\\${#pipe_statuses[@]};declare -i tot=0;echo \\\\${pipe_statuses[*]};for (( i=0; i<\\\\${len}; i++ ));do if [ \\\\${pipe_statuses[\\\\$i]} -ne 0 ];then tot=\\\\${pipe_statuses[\\\\$i]}; fi;done;if [ \\\\$tot -ne 0 ]; then >&2 echo Error in piping. Pipe statuses: \\\\${pipe_statuses[*]};fi; if [ \\\\$tot -ne 0 ]; then false;fi'\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 300,
            "valueFrom": "${ //Rename metrics.txt file\n\n    var reads=[].concat(inputs.in_reads);\n    \n    if(inputs.metrics_file){\n        \n        if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n            \n            return '; mv metrics.txt ' + inputs.out_prefix + '_metrics.txt';\n        }\n        else if(reads[0].metadata && reads[0].metadata.sample_id){\n            \n            var sample_id= reads[0].metadata.sample_id;\n            return '; mv metrics.txt ' + sample_id + '_metrics.txt';\n        }\n        else {\n            \n            var input_read_name = reads[0].nameroot.split('.')[0];\n            return '; mv metrics.txt ' + input_read_name + '_metrics.txt';\n        }\n    }\n    \n}\n"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 301,
            "valueFrom": "${  //Rename summary.txt file\n    \n    var reads=[].concat(inputs.in_reads);\n    \n    if(inputs.summary_file){\n        \n        if(inputs.out_prefix && inputs.out_prefix.trim()!=''){\n            \n            return '; mv summary.txt ' + inputs.out_prefix + '_summary.txt';\n        }\n        else if(reads[0].metadata && reads[0].metadata.sample_id){\n            \n            var sample_id= reads[0].metadata.sample_id;\n            return '; mv summary.txt ' + sample_id + '_summary.txt';\n        }\n        else{\n        \n            var input_read_name = reads[0].nameroot.split('.')[0];\n            return '; mv summary.txt ' + input_read_name + '_summary.txt';\n            \n        }\n        \n    }\n\n    \n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 303,
            "valueFrom": "\""
          },
          {
            "prefix": "--rg-id",
            "shellQuote": false,
            "position": 1,
            "valueFrom": "${  \n    if(inputs.no_rg){\n        return null;\n    } else {\n        var input = [].concat(inputs.in_reads)[0];\n        // Used for scatter mode\n        var folder_name = input.path.split('/').slice(-2,-1).toString();\n        var suffix = \"_s\";\n  \n        if(inputs.rg_id && inputs.rg_id.trim()!=''){\n            return inputs.rg_id; \n            \n        } else if (folder_name.indexOf(suffix, folder_name.length - suffix.length) !== -1) { // scatter mode\n        \n             var rg_id = folder_name.split(\"_\").slice(-2)[0];\n             if (parseInt(rg_id)) return rg_id;\n             else return '1';\n        \n        } else return '1';\n    } \n}\n"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 1,
            "valueFrom": "${  \n    function add_field(key,val) {\n        return '--rg '+key+':'+val; \n    }\n    \n    var rg=[];\n    var reads=[].concat(inputs.in_reads);\n    \n    if(inputs.no_rg){\n        return '';\n        \n    } else {\n    if(inputs.rg_seq_center && inputs.rg_seq_center.trim()!='') {\n        rg.push(add_field('CN',inputs.rg_seq_center)); \n    } else if(reads[0].metadata && reads[0].metadata.seq_center) {\n        rg.push(add_field('CN',reads[0].metadata.seq_center)); }\n        \n    if(inputs.rg_library && inputs.rg_library.trim()!='') {\n        rg.push(add_field('LB',inputs.rg_library)); \n    } else if(reads[0].metadata && reads[0].metadata.library_id) {\n        rg.push(add_field('LB',reads[0].metadata.library_id)); }\n    \n    if(inputs.rg_median_insert_size && inputs.rg_median_insert_size!=0) {\n        rg.push(add_field('PI',inputs.rg_median_insert_size)); \n    } else if(reads[0].metadata && reads[0].metadata.median_insert_size) {\n        rg.push(add_field('PI',reads[0].metadata.median_insert_size)); }\n        \n    if (inputs.rg_platform) {\n        rg.push(add_field('PL',inputs.rg_platform.replace(/ /g, \"_\"))); \n    } else if (reads[0].metadata && reads[0].metadata.platform) {\n        rg.push(add_field('PL',reads[0].metadata.platform.replace(/ /g, \"_\"))); }\n    \n    if (inputs.rg_platform_unit_id && inputs.rg_platform_unit_id.trim()!='' ) {\n        rg.push(add_field('PU',inputs.rg_platform_unit_id));  \n    } else if (reads[0].metadata && reads[0].metadata.platform_unit_id) {\n            rg.push(add_field('PU',reads[0].metadata.platform_unit_id)); }\n    \n    if(inputs.rg_sample_id && inputs.rg_sample_id.trim()!='') {\n        rg.push(add_field('SM',inputs.rg_sample_id)); \n    } else if(reads[0].metadata && reads[0].metadata.sample_id) {\n        rg.push(add_field('SM',reads[0].metadata.sample_id)); }\n    \n    var rg_addf=inputs.rg_additional_fields;\n    if(rg_addf && rg_addf[0].trim()!='') {\n        for(var i=0;i<rg_addf.length; i++ ) {\n                var addf=rg_addf[i];\n                rg.push('--rg ' + addf); \n        }\n    }\n    \n    return rg.join(' ');\n    }\n}"
          },
          {
            "prefix": "",
            "shellQuote": false,
            "position": 302,
            "valueFrom": "${  //Rename novel_splice_sites.txt file\n   \n    var reads=[].concat(inputs.in_reads);\n    \n    if(inputs.novel_splicesite_outfile) {\n        \n        if(inputs.out_prefix && inputs.out_prefix.trim()!='') {\n            \n            return '; mv novel_splice_sites.txt ' + inputs.out_prefix + '_novel_splice_sites.txt';\n        }\n        else if(reads[0].metadata && reads[0].metadata.sample_id) {\n            \n            var sample_id= reads[0].metadata.sample_id;\n            return '; mv novel_splice_sites.txt ' + sample_id + '_novel_splice_sites.txt';\n        }\n        else{\n        \n            var input_read_name = reads[0].nameroot.split('.')[0];\n            return '; mv novel_splice_sites.txt ' + input_read_name + '_novel_splice_sites.txt';\n        }\n        \n    }\n    \n}"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": "${\n    return inputs.mem_per_job ? inputs.mem_per_job : 1000;\n}",
            "coresMin": "${\n    if (inputs.nthreads && inputs.nthreads > 0) {\n            return inputs.nthreads;\n        } else {\n        return 4;\n    }\n}"
          },
          {
            "class": "DockerRequirement",
            "dockerPull": "images.sbgenomics.com/jasmina_miscevic/hisat2-2.2.1:0"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.indexed_reference)",
              "$(inputs.in_reads)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file)) {\n        file['metadata'] = {}\n    }\n    for (var key in metadata) {\n        file['metadata'][key] = metadata[key];\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "sbg:toolkitVersion": "2.2.1",
        "sbg:toolAuthor": "Johns Hopkins University",
        "sbg:categories": [
          "RNA-Seq",
          "Alignment"
        ],
        "sbg:license": "GNU General Public License v3.0 only",
        "sbg:image_url": null,
        "sbg:links": [
          {
            "id": "https://daehwankimlab.github.io/hisat2/",
            "label": "HISAT2 Homepage"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-source/download",
            "label": "HISAT2 Source Code"
          },
          {
            "id": "https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-Linux_x86_64/download",
            "label": "HISAT2 Download"
          },
          {
            "id": "http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html",
            "label": "HISAT2 Publications"
          },
          {
            "id": "https://daehwankimlab.github.io/hisat2/manual/",
            "label": "HISAT2 Documentation"
          }
        ],
        "sbg:toolkit": "HISAT2",
        "sbg:expand_workflow": false,
        "sbg:projectName": "HISAT2 2.2.1 Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1597960991,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1597961152,
            "sbg:revisionNotes": "HISAT2 2.2.1"
          },
          {
            "sbg:revision": 2,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1599834278,
            "sbg:revisionNotes": "Description modified"
          },
          {
            "sbg:revision": 3,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1612171822,
            "sbg:revisionNotes": "Description and tool categories modified."
          },
          {
            "sbg:revision": 4,
            "sbg:modifiedBy": "jasmina_miscevic",
            "sbg:modifiedOn": 1645090712,
            "sbg:revisionNotes": "Category modified."
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-cb33b74d/h-6cc7b3f1/h-8ba6d422/0",
        "sbg:revision": 4,
        "sbg:revisionNotes": "Category modified.",
        "sbg:modifiedOn": 1645090712,
        "sbg:modifiedBy": "jasmina_miscevic",
        "sbg:createdOn": 1597960991,
        "sbg:createdBy": "jasmina_miscevic",
        "sbg:project": "jasmina_miscevic/hisat2-2-2-1-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "jasmina_miscevic"
        ],
        "sbg:latestRevision": 4,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "ab3529b0c068e14b948639290094e5e2ff3afafd5cc2b3eee89ff75e52260efa7",
        "sbg:workflowLanguage": "CWL"
      },
      "label": "HISAT2",
      "scatter": [
        "in_reads"
      ],
      "sbg:x": -97.26673126220703,
      "sbg:y": 70.95218658447266
    },
    {
      "id": "sbg_pair_fastqs_by_metadata",
      "in": [
        {
          "id": "fastq_list",
          "source": [
            "in_reads"
          ]
        }
      ],
      "out": [
        {
          "id": "tuple_list"
        }
      ],
      "run": {
        "class": "CommandLineTool",
        "cwlVersion": "v1.0",
        "$namespaces": {
          "sbg": "https://sevenbridges.com"
        },
        "id": "sevenbridges/sbgtools-cwl1-0-demo/sbg-pair-fastqs-by-metadata/1",
        "baseCommand": [
          "echo"
        ],
        "inputs": [
          {
            "id": "fastq_list",
            "type": "File[]?",
            "label": "List of FASTQ files",
            "doc": "List of the FASTQ files with properly set metadata fileds.",
            "sbg:fileTypes": "FASTQ, FQ, FASTQ.GZ, FQ.GZ"
          }
        ],
        "outputs": [
          {
            "id": "tuple_list",
            "doc": "List of grouped FASTQ files by metadata fields.",
            "label": "List of grouped FASTQ files",
            "type": "File[]?",
            "outputBinding": {
              "outputEval": "${\n  function get_meta_map(m, file, meta) {\n    if (meta in file.metadata) {\n      return m[file.metadata[meta]];\n    } else {\n      return m['Undefined'];\n    }\n  }\n  \n  function create_new_map(map, file, meta) {\n    if (meta in file.metadata) {\n      map[file.metadata[meta]] = {};\n      return map[file.metadata[meta]];\n    } else {\n      map['Undefined'] = {};\n      return map['Undefined'];\n    }\n  }\n  \n  if (inputs.fastq_list) {\n    \n    var arr = [].concat(inputs.fastq_list);\n    var map = {};\n    \n    for (var i in arr) {\n      \n      var sm_map = get_meta_map(map, arr[i], 'sample_id');\n      if (!sm_map) sm_map = create_new_map(map, arr[i], 'sample_id');\n      \n      var lb_map = get_meta_map(sm_map, arr[i], 'library_id');\n      if (!lb_map) lb_map = create_new_map(sm_map, arr[i], 'library_id');\n      \n      var pu_map = get_meta_map(lb_map, arr[i], 'platform_unit_id');\n      if (!pu_map) pu_map = create_new_map(lb_map, arr[i], 'platform_unit_id');\n      \n      var a = '';\n      var ar = '';\n      \n      if ('file_segment_number' in arr[i].metadata) {\n        if (pu_map[arr[i].metadata['file_segment_number']]) {\n          a = pu_map[arr[i].metadata['file_segment_number']];\n          ar = [].concat(a);\n          ar = ar.concat(arr[i]);\n          pu_map[arr[i].metadata['file_segment_number']] = ar;\n        } else {\n          pu_map[arr[i].metadata['file_segment_number']] = [].concat(arr[i]);\n        }\n      } else {\n        if (pu_map['Undefined']) {\n          a = pu_map['Undefined'];\n          ar = [].concat(a);\n          ar = ar.concat(arr[i]);\n          pu_map['Undefined'] = ar;\n        } else {\n          pu_map['Undefined'] = [].concat(arr[i]);\n        }\n      }\n    }\n    var tuple_list = [];\n    var list;\n    for (var sm in map)\n      for (var lb in map[sm])\n        for (var pu in map[sm][lb]) {\n          for (var fsm in map[sm][lb][pu]) {\n            list = map[sm][lb][pu][fsm];\n            tuple_list.push(list);\n          }\n        }\n    return tuple_list;\n  }\n}"
            },
            "sbg:fileTypes": "FASTQ, FQ, FASTQ.GZ, FQ.GZ"
          }
        ],
        "doc": "Tool accepts list of FASTQ files groups them into separate lists. This grouping is done using metadata values and their hierarchy (Sample ID > Library ID > Platform unit ID > File segment number) which should create unique combinations for each pair of FASTQ files. Important metadata fields are Sample ID, Library ID, Platform unit ID and File segment number. Not all of these four metadata fields are required, but the present set has to be sufficient to create unique combinations for each pair of FASTQ files. Files with no paired end metadata are grouped in the same way as the ones with paired end metadata, generally they should be alone in a separate list. Files with no metadata set will be grouped together. \n\nIf there are more than two files in a group, this might create errors further down most pipelines and the user should check if the metadata fields for those files are set properly.",
        "label": "SBG Pair FASTQs by Metadata",
        "arguments": [
          {
            "shellQuote": false,
            "position": 0,
            "valueFrom": "'Pairing"
          },
          {
            "shellQuote": false,
            "position": 1,
            "valueFrom": "FASTQs!'"
          }
        ],
        "requirements": [
          {
            "class": "ShellCommandRequirement"
          },
          {
            "class": "ResourceRequirement",
            "ramMin": 1024,
            "coresMin": 1
          },
          {
            "class": "DockerRequirement",
            "dockerImageId": "d41a0837ab81",
            "dockerPull": "images.sbgenomics.com/nikola_jovanovic/alpine:1"
          },
          {
            "class": "InitialWorkDirRequirement",
            "listing": [
              "$(inputs.fastq_list)"
            ]
          },
          {
            "class": "InlineJavascriptRequirement",
            "expressionLib": [
              "var updateMetadata = function(file, key, value) {\n    file['metadata'][key] = value;\n    return file;\n};\n\n\nvar setMetadata = function(file, metadata) {\n    if (!('metadata' in file))\n        file['metadata'] = metadata;\n    else {\n        for (var key in metadata) {\n            file['metadata'][key] = metadata[key];\n        }\n    }\n    return file\n};\n\nvar inheritMetadata = function(o1, o2) {\n    var commonMetadata = {};\n    if (!Array.isArray(o2)) {\n        o2 = [o2]\n    }\n    for (var i = 0; i < o2.length; i++) {\n        var example = o2[i]['metadata'];\n        for (var key in example) {\n            if (i == 0)\n                commonMetadata[key] = example[key];\n            else {\n                if (!(commonMetadata[key] == example[key])) {\n                    delete commonMetadata[key]\n                }\n            }\n        }\n    }\n    if (!Array.isArray(o1)) {\n        o1 = setMetadata(o1, commonMetadata)\n    } else {\n        for (var i = 0; i < o1.length; i++) {\n            o1[i] = setMetadata(o1[i], commonMetadata)\n        }\n    }\n    return o1;\n};\n\nvar toArray = function(file) {\n    return [].concat(file);\n};\n\nvar groupBy = function(files, key) {\n    var groupedFiles = [];\n    var tempDict = {};\n    for (var i = 0; i < files.length; i++) {\n        var value = files[i]['metadata'][key];\n        if (value in tempDict)\n            tempDict[value].push(files[i]);\n        else tempDict[value] = [files[i]];\n    }\n    for (var key in tempDict) {\n        groupedFiles.push(tempDict[key]);\n    }\n    return groupedFiles;\n};\n\nvar orderBy = function(files, key, order) {\n    var compareFunction = function(a, b) {\n        if (a['metadata'][key].constructor === Number) {\n            return a['metadata'][key] - b['metadata'][key];\n        } else {\n            var nameA = a['metadata'][key].toUpperCase();\n            var nameB = b['metadata'][key].toUpperCase();\n            if (nameA < nameB) {\n                return -1;\n            }\n            if (nameA > nameB) {\n                return 1;\n            }\n            return 0;\n        }\n    };\n\n    files = files.sort(compareFunction);\n    if (order == undefined || order == \"asc\")\n        return files;\n    else\n        return files.reverse();\n};"
            ]
          }
        ],
        "sbg:image_url": null,
        "sbg:license": "Apache License 2.0",
        "sbg:toolkit": "SBGTools",
        "sbg:cmdPreview": "echo 'Pairing FASTQs!'",
        "sbg:categories": [
          "Converters",
          "Other"
        ],
        "sbg:toolAuthor": "",
        "sbg:projectName": "SBGTools - CWL1.0 - Demo",
        "sbg:revisionsInfo": [
          {
            "sbg:revision": 0,
            "sbg:modifiedBy": "nens",
            "sbg:modifiedOn": 1566551892,
            "sbg:revisionNotes": null
          },
          {
            "sbg:revision": 1,
            "sbg:modifiedBy": "nens",
            "sbg:modifiedOn": 1566551930,
            "sbg:revisionNotes": "v5-dev project"
          }
        ],
        "sbg:appVersion": [
          "v1.0"
        ],
        "sbg:id": "h-b226f33f/h-05ffdf86/h-88187742/0",
        "sbg:revision": 1,
        "sbg:revisionNotes": "v5-dev project",
        "sbg:modifiedOn": 1566551930,
        "sbg:modifiedBy": "nens",
        "sbg:createdOn": 1566551892,
        "sbg:createdBy": "nens",
        "sbg:project": "sevenbridges/sbgtools-cwl1-0-demo",
        "sbg:sbgMaintained": false,
        "sbg:validationErrors": [],
        "sbg:contributors": [
          "nens"
        ],
        "sbg:latestRevision": 1,
        "sbg:publisher": "sbg",
        "sbg:content_hash": "abc1ee4211fa6d6a183c881d4222c5db44458cc03409291a5844ebc6f0a7fa043"
      },
      "label": "SBG Pair FASTQs by Metadata",
      "sbg:x": -629.0270385742188,
      "sbg:y": -198.0656280517578
    }
  ],
  "hints": [
    {
      "class": "sbg:AWSInstanceType",
      "value": "r5.8xlarge;ebs-gp2;2048"
    },
    {
      "class": "sbg:GoogleInstanceType",
      "value": "n1-highmem-32;pd-ssd;2048"
    },
    {
      "class": "sbg:AzureInstanceType",
      "value": "Standard_E32s_v4;StandardSSD;2000"
    },
    {
      "class": "sbg:maxNumberOfParallelInstances",
      "value": "6"
    }
  ],
  "requirements": [
    {
      "class": "ScatterFeatureRequirement"
    },
    {
      "class": "InlineJavascriptRequirement"
    },
    {
      "class": "StepInputExpressionRequirement"
    }
  ],
  "sbg:projectName": "BCO-CWL Examples",
  "sbg:revisionsInfo": [
    {
      "sbg:revision": 0,
      "sbg:modifiedBy": "phil_webster",
      "sbg:modifiedOn": 1676561864,
      "sbg:revisionNotes": "Copy of admin/sbg-public-data/hisat2-stringtie/11"
    }
  ],
  "sbg:image_url": "https://cgc.sbgenomics.com/ns/brood/images/phil_webster/bco-cwl-examples/hisat2-stringtie/0.png",
  "sbg:links": [
    {
      "id": "http://www.nature.com/nprot/journal/v11/n9/full/nprot.2016.095.html",
      "label": "Publication"
    },
    {
      "id": "https://daehwankimlab.github.io/hisat2/",
      "label": "HISAT2 Homepage"
    },
    {
      "id": "http://ccb.jhu.edu/software/stringtie/index.shtml",
      "label": "StringTie Homepage"
    }
  ],
  "sbg:toolAuthor": "",
  "sbg:wrapperAuthor": "",
  "sbg:categories": [
    "Alignment",
    "Quantification",
    "RNA-Seq"
  ],
  "sbg:license": "GNU General Public License v3.0",
  "sbg:expand_workflow": false,
  "sbg:appVersion": [
    "v1.0"
  ],
  "id": "https://cgc-api.sbgenomics.com/v2/apps/phil_webster/bco-cwl-examples/hisat2-stringtie/0/raw/",
  "sbg:id": "phil_webster/bco-cwl-examples/hisat2-stringtie/0",
  "sbg:revision": 0,
  "sbg:revisionNotes": "Copy of admin/sbg-public-data/hisat2-stringtie/11",
  "sbg:modifiedOn": 1676561864,
  "sbg:modifiedBy": "phil_webster",
  "sbg:createdOn": 1676561864,
  "sbg:createdBy": "phil_webster",
  "sbg:project": "phil_webster/bco-cwl-examples",
  "sbg:sbgMaintained": false,
  "sbg:validationErrors": [],
  "sbg:contributors": [
    "phil_webster"
  ],
  "sbg:latestRevision": 0,
  "sbg:publisher": "sbg",
  "sbg:content_hash": "a3260624441b781d2fb36ff3ade22573f3d50b98065a4e1034b9427c186aeb1a0",
  "sbg:workflowLanguage": "CWL",
  "sbg:copyOf": "admin/sbg-public-data/hisat2-stringtie/11"
}